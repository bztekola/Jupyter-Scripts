{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== part_cost.py start ==\n",
      "\n",
      "0 nulls\n",
      "the mean_stripe_margin is 77.44%\n",
      "\n",
      "the part types with no MSRP are/is: ['sku']\n",
      "\n",
      "avg gross profit for:\n",
      "parts, combos, and stripes\n",
      "which have been purchased within the last year\n",
      "whose sku_status equals \"working\"\n",
      "whose msrp is greater than zero\n",
      "bought by non resellers\n",
      "is 55.74%\n",
      "\n",
      "the parts with negative gross profit are: [2885, 3400]\n",
      "\n",
      "your dfs are: all_cost (cost on the sku level) and all_cost_by_part (cost on the part level)\n",
      "\n",
      "== part_cost.py end ==\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/Users/jarad/fake_folder/Python Libraries')\n",
    "\n",
    "from jb_libraries import *\n",
    "from part_cost import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "resellers = {'Chicago Electronic Distributors':170955,\n",
    "            'Elmwood Electronics':402263,\n",
    "            'Digi-Key':515404,\n",
    "            'Arrow':430980,\n",
    "            'Mouser':383922,\n",
    "            'Akizuki Denshi Tsusho Co.':297368,\n",
    "            'Exp Tech':128228,\n",
    "            'Pi Hut':218531,\n",
    "            'KJD Electronics':211704,\n",
    "            'Pimoroni':122936,\n",
    "            'Distrelec':654035,\n",
    "            'Micro Center':390641,\n",
    "            'Allied Electronics':489596}\n",
    "\n",
    "# go two years back for main sales data, then restrict to only one year in your \"data\" df\n",
    "date_start = '2016-10-01'\n",
    "date_end = '2018-10-31'\n",
    "\n",
    "rolling_quarter_start = '2018-08-01'\n",
    "rolling_quarter_end = '2018-10-31'\n",
    "\n",
    "one_year_ago = pd.to_datetime(date_start) + pd.DateOffset(years = 1)\n",
    "pretty_rolling_quarter_start = calendar.month_abbr[int(rolling_quarter_start[5:7])] + ' ' + rolling_quarter_start[:4]\n",
    "pretty_rolling_quarter_end = calendar.month_abbr[int(rolling_quarter_end[5:7])] + ' ' + rolling_quarter_end[:4]\n",
    "\n",
    "workbook_title = '2018 - 10 - Oct - Reseller Report'\n",
    "\n",
    "close_workbook = 'no'\n",
    "close_plot = 'no'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "disco = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "p.part_id AS 'part id',\n",
    "pd.products_name AS name\n",
    "FROM parts p\n",
    "LEFT JOIN products_description pd ON p.part_id = pd.part_id\n",
    "WHERE (p.products_discontinued = 1\n",
    "OR p.products_dont_sell_to_resellers = 1)\n",
    "''', db)\n",
    "\n",
    "disco['why'] = 'discontinued'\n",
    "\n",
    "internal = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "part_id AS 'part id',\n",
    "sku_name AS name\n",
    "FROM skus\n",
    "WHERE sku_is_internal = 1\n",
    "AND part_id != 0\n",
    "''', db)\n",
    "\n",
    "internal['why'] = 'internal'\n",
    "\n",
    "exclude_by_hand = [2843,3358,3359,3360,3067,2931,2929,2684,2893,2481,2877,2904,2905,2907,2908,3075,3126,3074,30,31,32,141,\n",
    "                   3331,1205,1245,1408,3792]\n",
    "always_exclude = disco['part id'].tolist() + internal['part id'].tolist() + exclude_by_hand\n",
    "\n",
    "# for workbook\n",
    "excluded_db = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "part_id AS 'part id',\n",
    "products_name AS 'products name',\n",
    "'always exclude' AS 'why'\n",
    "FROM products_description\n",
    "WHERE part_id IN '''+ str(tuple(always_exclude)) +'''\n",
    "''', db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sku data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sku_data = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "p.part_id AS 'part id',\n",
    "k.bom_type AS bom,\n",
    "p.combined_sales_90 AS 'combined sales 90'\n",
    "FROM parts p\n",
    "\n",
    "LEFT JOIN \n",
    "(SELECT\n",
    "MAX(sku_date_modified),\n",
    "bom_type,\n",
    "part_id,\n",
    "sku_id\n",
    "FROM skus\n",
    "WHERE part_id != 0\n",
    "GROUP BY part_id) k ON p.part_id = k.part_id\n",
    "''', db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manufacturing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that there can be several manufacturers for a single part\n",
    "# so this query has duplicate part numbers!!\n",
    "# but we just flag adafruit prods later, so it doesn't really matter \n",
    "\n",
    "manufacturing = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "A.part_id AS 'part id',\n",
    "sm.stuff_manufacturers_name AS manufacturer\n",
    "FROM\n",
    "\n",
    "(SELECT\n",
    "part_id,\n",
    "sku_id\n",
    "FROM skus\n",
    "WHERE part_id != 0\n",
    "GROUP BY sku_id) A\n",
    "\n",
    "LEFT JOIN stuff_to_manufacturers stm ON A.sku_id = stm.sku_id\n",
    "LEFT JOIN stuff_manufacturers sm ON stm.stuff_manufacturers_id = sm.stuff_manufacturers_id\n",
    "''', db)\n",
    "\n",
    "manufacturing['manufacturer'].fillna('Adafruit Industries', inplace = True)\n",
    "\n",
    "ada_parts = manufacturing['part id'][manufacturing['manufacturer'] == 'Adafruit Industries'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reseller_discounts = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "part_id AS 'part id',\n",
    "discount_qty AS 'reseller discount qty',\n",
    "discount_price / 100 AS 'reseller max % off'\n",
    "FROM products_reseller_discount_pricing\n",
    "''', db)\n",
    "\n",
    "reseller_discounts.sort_values(['part id','reseller max % off'], ascending = [True, False], inplace = True)\n",
    "reseller_discounts.drop_duplicates('part id', keep = 'first', inplace = True)\n",
    "\n",
    "#================================================================================\n",
    "\n",
    "qty_discounts = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "part_id AS 'part id',\n",
    "discount_qty AS 'qty discount qty',\n",
    "discount_price / 100 AS 'qty max % off'\n",
    "FROM products_discount_quantity\n",
    "''', db)\n",
    "\n",
    "qty_discounts.sort_values(['part id','qty max % off'], ascending = [True, False], inplace = True)\n",
    "qty_discounts.drop_duplicates('part id', keep = 'first', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orders_status_id</th>\n",
       "      <th>language_id</th>\n",
       "      <th>orders_status_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Shipped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Printed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Billed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Payment Received</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Fraud - Pending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>Fraud - Confirmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>Replaced Defective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Refunded Defective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>No Shipment Necessary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>Voided</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>Fraud - Void</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    orders_status_id  language_id     orders_status_name\n",
       "0                  1            1                Pending\n",
       "1                  2            1             Processing\n",
       "2                  3            1                Shipped\n",
       "3                  4            1                 Update\n",
       "4                  5            1                Printed\n",
       "5                  6            1                 Billed\n",
       "6                  7            1       Payment Received\n",
       "7                  8            1        Fraud - Pending\n",
       "8                  9            1      Fraud - Confirmed\n",
       "9                 10            1                 Return\n",
       "10                11            1     Replaced Defective\n",
       "11                12            1     Refunded Defective\n",
       "12                13            1  No Shipment Necessary\n",
       "13                14            1                 Voided\n",
       "14                15            1           Fraud - Void"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "*\n",
    "FROM orders_status\n",
    "ORDER BY orders_status_id \n",
    "''', db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_products = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "DATE(o.date_purchased) AS date,\n",
    "DATE_FORMAT(o.date_purchased, '%Y-%m') AS 'year and month',\n",
    "o.orders_id AS 'orders id',\n",
    "o.customers_id AS 'customers id',\n",
    "IF(o.orders_reseller = 0 AND o.orders_super_reseller = 0, 'non reseller', 'reseller') AS customer,\n",
    "op.part_id AS 'part id',\n",
    "op.products_quantity - op.products_quantity_free AS 'qty bought',\n",
    "op.products_quantity_free AS 'qty free',\n",
    "op.products_quantity AS 'qty total',\n",
    "(op.products_quantity - op.products_quantity_free) * op.products_price AS revenue,\n",
    "op.products_price AS 'price paid per unit'\n",
    "\n",
    "FROM orders_products op\n",
    "JOIN orders o ON op.orders_id = o.orders_id\n",
    "\n",
    "WHERE DATE(o.date_purchased) BETWEEN ' '''+ date_start +''' ' AND ' '''+ date_end +''' '\n",
    "AND o.orders_status NOT IN (8,9,10,11,12,14,15)\n",
    "AND o.payment_method != 'Replacement Order'\n",
    "AND op.part_id NOT IN '''+ str(tuple(always_exclude)) +'''\n",
    "''', db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_description = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "part_id,\n",
    "products_name\n",
    "FROM products_description\n",
    "''', db)\n",
    "\n",
    "col_fix(products_description)\n",
    "orders_products['products name'] = orders_products['part id'].map(dict(zip(products_description['part id'],products_description['products name'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge it all and label parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_cost2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c11f1f6667cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_cost2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'part type'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'latest cost'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'cost per unit'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'all_cost2' is not defined"
     ]
    }
   ],
   "source": [
    "all_cost2.rename(columns = {'type':'part type','latest cost':'cost per unit'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msrp = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "part_id,\n",
    "products_price AS msrp\n",
    "FROM parts\n",
    "''', db)\n",
    "\n",
    "col_fix(msrp)\n",
    "\n",
    "all_cost2['msrp'] = all_cost2['part id'].map(dict(zip(msrp['part id'], msrp['msrp'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.merge(orders_products,\n",
    "                all_cost2,\n",
    "                how = 'left',\n",
    "                on = 'part id').merge(sku_data,\n",
    "                                      how = 'left',\n",
    "                                      on = 'part id')\n",
    "\n",
    "sales['bom'] = np.where(sales['part type'] == 'combo', 'combo', sales['bom'])\n",
    "sales['date'] = pd.to_datetime(sales['date'])\n",
    "sales['manufacturer'] = np.where(sales['part id'].isin(ada_parts), 'Adafruit Industries', 'someone else')\n",
    "\n",
    "# the way we price and cost stripes changed around may 4, 2018\n",
    "# if we want historical costs and prices then we need to get creative\n",
    "# before this date, assume that the margin for any stripe is the avg margin of the price paid\n",
    "# note that the mean_stripe_margin is based on the CURRENT MSRPs\n",
    "\n",
    "# to fix the cost we'll adjust it such that the profit margin of the unit sold will equal the \n",
    "    # avg stripe margin based on current MSRP\n",
    "# mean_stripe_margin comes directly from the parts table and is in part_cost.py\n",
    "\n",
    "print('the mean stripe margin is {:,.1f}%'.format(mean_stripe_margin * 100))\n",
    "\n",
    "sales['cost per unit'] = np.where((sales['part type'] == 'stripe') & (sales['date'] < '2018-05-04'),\n",
    "                                 sales['price paid per unit'] * (1 - mean_stripe_margin),\n",
    "                                 sales['cost per unit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_nulls = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "part_id AS 'part id',\n",
    "products_name AS 'products name'\n",
    "FROM products_description\n",
    "WHERE part_id IN '''+ str(tuple(sales['part id'][sales.isnull().any(1)].unique())) +'''\n",
    "''', db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy and work on it\n",
    "# use this \"data\" df for your workbook\n",
    "data = sales.copy()\n",
    "\n",
    "# restrice by date for reseller data\n",
    "data = data[data['date'].between(one_year_ago, date_end)]\n",
    "data['total cost'] = data['qty total'] * data['cost per unit']\n",
    "data['gross profit'] = data['revenue'] - data['total cost']\n",
    "\n",
    "link_path = 'https://www.adafruit.com/product/'\n",
    "data['link'] = link_path + data['part id'].map(str)\n",
    "\n",
    "data = pd.merge(data,\n",
    "               pd.DataFrame.from_dict(resellers,\n",
    "               orient = 'index').reset_index().rename(columns = {'index':'company', 0:'customers id'}),\n",
    "               how = 'left',\n",
    "               on = 'customers id',\n",
    "               copy = False)\n",
    "\n",
    "print('%i dupe(s) before removing' % np.sum(data.duplicated()))\n",
    "data.drop_duplicates(inplace = True)\n",
    "print('overall profit margin {:,.1f}%'.format(data['gross profit'].sum()/data['revenue'].sum() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check gross profts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = data[['date',\n",
    "                  'orders id',\n",
    "                  'part id',\n",
    "                  'qty bought',\n",
    "                  'price paid per unit',\n",
    "                  'revenue',\n",
    "                  'cost per unit',\n",
    "                  'total cost',\n",
    "                  'gross profit',\n",
    "                  'customer',\n",
    "                  'part type']][(data['gross profit'] < 0)\n",
    "                               & (data['qty bought'] > 0)\n",
    "                               & (data['price paid per unit'] > 0.00)].sort_values('gross profit')\n",
    "\n",
    "days = (data['date'].max() - data['date'].min()).days\n",
    "months = days/12\n",
    "tot_loss = negative['gross profit'].sum()\n",
    "print('total gross profit loss is ${:,.0f} or ${:,.0f} per month over {:,.0f} months\\n'.format(tot_loss,\n",
    "                                                                                             tot_loss/months,\n",
    "                                                                                             months))\n",
    "print(negative.groupby('part type')[['gross profit']].sum().sort_values('gross profit').format_(['m0']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adafruit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_rolling_q_stats = data.copy()\n",
    "ada_rolling_q_stats = ada_rolling_q_stats[ada_rolling_q_stats['date'].between(rolling_quarter_start, rolling_quarter_end)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cust = ada_rolling_q_stats.groupby(['part id','products name'], as_index = False)[['qty bought']].sum().sort_values('qty bought', ascending = False).head(25)\n",
    "res_only = ada_rolling_q_stats[ada_rolling_q_stats['customer'] == 'reseller'].groupby(['part id','products name'], as_index = False)[['qty bought']].sum().sort_values('qty bought', ascending = False).head(25)\n",
    "ada_manufact_only = ada_rolling_q_stats[ada_rolling_q_stats['manufacturer'] == 'Adafruit Industries'].groupby(['part id','products name'], as_index = False)[['qty bought']].sum().sort_values('qty bought', ascending = False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_company = data.groupby(['year and month','company'])[['revenue']].sum().unstack(1).fillna(0)\n",
    "data_by_company.columns = data_by_company.columns.droplevel(0)\n",
    "data_by_company.reset_index(inplace = True)\n",
    "\n",
    "data_by_company.format_([0] + list(['m0'] * (len(data_by_company.columns) - 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"all_cost\" from part_cost.py\n",
    "# this returns all costs and MSRPs\n",
    "# for stripes tho, this returns the cost and MSRP for the entire reel\n",
    "cost_for_five_tables = all_cost2.copy()\n",
    "cost_for_five_tables['parent part id'] = cost_for_five_tables['part id']\n",
    "cost_for_five_tables.sort_values(['part id','cost per unit'], inplace = True)\n",
    "\n",
    "for_five_tables = data.groupby(['part id',\n",
    "                                'products name',\n",
    "                                'bom',\n",
    "                                'combined sales 90',\n",
    "                                'link'], as_index = False)[['qty bought']].sum().merge(cost_for_five_tables[['part id','cost per unit','msrp']],\n",
    "                                                                                                how = 'left',\n",
    "                                                                                                on = 'part id').merge(reseller_discounts,\n",
    "                                                                                                                        how = 'left',\n",
    "                                                                                                                        on = 'part id').merge(qty_discounts,\n",
    "                                                                                                                                              how = 'left',\n",
    "                                                                                                                                              on = 'part id')\n",
    "for col in ['reseller discount qty','reseller max % off','qty discount qty','qty max % off']:\n",
    "    for_five_tables[col].fillna(0, inplace = True)\n",
    "    \n",
    "print('%i dupe(s)' % np.sum(for_five_tables['part id'].duplicated()))\n",
    "print('%i null(s)' % np.sum(for_five_tables.isnull().any(1)))\n",
    "\n",
    "for_five_tables['price per unit with reseller max discount'] = for_five_tables['msrp'] * (1 - for_five_tables['reseller max % off'])\n",
    "for_five_tables['margin with reseller max discount'] = 1 - (for_five_tables['cost per unit']/for_five_tables['price per unit with reseller max discount'])\n",
    "\n",
    "for_five_tables['price per unit with qty max discount'] = for_five_tables['msrp'] * (1 - for_five_tables['qty max % off'])\n",
    "for_five_tables['margin with qty max discount'] = 1 - (for_five_tables['cost per unit']/for_five_tables['price per unit with qty max discount'])\n",
    "\n",
    "for_five_tables['adafruit manufactured'] = np.where(for_five_tables['part id'].isin(ada_parts), 'x', '')\n",
    "\n",
    "print('%i dupe(s)' % np.sum(for_five_tables['part id'].duplicated()))\n",
    "print('%i null(s)' % np.sum(for_five_tables.isnull().any(1)))\n",
    "print('%i part(s) with zero MSRP before removing' % np.sum(for_five_tables['msrp'] == 0))\n",
    "for_five_tables.drop(for_five_tables[for_five_tables['msrp'] == 0]. index, inplace = True)\n",
    "print('overall profit margin is {:,.1f}%'.format(np.mean((for_five_tables['msrp'] - for_five_tables['cost per unit'])/for_five_tables['msrp']) * 100))\n",
    "\n",
    "#==============================================================================================================\n",
    "\n",
    "parts_resellers = data[(data['date'] >= rolling_quarter_start)\n",
    "                          & (data['customer'] == 'reseller')].groupby('part id',\n",
    "                                                                      as_index = False)[['qty bought']].sum()\n",
    "\n",
    "#==============================================================================================================\n",
    "\n",
    "parts_non_resellers = data[(data['date'] >= rolling_quarter_start)\n",
    "                          & (data['customer'] == 'non reseller')].groupby('part id',\n",
    "                                                                      as_index = False)[['qty bought']].sum()\n",
    "\n",
    "#==============================================================================================================\n",
    "\n",
    "do_not_stock = pd.read_excel(r'/Users/jarad/fake_folder/Accounts and Biz Dev/Recurring/Reseller Report/Docs/reseller exclude.xlsx')\n",
    "\n",
    "#==============================================================================================================\n",
    "\n",
    "all_part_names = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "part_id AS 'part id',\n",
    "products_name AS 'products name'\n",
    "FROM products_description\n",
    "''', db)\n",
    "\n",
    "every_part_bought = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "o.customers_id AS 'customers id',\n",
    "op.part_id AS 'part id'\n",
    "FROM orders_products op\n",
    "JOIN orders o ON op.orders_id = o.orders_id\n",
    "AND o.customers_id IN '''+ str(tuple(resellers.values())) +'''\n",
    "''', db)\n",
    "\n",
    "every_part_bought['reseller'] = every_part_bought['customers id'].replace(resellers.values(), resellers.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excel start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if close_workbook == 'yes':\n",
    "    \n",
    "    workbook = xlsxwriter.Workbook(workbook_title + '.xlsx',\n",
    "                                   {'nan_inf_to_errors': False})\n",
    "    \n",
    "    # formats\n",
    "    worksheet_title_format = workbook.add_format({'font_size':25,\n",
    "                                                  'font_name':'Arial (Bold)'})\n",
    "\n",
    "    header_and_column_format = workbook.add_format({'font_name':'Arial (Bold)',\n",
    "                                                    'valign':'vcenter',\n",
    "                                                    'align':'center',\n",
    "                                                    'bg_color':'#edf9ff',\n",
    "                                                    'bottom':1,\n",
    "                                                    'top':1,\n",
    "                                                    'left':1,\n",
    "                                                    'right':1})\n",
    "\n",
    "    money_format = workbook.add_format({'num_format':'$#,##0'})\n",
    "    money_decimal_format = workbook.add_format({'num_format':'$#,##0.00'})\n",
    "\n",
    "    percent_format = workbook.add_format({'num_format':'0.00%'})\n",
    "    date_format = workbook.add_format({'num_format':'mmm yyyy'})\n",
    "\n",
    "    number_format = workbook.add_format({'num_format':'#,##0'})\n",
    "\n",
    "\n",
    "    # create reseller name list\n",
    "    worksheet_list = ['Adafruit Stats']\n",
    "    for key in resellers.keys():\n",
    "        worksheet_list.append(key)\n",
    "\n",
    "    # create worksheets\n",
    "    for name in worksheet_list:\n",
    "        workbook.add_worksheet(name)\n",
    "\n",
    "    # send all to worksheet dict\n",
    "    my_worksheets = {}\n",
    "    for worksheet in workbook.worksheets():\n",
    "        my_worksheets[worksheet.get_name()] = worksheet\n",
    "\n",
    "    # do all similar formatting\n",
    "    for key, value in my_worksheets.items():\n",
    "        worksheet = my_worksheets[key]\n",
    "        if key == 'Adafruit Stats':\n",
    "            write_this = key + ' from ' + pretty_rolling_quarter_start + ' to ' + pretty_rolling_quarter_end\n",
    "        else:\n",
    "            write_this = key + ' with Customer ID: ' + str(resellers[key])\n",
    "        worksheet.write(0, 0, \n",
    "                        write_this,\n",
    "                        worksheet_title_format)\n",
    "\n",
    "#===== adafruit data\n",
    "#==============================================================================================================    \n",
    "\n",
    "    worksheet = my_worksheets['Adafruit Stats']\n",
    "\n",
    "    worksheet.merge_range(3, 1,\n",
    "                          3, 3,\n",
    "                         'all customers',\n",
    "                          header_and_column_format)\n",
    "\n",
    "#===== all customers\n",
    "\n",
    "    start_row = 4\n",
    "    start_col = 1\n",
    "\n",
    "    for col in range(len(all_cust.columns)):\n",
    "        worksheet.write(start_row, start_col + col,\n",
    "                       all_cust.columns[col],\n",
    "                       header_and_column_format)\n",
    "        worksheet.set_column(start_col + col, start_col + col,\n",
    "                         np.max([len(str(x)) for x in all_cust.iloc[:,col]] + [len(all_cust.columns[col])]) + 1)\n",
    "        for row in range(len(all_cust)):\n",
    "            if all_cust.columns[col] == 'qty bought':\n",
    "                worksheet.write(start_row + 1 + row, start_col + col,\n",
    "                               all_cust.iloc[row, col],\n",
    "                               number_format)\n",
    "            else:\n",
    "                worksheet.write(start_row + 1 + row, start_col + col,\n",
    "                               all_cust.iloc[row, col])\n",
    "\n",
    "#===== resellers only\n",
    "\n",
    "    worksheet.merge_range(3, 5,\n",
    "                          3, 7,\n",
    "                         'resellers only',\n",
    "                          header_and_column_format)\n",
    "\n",
    "    start_row = 4\n",
    "    start_col = 5\n",
    "\n",
    "    for col in range(len(res_only.columns)):\n",
    "        worksheet.write(start_row, start_col + col,\n",
    "                       res_only.columns[col],\n",
    "                       header_and_column_format)\n",
    "        worksheet.set_column(start_col + col, start_col + col,\n",
    "                         np.max([len(str(x)) for x in res_only.iloc[:,col]] + [len(res_only.columns[col])]) + 1)\n",
    "        for row in range(len(res_only)):\n",
    "            if res_only.columns[col] == 'qty bought':\n",
    "                worksheet.write(start_row + 1 + row, start_col + col,\n",
    "                               res_only.iloc[row, col],\n",
    "                               number_format)\n",
    "            else:\n",
    "                worksheet.write(start_row + 1 + row, start_col + col,\n",
    "                               res_only.iloc[row, col])\n",
    "\n",
    "#===== adafruit manufactured only\n",
    "\n",
    "    worksheet.merge_range(3, 9,\n",
    "                          3, 11,\n",
    "                         'adafruit manufactured parts only',\n",
    "                          header_and_column_format)\n",
    "\n",
    "    start_row = 4\n",
    "    start_col = 9\n",
    "\n",
    "    for col in range(len(ada_manufact_only.columns)):\n",
    "        worksheet.write(start_row, start_col + col,\n",
    "                       ada_manufact_only.columns[col],\n",
    "                       header_and_column_format)\n",
    "        worksheet.set_column(start_col + col, start_col + col,\n",
    "                         np.max([len(str(x)) for x in ada_manufact_only.iloc[:,col]] + [len(ada_manufact_only.columns[col])]) + 1)\n",
    "        for row in range(len(ada_manufact_only)):\n",
    "            if ada_manufact_only.columns[col] == 'qty bought':\n",
    "                worksheet.write(start_row + 1 + row, start_col + col,\n",
    "                               ada_manufact_only.iloc[row, col],\n",
    "                               number_format)\n",
    "            else:\n",
    "                worksheet.write(start_row + 1 + row, start_col + col,\n",
    "                               ada_manufact_only.iloc[row, col])\n",
    "\n",
    "#===== data by company\n",
    "\n",
    "    worksheet.merge_range(3, 13,\n",
    "                          3, 24,\n",
    "                         'revenue by reseller',\n",
    "                          header_and_column_format)\n",
    "\n",
    "    start_row = 4\n",
    "    start_col = 13\n",
    "\n",
    "    for col in range(len(data_by_company.columns)):\n",
    "        worksheet.write(start_row, start_col + col,\n",
    "                       data_by_company.columns[col],\n",
    "                       header_and_column_format)\n",
    "        worksheet.set_column(start_col + col, start_col + col,\n",
    "                         np.max([len(str(x)) for x in data_by_company.iloc[:,col]] + [len(data_by_company.columns[col])]) + 1)\n",
    "        for row in range(len(data_by_company)):\n",
    "            worksheet.write(start_row + 1 + row, start_col + col,\n",
    "                           data_by_company.iloc[row, col],\n",
    "                           money_format) \n",
    "\n",
    "#===== reseller data\n",
    "#==============================================================================================================    \n",
    "\n",
    "    year_and_month = pd.DataFrame({'year and month':pd.to_datetime(pd.date_range(one_year_ago, date_end, freq = 'MS'))})\n",
    "    year_and_month['year and month'] = [str(x)[:7] for x in year_and_month['year and month']]\n",
    "\n",
    "    for key, value in resellers.items():\n",
    "\n",
    "        worksheet = my_worksheets[key]\n",
    "\n",
    "        res_data = data.copy()\n",
    "        res_data = res_data[res_data['customers id'] == value]\n",
    "\n",
    "#===== revenue, gross profit, and qty sold\n",
    "#===================================================================================================================\n",
    "\n",
    "        numbers = res_data.groupby('year and month', as_index = False)[['revenue','gross profit','qty bought']].sum()\n",
    "        numbers = pd.merge(year_and_month,\n",
    "                          numbers,\n",
    "                          how = 'left',\n",
    "                          on = 'year and month')\n",
    "        numbers.fillna(0, inplace = True)\n",
    "\n",
    "        worksheet.merge_range(2, 1,\n",
    "                              2, len(numbers.columns), \n",
    "                              'Revenue, Gross Profit, and Qty',\n",
    "                              header_and_column_format)    \n",
    "        start_row = 3\n",
    "        start_col = 1\n",
    "\n",
    "        for col in range(len(numbers.columns)):\n",
    "            worksheet.write(start_row, start_col + col, \n",
    "                            numbers.columns[col],\n",
    "                            header_and_column_format)\n",
    "            worksheet.set_column(start_col + col, start_col + col,\n",
    "                             np.max([len(str(x)) for x in numbers.iloc[:,col]] + [len(numbers.columns[col])]) + 1)\n",
    "\n",
    "            for row in range(len(numbers)):\n",
    "                if numbers.columns[col] == 'year and month':\n",
    "                    worksheet.write(start_row + 1 + row, start_col + col,\n",
    "                                    numbers.iloc[row, col])\n",
    "                elif numbers.columns[col] in ('revenue','gross profit'):\n",
    "                    worksheet.write(start_row + 1 + row, start_col + col,\n",
    "                                    numbers.iloc[row, col],\n",
    "                                    money_format)\n",
    "                elif numbers.columns[col] == 'qty bought':\n",
    "                    worksheet.write(start_row + 1 + row, start_col + col,\n",
    "                                    numbers.iloc[row, col],\n",
    "                                    number_format)\n",
    "\n",
    "#===== month to month and YoY % changes\n",
    "#===================================================================================================================\n",
    "\n",
    "        changes = numbers.set_index('year and month')\n",
    "        changes = changes.pct_change()\n",
    "        changes.loc['YoY'] = numbers.iloc[:,1:].pct_change(periods = 12).iloc[-1]\n",
    "        changes.reset_index(inplace = True)\n",
    "\n",
    "        worksheet.merge_range(2, 6,\n",
    "                              2, len(changes.columns) + 6 - 1, \n",
    "                              'Percent Changes',\n",
    "                              header_and_column_format)    \n",
    "        start_row = 3\n",
    "        start_col = 6\n",
    "\n",
    "        for col in range(len(changes.columns)):\n",
    "            worksheet.write(start_row, start_col + col, \n",
    "                            changes.columns[col],\n",
    "                            header_and_column_format)\n",
    "            worksheet.set_column(start_col + col, start_col + col,\n",
    "                             np.max([len(str(x)) for x in changes.iloc[:,col]] + [len(changes.columns[col])]))\n",
    "\n",
    "            for row in range(len(changes)):\n",
    "                try:\n",
    "                    worksheet.write(start_row + 1 + row, start_col + col,\n",
    "                                   changes.iloc[row, col],\n",
    "                                   percent_format)\n",
    "                except:\n",
    "                    worksheet.write_blank(start_row + 1 +  row, start_col + col,\n",
    "                                          changes.iloc[row, col])\n",
    "\n",
    "#===== descriptive stats by month\n",
    "#==============================================================================================================                    \n",
    "\n",
    "        describe = numbers.set_index('year and month').describe().reset_index().rename(columns = {'index':'statistic'}).copy()\n",
    "\n",
    "        worksheet.merge_range(2, 11,\n",
    "                              2, len(describe.columns) + 11 - 1, \n",
    "                              'Descriptive Statistics by Month',\n",
    "                              header_and_column_format)    \n",
    "        start_row = 3\n",
    "        start_col = 11\n",
    "\n",
    "        for col in range(len(describe.columns)):\n",
    "            worksheet.write(start_row, start_col + col, \n",
    "                            describe.columns[col],\n",
    "                            header_and_column_format)\n",
    "            worksheet.set_column(start_col + col, start_col + col,\n",
    "                             np.max([len(str(x)) for x in describe.iloc[:,col]] + [len(describe.columns[col])]))\n",
    "\n",
    "            for row in range(len(describe)):\n",
    "                worksheet.write(start_row + 1 + row, start_col + col,\n",
    "                               describe.iloc[row, col],\n",
    "                               number_format)\n",
    "\n",
    "#===== rolling quarter qty sold\n",
    "#==============================================================================================================    \n",
    "\n",
    "        qty = res_data[res_data['date'].between(rolling_quarter_start, rolling_quarter_end)].groupby(['part id','products name'], as_index = False)[['qty bought']].sum().sort_values('qty bought', ascending = False).head(50)    \n",
    "\n",
    "        worksheet.merge_range(2, 16,\n",
    "                              2, 18,\n",
    "                             'top ' + str(len(qty)) + ' parts in last 3 months' if len(qty) < 50 else 'top 50 parts bought in last 3 months',\n",
    "                             header_and_column_format)\n",
    "        start_row = 3\n",
    "        start_col = 16\n",
    "\n",
    "        for col in range(len(qty.columns)):\n",
    "            worksheet.write(start_row, start_col + col,\n",
    "                           qty.columns[col],\n",
    "                           header_and_column_format)\n",
    "            worksheet.set_column(start_col + col, start_col + col,\n",
    "                             np.max([len(str(x)) for x in qty.iloc[:,col]] + [len(qty.columns[col])]))        \n",
    "            for row in range(len(qty)):\n",
    "                if qty.columns[col] == 'qty bought':\n",
    "                    worksheet.write(start_row + 1 + row, start_col + col,\n",
    "                                   qty.iloc[row, col],\n",
    "                                   number_format)\n",
    "                else:\n",
    "                    worksheet.write(start_row + 1 + row, start_col + col,\n",
    "                                   qty.iloc[row, col])\n",
    "\n",
    "#===== the five tables\n",
    "#==============================================================================================================                    \n",
    "\n",
    "        # bought by X in last year\n",
    "        bought01 = data.copy()\n",
    "        bought01 = bought01['part id'][bought01['customers id'] == value].unique().tolist()\n",
    "\n",
    "        # bought by X in last 3 months\n",
    "        bought02 = data.copy()\n",
    "        bought02 = bought02['part id'][(bought02['date'] >= rolling_quarter_start)\n",
    "                                      & (bought02['customers id'] == value)].unique().tolist()\n",
    "        \n",
    "        five_tables = for_five_tables.copy()\n",
    "        five_tables = five_tables[~five_tables['part id'].isin(do_not_stock['part id'][do_not_stock['reseller'] == key].tolist())]\n",
    "\n",
    "        five_tables['bought by ' + key.split()[0] + ' in last year'] = np.where(five_tables['part id'].isin(bought01), 'x','')\n",
    "        five_tables['bought by ' + key.split()[0] + ' in last 3 months'] = np.where(five_tables['part id'].isin(bought02), 'x','')\n",
    "        five_tables['never bought by ' + key.split()[0]] = np.where(~five_tables['part id'].isin(every_part_bought['part id'][every_part_bought['reseller'] == key].tolist()), 'x','')\n",
    "\n",
    "        five_tables['reseller'] = np.where(five_tables['part id'].isin(parts_resellers['part id'].tolist()), 'x','')\n",
    "        five_tables['all customers'] = np.where(five_tables['part id'].isin(parts_non_resellers['part id'].tolist()), 'x','')                    \n",
    "        \n",
    "        five_tables['part id '] = five_tables['part id']\n",
    "        five_tables['name '] = five_tables['products name']\n",
    "\n",
    "        worksheet.merge_range(2, 20,\n",
    "                              2, 20 + len(five_tables.columns) - 1,\n",
    "                             'the five tables',\n",
    "                             header_and_column_format)\n",
    "\n",
    "        start_row = 3\n",
    "        start_col = 20\n",
    "\n",
    "        for col in range(len(five_tables.columns)):\n",
    "            worksheet.write(start_row, start_col + col,\n",
    "                           five_tables.columns[col],\n",
    "                           header_and_column_format)\n",
    "            worksheet.set_column(start_col + col, start_col + col,\n",
    "                     np.max([len(str(x)) for x in five_tables.iloc[:,col]] + [len(five_tables.columns[col])]) + 10)\n",
    "\n",
    "            for row in range(len(five_tables)):\n",
    "                try:\n",
    "                    if five_tables.columns[col] in ('msrp',\n",
    "                                                    'cost',\n",
    "                                                    'lowest price @ 30% off',\n",
    "                                                    'price per unit with reseller max discount',\n",
    "                                                    'price per unit with qty max discount'):\n",
    "                        worksheet.write(start_row + 1 + row, start_col + col,\n",
    "                                       five_tables.iloc[row, col],\n",
    "                                       money_decimal_format)\n",
    "                    elif five_tables.columns[col] in ('reseller max % off',\n",
    "                                                      'margin with reseller max discount',\n",
    "                                                      'qty max % off',\n",
    "                                                      'margin with qty max discount'):\n",
    "                        worksheet.write(start_row + 1 + row, start_col + col,\n",
    "                                       five_tables.iloc[row, col],\n",
    "                                       percent_format)        \n",
    "                    elif five_tables.columns[col] in ('part id',\n",
    "                                                      'qty bought',\n",
    "                                                      'reseller discount qty',\n",
    "                                                      'qty discount qty',\n",
    "                                                      'combined sales 90'):\n",
    "                        worksheet.write(start_row + 1 + row, start_col + col,\n",
    "                                       five_tables.iloc[row, col],\n",
    "                                       number_format)                        \n",
    "                    else:\n",
    "                        worksheet.write(start_row + 1 + row, start_col + col,\n",
    "                                       five_tables.iloc[row, col])\n",
    "                except:\n",
    "                    worksheet.write_blank(start_row + 1 + row, start_col + col,\n",
    "                                   five_tables.iloc[row, col])\n",
    "\n",
    "\n",
    "        worksheet.autofilter(start_row, start_col,\n",
    "                            start_row + len(five_tables), start_col + len(five_tables.columns) - 1)\n",
    "\n",
    "#===== excluded\n",
    "#==============================================================================================================                    \n",
    "\n",
    "        excluded_reseller = do_not_stock[['part id']][do_not_stock['reseller'] == key].copy()\n",
    "        excluded_reseller = pd.merge(excluded_reseller,\n",
    "                                       all_part_names,\n",
    "                                       how = 'left',\n",
    "                                       on = 'part id',\n",
    "                                       copy = False)\n",
    "        excluded_reseller['why'] = 'reseller do not stock'\n",
    "\n",
    "        excluded = pd.concat([excluded_reseller,\n",
    "                            excluded_db])\n",
    "\n",
    "        excluded.drop_duplicates('part id', inplace = True)\n",
    "        excluded.sort_values('part id', ascending = False, inplace = True)\n",
    "\n",
    "        worksheet.merge_range(2, 45,\n",
    "                              2, 47,\n",
    "                             'excluded parts',\n",
    "                             header_and_column_format)\n",
    "\n",
    "        start_row = 3\n",
    "        start_col = 45\n",
    "\n",
    "        for col in range(len(excluded.columns)):\n",
    "            worksheet.write(start_row, start_col + col,\n",
    "                           excluded.columns[col],\n",
    "                           header_and_column_format)\n",
    "            worksheet.set_column(start_col + col, start_col + col,\n",
    "                     np.max([len(str(x)) for x in excluded.iloc[:,col]] + [len(excluded.columns[col])]) + 10)\n",
    "            for row in range(len(excluded)):\n",
    "                worksheet.write(start_row + 1 + row, start_col + col,\n",
    "                               excluded.iloc[row, col])\n",
    "\n",
    "#===== unique part count\n",
    "#==============================================================================================================                    \n",
    "\n",
    "        unique_parts_main = res_data.copy()\n",
    "\n",
    "        unique_parts_main = unique_parts_main[['year and month','part id']]\n",
    "        unique_parts_main.sort_values(['part id','year and month'], inplace = True)\n",
    "        unique_parts_main.drop_duplicates('part id', keep = 'first', inplace = True)\n",
    "\n",
    "        unique_parts = unique_parts_main.groupby('year and month', as_index = False).agg({'part id':'count'})#.cumsum()\n",
    "        unique_parts = pd.merge(year_and_month,\n",
    "                                unique_parts,\n",
    "                                how = 'left',\n",
    "                                on = 'year and month',\n",
    "                                copy = False).fillna(0)\n",
    "        unique_parts['running sum'] = unique_parts['part id'].cumsum()\n",
    "        unique_parts.drop(['part id'], 1, inplace = True)\n",
    "        unique_parts['m2m'] = unique_parts['running sum'].pct_change()\n",
    "        unique_parts['yoy'] = unique_parts['running sum'].pct_change(periods = 12)\n",
    "\n",
    "        worksheet.merge_range(2, 49,\n",
    "                              2, 52,\n",
    "                             'unique part count',\n",
    "                             header_and_column_format)\n",
    "\n",
    "        start_row = 3\n",
    "        start_col = 49\n",
    "\n",
    "        for col in range(len(unique_parts.columns)):\n",
    "            worksheet.write(start_row, start_col + col,\n",
    "                           unique_parts.columns[col],\n",
    "                           header_and_column_format)\n",
    "            worksheet.set_column(start_col + col, start_col + col,\n",
    "                     np.max([len(str(x)) for x in unique_parts.iloc[:,col]] + [len(unique_parts.columns[col])]) + 5)\n",
    "            for row in range(len(unique_parts)):\n",
    "                try:\n",
    "                    if unique_parts.columns[col] == 'running sum':\n",
    "                        worksheet.write(start_row + 1 + row, start_col + col,\n",
    "                                       unique_parts.iloc[row, col],\n",
    "                                       number_format)\n",
    "                    elif unique_parts.columns[col] in ('m2m','yoy'):\n",
    "                        worksheet.write(start_row + 1 + row, start_col + col,\n",
    "                                       unique_parts.iloc[row, col],\n",
    "                                       percent_format)\n",
    "                    else:\n",
    "                        worksheet.write(start_row + 1 + row, start_col + col,\n",
    "                                       unique_parts.iloc[row, col])                    \n",
    "                except:\n",
    "                        worksheet.write_blank(start_row + 1 + row, start_col + col,\n",
    "                                       unique_parts.iloc[row, col])\n",
    "\n",
    "    workbook.close()\n",
    "    \n",
    "#===== charts\n",
    "#===================================================================================================================\n",
    "\n",
    "import xlwings as xw\n",
    "\n",
    "if close_plot == 'yes':\n",
    "\n",
    "    sht = xw.Book(r'/Users/jarad/fake_folder/Accounts and Biz Dev/Recurring/Reseller Report/Python/' + workbook_title + '.xlsx').sheets\n",
    "\n",
    "#===== reseller specific charts        \n",
    "#===================================================================================================================\n",
    "    \n",
    "    colors = {\n",
    "    'color01':'#085f89',\n",
    "    'color02':'#038fd2',\n",
    "    'color03':'#edf9ff',\n",
    "    'color04':'#989898',\n",
    "    'color05':'#313131'}\n",
    "\n",
    "    for key, value in resellers.items():\n",
    "\n",
    "        res_data = data.copy()\n",
    "        res_data = res_data[res_data['customers id'] == value]\n",
    "\n",
    "        numbers = res_data.groupby('year and month', as_index = False)[['revenue','gross profit','qty bought']].sum()\n",
    "        numbers = pd.merge(year_and_month,\n",
    "                          numbers,\n",
    "                          how = 'left',\n",
    "                          on = 'year and month')\n",
    "        numbers.fillna(0, inplace = True)\n",
    "\n",
    "        for_reseller_chart = numbers.copy()\n",
    "        for_reseller_chart.set_index('year and month', inplace = True)\n",
    "\n",
    "        reseller_chart, ax = plt.subplots(figsize = (15,5))\n",
    "\n",
    "        for_reseller_chart[['revenue','gross profit']].plot(ax = ax,\n",
    "                                                           color = [colors['color01'],colors['color04']],\n",
    "                                                           kind = 'bar')\n",
    "\n",
    "\n",
    "        ax.set_facecolor(colors['color03'])\n",
    "        ax.set_xticks(np.arange(len(for_reseller_chart)))\n",
    "        ax.set_xticklabels([calendar.month_abbr[int(str(x)[-2:])] + '\\n' + str(x)[:4] for x in for_reseller_chart.index],\n",
    "                          rotation = 0)\n",
    "        ax.set_xlabel('')\n",
    "        vals = ax.get_yticks()\n",
    "        ax.set_yticklabels(['${:,.0f}'.format(x/1000) for x in vals])\n",
    "        ax.set_ylabel('thousands')\n",
    "        ax.set_title(key + ' Revenue and Gross Profit',\n",
    "                    y = 1.02)\n",
    "\n",
    "        x = range(len(for_reseller_chart))\n",
    "        y1 = for_reseller_chart['revenue']\n",
    "        y2 = for_reseller_chart['gross profit']\n",
    "\n",
    "        z1 = np.polyfit(x, y1, 1)\n",
    "        p1 = np.poly1d(z1)\n",
    "\n",
    "        z2 = np.polyfit(x, y2, 1)\n",
    "        p2 = np.poly1d(z2)\n",
    "\n",
    "        ax.plot(x, p1(x), color = colors['color01'], ls = '--', label = 'revenue trend')\n",
    "        ax.plot(x, p2(x), color = colors['color04'], ls = '--', label = 'gross profit trend')    \n",
    "\n",
    "        ax.grid()\n",
    "\n",
    "        ax.legend()\n",
    "        sht_plot = sht[key].pictures.add(reseller_chart, \n",
    "                                    name = 'reseller_chart', \n",
    "                                    update = True, \n",
    "                                    left = sht[key].range('B21').left, \n",
    "                                    top = sht[key].range('B21').top)\n",
    "\n",
    "        plt.close(reseller_chart)    \n",
    "        \n",
    "#===== all resellers chart for first worksheet\n",
    "#===================================================================================================================\n",
    "\n",
    "    all_resellers = data_by_company.set_index('year and month').copy()\n",
    "    all_resellers['total'] = all_resellers.sum(1)\n",
    "    all_resellers['mean'] = all_resellers.mean(1)\n",
    "    all_resellers = all_resellers[['total','mean']]\n",
    "\n",
    "    all_resellers_chart, ax = plt.subplots(figsize = (16,5))\n",
    "\n",
    "    all_resellers['total'].plot(kind = 'bar',\n",
    "                           ax = ax,\n",
    "                           color = colors['color01'])\n",
    "    all_resellers['mean'].plot(ax = ax, \n",
    "                          color = colors['color02'])\n",
    "\n",
    "    ax.set_facecolor(colors['color03'])\n",
    "    ax.set_xticks(np.arange(len(all_resellers)))\n",
    "    ax.set_xticklabels([calendar.month_abbr[int(str(x)[-2:])] + '\\n' + str(x)[:4] for x in all_resellers.index],\n",
    "                      rotation = 0)\n",
    "    ax.set_xlabel('')\n",
    "    vals = ax.get_yticks()\n",
    "    ax.set_yticklabels(['${:,.0f}'.format(x/1000) for x in vals])\n",
    "    ax.set_ylabel('thousands')\n",
    "    ax.set_title('Total and Mean Revenue from Resellers')\n",
    "    ax.grid()\n",
    "    ax.legend() \n",
    "\n",
    "    sht_plot = sht['Adafruit Stats'].pictures.add(all_resellers_chart, \n",
    "                                name = 'all_resellers_chart', \n",
    "                                update = True, \n",
    "                                left = sht['Adafruit Stats'].range('N21').left, \n",
    "                                top = sht['Adafruit Stats'].range('N21').top)\n",
    "\n",
    "    plt.close(all_resellers_chart)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reseller totals check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cust ids\n",
    "customer_id_check_list = []\n",
    "for value in resellers.values():\n",
    "    customer_id_check_list.append(value)\n",
    "    \n",
    "# get data from the original df, before any changes    \n",
    "df = orders_products[(orders_products['customers id'].isin(customer_id_check_list))\n",
    "                   & (orders_products['date'] >= one_year_ago.date())]\n",
    "db_check = df.groupby('customers id', as_index = False)[['revenue']].sum()\n",
    "db_check.rename(columns = {'revenue':'db revenue'}, inplace= True)\n",
    "\n",
    "# get revenue from report\n",
    "report_check = data[data['customers id'].isin(customer_id_check_list)].groupby('customers id', as_index = False).agg({'revenue':'sum'})\n",
    "report_check.rename(columns = {'revenue':'report revenue'}, inplace = True)\n",
    "\n",
    "# merge\n",
    "check = pd.merge(report_check,\n",
    "                db_check,\n",
    "                on = 'customers id')\n",
    "\n",
    "check['reseller'] = check['customers id'].replace(resellers.values(), resellers.keys())\n",
    "\n",
    "cols = ['customers id','reseller','report revenue','db revenue']\n",
    "check = check[cols]\n",
    "\n",
    "check['diff'] = check['report revenue'] - check['db revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check by OID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = orders_products.groupby('orders id')[['revenue']].sum()\n",
    "df1.columns = ['db revenue']\n",
    "\n",
    "df2 = data.groupby('orders id')[['revenue']].sum()\n",
    "df2.columns = ['report revenue']\n",
    "\n",
    "df3 = df2.join(df1)\n",
    "\n",
    "diff = df3[np.abs(df3['db revenue'] - df3['report revenue']) > 1]\n",
    "\n",
    "if diff.empty:\n",
    "    print('match')\n",
    "else:\n",
    "    print('mismatch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
