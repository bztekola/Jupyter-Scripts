{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THIS IS BROKEN\n",
    "# State-by-State Sales Numbers - Sales Tax\n",
    "* Started July 6,2018\n",
    "* Continued July 18, 2018\n",
    "*****\n",
    "### From Stella:\n",
    "* From email with subject line \"state-by-state sales numbers - sales tax\"\n",
    "* Please run state-by-state gross sales and number of sales transactions for the whole of 2017. Break up by month and then have a grand total (sum of all months) for the annual. You can create one workbook with one tab per state. If you'd prefer to configure the workbook in a different way, please feel free.\n",
    "* We can pull 2018 Q1 and Q2 numbers after the completion of this month (June). It would have the same format - broken down by month and then total sum of all months."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State and abbrev dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_state_abbrev = {\n",
    "    'Alabama': 'AL',\n",
    "    'Alaska': 'AK',\n",
    "    'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'California': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'Delaware': 'DE',\n",
    "    'Florida': 'FL',\n",
    "    'Georgia': 'GA',\n",
    "    'Hawaii': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI',\n",
    "    'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY',\n",
    "    'District Of Columbia':'DC',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get state data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_main = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "orders_id,\n",
    "customers_state,\n",
    "customers_postcode,\n",
    "customers_country\n",
    "FROM orders\n",
    "WHERE DATE(date_purchased) >= '2017-01-01'\n",
    "''', db)\n",
    "\n",
    "col_fix(states_main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean it up and map it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast to lowercase\n",
    "states_main['customers country'] = [x.lower() for x in states_main['customers country']]\n",
    "\n",
    "# strip whitespace\n",
    "for col in ['state','country']:\n",
    "    states_main['customers ' + col] = [x.strip() for x in states_main['customers ' + col]]\n",
    "\n",
    "# print these, just to see\n",
    "print('states before extracting just \"united states\"\\n')\n",
    "print(set(states_main['customers country'][states_main['customers country'].str.contains('united')]))\n",
    "\n",
    "# consider only this \n",
    "states_main = states_main[states_main['customers country'] == 'united states']\n",
    "\n",
    "# clean state abbrevs\n",
    "def state_clean(x):\n",
    "    if len(x['customers state']) == 2:\n",
    "        state = x['customers state'].upper()\n",
    "    else:\n",
    "        state = x['customers state'].title()\n",
    "    return state\n",
    "states_main['customers state'] = states_main.apply(state_clean, axis = 1)\n",
    "\n",
    "# map\n",
    "states_main['state name'] = states_main['customers state'].replace(us_state_abbrev.values(), us_state_abbrev.keys())\n",
    "\n",
    "# find true states \n",
    "states_main['is state'] = np.where(states_main['state name'].isin(us_state_abbrev.keys()), 'yes','no')\n",
    "\n",
    "# save for later viewing, if needed\n",
    "exclude = list(set(states_main[states_main['is state'] == 'no']['customers state']))\n",
    "print('\\nexcluded \"states\"')\n",
    "print(exclude)\n",
    "\n",
    "# map state date to main data\n",
    "# recall that your sales_main df does not have any mismatches on the OID level\n",
    "for x in ['state name','is state']:\n",
    "    ot_main[x] = ot_main['orders id'].map(dict(zip(states_main['orders id'], states_main[x])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excluded \"states\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_main[states_main['is state'] == 'no'].groupby('state name')[['orders id']].count().sort_values('orders id', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate what is and is not \"gross\", as per Stella"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ot_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gross = ['check fee',\n",
    "        'ddp',\n",
    "        'production fee',\n",
    "        'refund reversal',\n",
    "        'shipping',\n",
    "        'subtotal',\n",
    "        'tax',\n",
    "        'wiretransfer fee']\n",
    "\n",
    "not_gross = list(set(ot_main['class']) - set(gross))\n",
    "\n",
    "for x in ['','total']:\n",
    "    not_gross.remove(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_this = 'no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if write_this == 'yes':\n",
    "\n",
    "    # make nice columns\n",
    "    cols = list(set(sales_main['class']))\n",
    "    for x in ['subtotal','shipping','tax','total','']:\n",
    "        cols.remove(x)\n",
    "    cols = ['subtotal'] + cols + ['shipping','tax','total']\n",
    "\n",
    "    # start to write\n",
    "    title = 'State-by-State Sales Numbers - Sales Tax - v1'\n",
    "    workbook = xlsxwriter.Workbook(csv_path + title + '.xlsx')\n",
    "\n",
    "    # set formats\n",
    "    set_col = 18\n",
    "    money = workbook.add_format({'num_format': '$#,##0'})\n",
    "    number = workbook.add_format({'num_format': '#,##0'})\n",
    "    header = workbook.add_format({'bold': True, 'valign': 'center', 'align':'center'})\n",
    "    merge = workbook.add_format({'bold': True, 'valign': 'center', 'align':'center', 'bg_color':'#e0ffff','font_size':14,'border':1})\n",
    "\n",
    "    conf_dict = {}\n",
    "\n",
    "    # create summary sheet\n",
    "    worksheet = workbook.add_worksheet('Summary')\n",
    "\n",
    "    # create confidence intervals for each state\n",
    "    df1 = sales_main[(sales_main['is state'] == 'yes')\n",
    "                  & (sales_main['class'].isin(gross))].copy()\n",
    "\n",
    "    df2 = df1.groupby(['year and month','state name'])[['value']].sum().unstack(1).fillna(0)\n",
    "    df2.columns = df2.columns.droplevel(0)\n",
    "\n",
    "    d = {}\n",
    "    for col in df2.columns:\n",
    "        x_bar = df2[col].mean()\n",
    "        s = df2[col].std()\n",
    "        n = len(df2[col])\n",
    "\n",
    "        deg_freed = n - 1\n",
    "        phi = stats.t.ppf(0.95, deg_freed)\n",
    "\n",
    "        lower = x_bar - phi * (s/np.sqrt(n))\n",
    "        upper = x_bar + phi * (s/np.sqrt(n))\n",
    "\n",
    "        d[col] = [lower,x_bar,upper]\n",
    "\n",
    "    df3 = pd.DataFrame(d).T\n",
    "    df3.reset_index(inplace = True)\n",
    "    df3.columns = ['state','lower 95%','avg','upper 95%']\n",
    "\n",
    "    start_row = 0\n",
    "    start_col = 0\n",
    "\n",
    "    # write it\n",
    "    worksheet.merge_range(start_row, start_col, start_row, start_col + len(df3.columns) - 1, '95% confidence intervals for avg gross charge per month', merge)        \n",
    "    for i in range(len(df3.columns)):\n",
    "        worksheet.write(start_row + 1, start_col + i, df3.columns[i], header)\n",
    "        for j in range(len(df3)):\n",
    "            worksheet.write(start_row + 2 + j, start_col + i, df3.iloc[j,i], money)\n",
    "\n",
    "    worksheet.set_column(0,100,15)\n",
    "\n",
    "    # create \"by year\" summary for gross charges\n",
    "    df4 = sales_main[(sales_main['is state'] == 'yes')\n",
    "                  & (sales_main['class'].isin(gross))].copy()\n",
    "\n",
    "    df4['year'] = [x[:4] for x in df4['year and month']]\n",
    "    df5 = df4.groupby(['year','state name'])[['value']].sum().unstack(1).fillna(0)\n",
    "    df5.columns = df5.columns.droplevel(0)\n",
    "    df5 = df5.T\n",
    "    df5.reset_index(inplace = True)\n",
    "    df5['total'] = df5.sum(1)\n",
    "\n",
    "    start_row = 0\n",
    "    start_col = len(df3.columns) + 1\n",
    "\n",
    "    worksheet.merge_range(start_row, start_col, start_row, start_col + len(df5.columns) - 1, 'gross charges by year', merge)        \n",
    "    for i in range(len(df5.columns)):\n",
    "        worksheet.write(start_row + 1, start_col + i, df5.columns[i], header)\n",
    "        for j in range(len(df5)):\n",
    "            worksheet.write(start_row + 2 + j, start_col + i, df5.iloc[j,i], money)\n",
    "\n",
    "    # create \"by year\" summary for order count\n",
    "    df6 = sales_main[(sales_main['is state'] == 'yes')\n",
    "                  & (sales_main['class'].isin(gross))].copy()\n",
    "\n",
    "    df6['year'] = [x[:4] for x in df6['year and month']]\n",
    "    df7 = df6.groupby(['year','state name'])[['orders id']].nunique().unstack(1).fillna(0)\n",
    "    df7.columns = df7.columns.droplevel(0)\n",
    "    df7 = df7.T\n",
    "    df7.reset_index(inplace = True)\n",
    "    df7['total'] = df7.sum(1)\n",
    "\n",
    "    start_row = 0\n",
    "    start_col = len(df3.columns) + len(df5.columns) + 2\n",
    "\n",
    "    worksheet.merge_range(start_row, start_col, start_row, start_col + len(df7.columns) - 1, 'order counts by year', merge)        \n",
    "    for i in range(len(df7.columns)):\n",
    "        worksheet.write(start_row + 1, start_col + i, df7.columns[i], header)\n",
    "        for j in range(len(df7)):\n",
    "            worksheet.write(start_row + 2 + j, start_col + i, df7.iloc[j,i], number)\n",
    "\n",
    "    # write some notes about gross charges    \n",
    "    start_row = 0\n",
    "    start_col = len(df3.columns) + len(df5.columns)+ len(df7.columns) + 3\n",
    "\n",
    "    worksheet.merge_range(start_row, start_col, start_row, start_col + 2, 'notes on gross charges', merge)    \n",
    "    worksheet.write(start_row + 1, start_col, 'gross charges include:')\n",
    "    for i in range(len(gross)):\n",
    "        worksheet.write(start_row + 2 + i, start_col, gross[i])\n",
    "\n",
    "    start_row = start_row + len(gross) + 3\n",
    "    worksheet.write(start_row, start_col, 'gross charges do not include:')\n",
    "    for i in range(len(not_gross)):\n",
    "        worksheet.write(start_row + 1 + i, start_col, not_gross[i])\n",
    "\n",
    "    # loop through each state for subsequent tabs\n",
    "    ls = sorted(list(set(sales_main['state name'][sales_main['is state'] == 'yes'])))\n",
    "    for state in ls:\n",
    "\n",
    "        # create worksheet\n",
    "        worksheet = workbook.add_worksheet(state)\n",
    "\n",
    "        # structure data\n",
    "        main_df = sales_main[sales_main['state name'] == state]    \n",
    "\n",
    "        # get $$\n",
    "        df1 = main_df.groupby(['year and month','class'])[['value']].sum().unstack(1).fillna(0)\n",
    "        df1.columns = df1.columns.droplevel(0)\n",
    "\n",
    "        # make uniform cols, whether or not there are values\n",
    "        for col in cols:\n",
    "            if col not in list(df1.columns):\n",
    "                df1[col] = 0\n",
    "\n",
    "        df1 = df1[cols]\n",
    "        # exclude \"not gross\"\n",
    "        df1.drop(not_gross, 1, inplace = True)\n",
    "\n",
    "        # drop old total and make new one with just \"gross\" columns\n",
    "        df1.drop('total', 1, inplace = True)\n",
    "        df1['total'] = df1[gross].sum(1)\n",
    "\n",
    "        # get OID count\n",
    "        df2 = main_df.groupby('year and month')[['orders id']].nunique()\n",
    "        df2.columns = ['unique oid count']\n",
    "\n",
    "        df = df1.join(df2)\n",
    "        df.loc['total'] = df.sum()\n",
    "        df.reset_index(inplace = True) \n",
    "\n",
    "        start_row = 0\n",
    "        start_col = 0    \n",
    "\n",
    "        worksheet.merge_range(start_row, start_col, start_row, start_col + len(df.columns) - 1, 'gross charges by month', merge)        \n",
    "        for i in range(len(df.columns)):\n",
    "            worksheet.write(start_row + 1, start_col + i, df.columns[i], header)\n",
    "            for j in range(len(df)):\n",
    "                if df.columns[i] == 'unique oid count':\n",
    "                    fmt = number\n",
    "                else:\n",
    "                    fmt = money\n",
    "                worksheet.write(start_row + 2 + j, start_col + i, df.iloc[j,i], fmt)\n",
    "\n",
    "        worksheet.set_column(0,100,15)    \n",
    "\n",
    "        # by year\n",
    "        df.drop(df[df['year and month'] == 'total'].index, inplace = True)\n",
    "        df['year'] = df['year and month'].str[:4]    \n",
    "        by_year = df.groupby('year')[['total','unique oid count']].sum()    \n",
    "        by_year.loc['total'] = by_year.sum()\n",
    "        by_year.reset_index(inplace = True)\n",
    "\n",
    "        start_row = 0\n",
    "        start_col = len(df.columns)\n",
    "\n",
    "        worksheet.merge_range(start_row, start_col, start_row, start_col + len(by_year.columns) - 1, 'totals by year', merge)    \n",
    "        for i in range(len(by_year.columns)):\n",
    "            worksheet.write(start_row + 1, start_col + i, by_year.columns[i], header)\n",
    "            for j in range(len(by_year)):\n",
    "                if by_year.columns[i] == 'total':\n",
    "                    fmt = money\n",
    "                else:\n",
    "                    fmt = number\n",
    "                worksheet.write(start_row + 2 + j, start_col + i, by_year.iloc[j,i], fmt)    \n",
    "\n",
    "        # create confidence interval for gross charge and oid count\n",
    "        confidence = pd.DataFrame(columns = ['lower 95%','avg','upper 95%'])\n",
    "\n",
    "        for thing in ['total','unique oid count']:\n",
    "\n",
    "            x_bar = df[thing].mean()\n",
    "            s = df[thing].std()\n",
    "            n = len(df)\n",
    "\n",
    "            deg_freed = n - 1\n",
    "            phi = stats.t.ppf(0.95, deg_freed)\n",
    "\n",
    "            lower = x_bar - phi * (s/np.sqrt(n))\n",
    "            upper = x_bar + phi * (s/np.sqrt(n))\n",
    "\n",
    "            confidence.loc[thing] = [lower, x_bar, upper]\n",
    "\n",
    "        confidence.rename(index = {'total':'gross charge'}, inplace = True)\n",
    "        confidence.index.name = ''\n",
    "        confidence.reset_index(inplace = True)      \n",
    "\n",
    "        # write confidence interval\n",
    "        start_row = 0\n",
    "        start_col = len(df.columns) + len(by_year.columns) + 1\n",
    "\n",
    "        worksheet.merge_range(start_row, start_col, start_row, start_col + len(confidence.columns) - 1, '95% confidence intervals for avg per month', merge)\n",
    "        for i in range(len(confidence.columns)):\n",
    "            worksheet.write(start_row + 1, start_col + i, confidence.columns[i], header)\n",
    "            for j in range(len(confidence)):\n",
    "                if confidence.iloc[j][''] == 'unique oid count':\n",
    "                    fmt = number\n",
    "                else:\n",
    "                    fmt = money\n",
    "                worksheet.write(start_row + 2 + j, start_col + i, confidence.iloc[j,i], fmt)\n",
    "\n",
    "        confidence.rename(columns = {'':state}, inplace = True)\n",
    "        conf_dict[state] = confidence\n",
    "\n",
    "        # write some notes about gross charges    \n",
    "        start_row = 0\n",
    "        start_col = len(df.columns) + len(by_year.columns) + len(confidence.columns) + 2\n",
    "\n",
    "        worksheet.merge_range(start_row, start_col, start_row, start_col + 2, 'notes on gross charges', merge)    \n",
    "        worksheet.write(start_row + 1, start_col, 'gross charges include:')\n",
    "        for i in range(len(gross)):\n",
    "            worksheet.write(start_row + 2 + i, start_col, gross[i])\n",
    "\n",
    "        start_row = start_row + len(gross) + 3\n",
    "        worksheet.write(start_row, start_col, 'gross charges do not include:')\n",
    "        for i in range(len(not_gross)):\n",
    "            worksheet.write(start_row + 1 + i, start_col, not_gross[i])\n",
    "\n",
    "    workbook.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
