{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change this stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do you want to run the script AND generate the Excel workbook? or just run the script?\n",
    "# the script will run regardless of what you choose here\n",
    "# choose \"yes\" or \"no\"\n",
    "write_workbook = 'yes'\n",
    "\n",
    "# choose one of the below:\n",
    "# 'year and month','year and quarter','week ending'\n",
    "report_type = 'week ending'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Email Resources\n",
    "* Email with subject line \"Fwd: Discrepancy between Google Analytics and Algolia\"\n",
    "* 2018-07-21 is when zephyr updated the tracking capabilities of GA, see email mentioned above\n",
    "* Email with subject line \"How to view defined Event Actions in Google Analytics\"\n",
    "* Email with subject line \"Google Analytics: Shop vs www.Adafruit.com\"\n",
    "\n",
    "### Google Analytics resources\n",
    "* [Difference between Entrances and Sessions](https://support.google.com/analytics/answer/2956047?hl=en)\n",
    "* [Behavior Flow help page](https://support.google.com/analytics/answer/2785577?hl=en)\n",
    "* [Difference between Starting Page and Landing Page in Behavior Flow](https://webmasters.stackexchange.com/questions/99267/whats-the-difference-between-landing-page-and-starting-page-in-behaviour-fl)\n",
    "* [Info on PagePathLevels and Session count discrepancy](https://www.quora.com/In-Google-analytics-custom-Reporting-what-is-Page-path-level-definition)\n",
    "* [How Site Search metrics are calculated](https://support.google.com/analytics/answer/1032321?hl=en)\n",
    "\n",
    "### Dimensions and Metrics Explorer for API\n",
    "* https://developers.google.com/analytics/devguides/reporting/core/dimsmets\n",
    "\n",
    "### Google2Pandas Docs\n",
    "* https://github.com/panalysis/Google2Pandas\n",
    "\n",
    "### Other notes\n",
    "* Do this for Shop, Learn Guides, and Internal (for Tom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== jb_google_analytics start ==\n",
      "\n",
      "Your ga function is: get_ga(account_id, date_start, date_end, dimensions, metrics, filters)\n",
      "\n",
      "Beware of sampling!\n",
      "\n",
      "== jb_google_analytics end ==\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "tilde = os.path.expanduser('~')\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, tilde + '/Scripts/Fake Folder/Python Libraries')\n",
    "\n",
    "from jb_libraries import *\n",
    "%matplotlib inline\n",
    "\n",
    "from jb_google_analytics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be the most recent sunday, if you run this every monday\n",
    "# valid if you run this every monday\n",
    "date_end = str((dt.datetime.now() - pd.DateOffset(days = 1)).date()) \n",
    "\n",
    "one_year_ago = str((pd.to_datetime(date_end) - pd.DateOffset(weeks = 52, days = -1)).date())\n",
    "three_months_ago = str((pd.to_datetime(date_end) - pd.DateOffset(weeks = 12, days = 6)).date())\n",
    "four_weeks_ago = str((pd.to_datetime(date_end) - pd.DateOffset(weeks = 4, days = -1)).date())\n",
    "one_week_ago = str((pd.to_datetime(date_end) - pd.DateOffset(weeks = 1, days = -1)).date())\n",
    "\n",
    "csv_path = tilde + '/Fake Folder/New Products/Recurring/Algolia Searches Report/CSVs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w.e 2019-06-16 - Algolia Searches Report\n"
     ]
    }
   ],
   "source": [
    "t = ' - Algolia Searches Report'\n",
    "\n",
    "d = pd.to_datetime(date_end)\n",
    "\n",
    "year = str(d.year)\n",
    "quarter = str(d.quarter)\n",
    "month_num = date_end[5:7]\n",
    "month_name = calendar.month_abbr[int(month_num)]\n",
    "month_num = str(month_num)\n",
    "\n",
    "if report_type == 'year and quarter':\n",
    "    workbook_title = year + ' - ' + 'Q' + quarter + t\n",
    "elif report_type == 'year and month':\n",
    "    workbook_title = year + ' - ' + month_num + ' - ' + month_name + t\n",
    "elif report_type == 'week ending':\n",
    "    workbook_title = 'w.e ' + date_end + t\n",
    "else:\n",
    "    workbook_title = 'no title'\n",
    "    \n",
    "print(workbook_title)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adafruit_id = 15556579"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define page_clean function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_guides = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "LOWER(url) AS url\n",
    "FROM learn_guides\n",
    "''', db)\n",
    "\n",
    "col_fix(learn_guides)\n",
    "\n",
    "learn_guides['url clean'] = learn_guides['url'].str.replace('https://learn.adafruit.com','')\n",
    "\n",
    "# list of tuples vs dictionary, of regex:value pairs\n",
    "# https://stackoverflow.com/questions/33343680/can-a-regular-expression-be-used-as-a-key-in-a-dictionary\n",
    "\n",
    "def page_clean(x):\n",
    "    \n",
    "    d = [\n",
    "         ('category|categories','categories'),\n",
    "         ('^\\/search|^\\/\\?s=|^\\/\\?q=','search'),\n",
    "         ('^\\/$','main page'),\n",
    "         ('checkout','checkout'),\n",
    "         ('^\\/product','product'),\n",
    "         ('wishlist','wishlists'),\n",
    "         ('account_history_info','account history info'),\n",
    "         ('galleries','galleries'),\n",
    "         ('back_in_stock_notification_subscribe','back in stock subscribe'),\n",
    "         ('manage_subscription','manage subscription'),\n",
    "         ('^\\/[0-9]{4}\\/[0-9]{2}\\/[0-9]{2}','blog post'),\n",
    "         ('^\\/assets','assets page'),\n",
    "         ('^\\/author', 'author page'),\n",
    "         ('^\\/tag','tag page')\n",
    "        ]\n",
    "        \n",
    "    # find learn guides    \n",
    "    if any(l in x for l in learn_guides['url clean'].tolist()):\n",
    "        return 'learn guide'\n",
    "        \n",
    "    # if the page title is \"/some_word\" or \"/some_word/\" and not just \"/\" or \"/some_number\"\n",
    "        # then take that single word\n",
    "    elif re.search(r'^/[a-z0-9_]*/*$', x) and re.search('^\\/$', x) == None and re.search('^\\/[0-9]*/*$', x) == None:\n",
    "        return x.replace('/','')\n",
    "    \n",
    "    # go through regex dict\n",
    "    else:\n",
    "        for k,v in d:\n",
    "            if re.search(k, x):\n",
    "                return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define get_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trend(array):\n",
    "    \n",
    "    x = range(len(array))\n",
    "    y = array\n",
    "    \n",
    "    z = np.polyfit(x,y,1)\n",
    "    slope = z[0]\n",
    "    intercept = z[1]\n",
    "    \n",
    "    return slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****\n",
    "# Check out all GA hostnames\n",
    "*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hostnames = get_ga(15556579, # www.adafruit.com account ID\n",
    "                  one_week_ago,\n",
    "                  date_end,\n",
    "                  ['hostname'],\n",
    "                  ['pageviews'],\n",
    "                  None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a137fdf28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g1 = hostnames.groupby('hostname')[['pageviews']].sum()\n",
    "g1.sort_values('pageviews', ascending = False, inplace = True)\n",
    "\n",
    "g1['% of total'] = g1['pageviews']/g1['pageviews'].sum()\n",
    "g1['% running sum'] = g1['% of total'].cumsum()\n",
    "\n",
    "q = 0.95\n",
    "g2 = g1[g1['% running sum'] <= q]\n",
    "\n",
    "g2['pageviews'].plot(figsize = (10,5),\n",
    "                     kind = 'bar', \n",
    "                     color = 'purple',\n",
    "                     edgecolor = 'black',\n",
    "                     alpha = 0.75,\n",
    "                     lw = 3,\n",
    "                     rot = 45,\n",
    "                     title = 'top {:,.0f}% of hostnames by pageviews during the most recent week'.format(q*100))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define hostname filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hostname==www.adafruit.com', 'or', 'hostname==learn.adafruit.com']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hostname_ls = ['www.adafruit.com','learn.adafruit.com']\n",
    "\n",
    "hostname_filter = hostname_ls.copy()\n",
    "hostname_filter = ['hostname==' + x for x in hostname_filter]\n",
    "\n",
    "for n in np.arange(1,len(hostname_ls) + 1):\n",
    "    if n%2 != 0:\n",
    "        hostname_filter.insert(n,'or')\n",
    "        \n",
    "hostname_filter        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****\n",
    "# Overall GA stats\n",
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = dt.datetime.now()\n",
    "   \n",
    "overall_super_main = get_ga(adafruit_id,\n",
    "                            three_months_ago,\n",
    "                            date_end,\n",
    "\n",
    "                            ['hostname',\n",
    "                             'date'], \n",
    "\n",
    "                            ['sessions',\n",
    "                             'searchSessions',\n",
    "                             'users',\n",
    "                             'searchUniques', # Total number of unique keywords from internal searches within a session. For example, if \"shoes\" was searched for 3 times in a session, it would be counted only once.\n",
    "                             'searchExits', # The number of exits on the site that occurred following a search result from the site's internal search feature.\n",
    "                             'pageviews'],\n",
    "\n",
    "                            hostname_filter)\n",
    "\n",
    "e = dt.datetime.now()\n",
    "print(e-s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_main = overall_super_main.copy()\n",
    "\n",
    "overall_main.rename(columns = {'search sessions':'sessions with search',\n",
    "                               'search uniques':'unique searches'}, inplace = True)\n",
    "\n",
    "# get week ending, using my function\n",
    "df = jb_week_ending(overall_main, 'date', 'Sunday')\n",
    "overall_main = pd.merge(overall_main, df, on = 'date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d1 = overall_main['date'].min().date()\n",
    "d2 = overall_main['date'].max().date()\n",
    "days = (pd.to_datetime(d2) - pd.to_datetime(d1)).days\n",
    "\n",
    "for hostname in set(overall_main['hostname']):\n",
    "    \n",
    "    report_dict[hostname + ' overall period'] = '%s to %s (%i days).' % (d1,d2,days)\n",
    "    \n",
    "#=========================\n",
    "# get data by report_type\n",
    "#=========================\n",
    "    \n",
    "    a1 = overall_main[overall_main['hostname'] == hostname]\n",
    "    a2 = a1.groupby(report_type)[['users',\n",
    "                                  'sessions',\n",
    "                                  'sessions with search',\n",
    "                                  'unique searches',\n",
    "                                  'search exits',\n",
    "                                  'pageviews']].sum()\n",
    "\n",
    "    a2['% of sessions with search'] = a2['sessions with search']/a2['sessions']\n",
    "    a2['avg search per search session'] = a2['unique searches']/a2['sessions with search']\n",
    "    a2['avg pageview per session'] = a2['pageviews']/a2['sessions']\n",
    "    a2['search exits as % of unique searches'] = a2['search exits']/a2['unique searches']\n",
    "    a2.fillna(0, inplace = True)\n",
    "    \n",
    "    old_cols = a2.columns.tolist()\n",
    "\n",
    "    cols1 = sorted([x for x in old_cols if 'search' in x], reverse = True)\n",
    "    cols2 = sorted([x for x in old_cols if 'pageview' in x], reverse = True)\n",
    "    cols3 = [x for x in old_cols if x not in cols1 + cols2]\n",
    "\n",
    "    new_cols = cols3 + cols1 + cols2\n",
    "    a2 = a2[new_cols]\n",
    "    \n",
    "    report_dict[hostname + ' overall over time'] = a2\n",
    "    \n",
    "#=========================\n",
    "# get confidence interval\n",
    "#=========================    \n",
    "    \n",
    "    conf = jb_conf(a2).loc[:'upper'].T\n",
    "    \n",
    "    report_dict[hostname + ' overall conf'] = conf\n",
    "    \n",
    "#=========================\n",
    "# get trend\n",
    "#=========================    \n",
    "    \n",
    "    a3 = a2.T\n",
    "    vals = a3.values\n",
    "    ls = []\n",
    "    for i in range(len(vals)):\n",
    "        slope = get_trend(vals[i])\n",
    "        results = 'up' if slope > 0 else 'down'\n",
    "        ls.append(results)    \n",
    "        \n",
    "#=========================\n",
    "# isolate most recent week\n",
    "#=========================    \n",
    "\n",
    "    a4 = pd.DataFrame(a3.iloc[:,-1])\n",
    "    a4.columns = ['week ending ' + x for x in a4.columns]\n",
    "    \n",
    "#=========================\n",
    "# add in avg and trend\n",
    "#=========================    \n",
    "\n",
    "    a4['average'] = conf['mean']\n",
    "    a4['week to week trend'] = ls\n",
    "    \n",
    "#=========================\n",
    "# add in confidence interval results\n",
    "#=========================    \n",
    "\n",
    "    ls = []\n",
    "    for index, row in a4.iterrows():\n",
    "        lower, mean, upper = conf.loc[index].values\n",
    "        val = row.values[0]\n",
    "        if np.logical_and(val >= lower, val <= upper):\n",
    "            res = 'normal'\n",
    "        else:\n",
    "            if val < lower:\n",
    "                res = 'BELOW normal'\n",
    "            else:\n",
    "                res = 'ABOVE normal'\n",
    "                \n",
    "        ls.append(res)\n",
    "        \n",
    "    a4['comment on current value'] = ls\n",
    "    \n",
    "#=========================\n",
    "# add to dict\n",
    "#=========================        \n",
    "       \n",
    "    report_dict[hostname + ' overall current'] = a4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'www.adafruit.com'\n",
    "\n",
    "print('%s data is from %s' % (a,report_dict[a + ' overall period']))\n",
    "\n",
    "df = report_dict['www.adafruit.com overall current']\n",
    "\n",
    "ls1 = df.index.tolist()\n",
    "ls2 = ['{:,.0f}','{:,.0f}','{:,.0f}','{:,.0f}','{:,.1f}%','{:,.0f}','{:,.1f}','{:,.1f}%','{:,.0f}','{:,.1f}']\n",
    "\n",
    "ls3 = []\n",
    "for l in ls2:\n",
    "    if '%' in l:\n",
    "        ls3.append(100)\n",
    "    else:\n",
    "        ls3.append(1)\n",
    "        \n",
    "d = {z[0]:list(z[1:]) for z in zip(ls1,ls2,ls3)}\n",
    "\n",
    "def f(df):\n",
    "    \n",
    "    df2 = df.copy()\n",
    "    \n",
    "    fmt = d[df.name][0]\n",
    "    mult = d[df.name][1]\n",
    "    \n",
    "    for i in range(2):\n",
    "        df2.iloc[i] = fmt.format(df2.iloc[i] * mult)\n",
    "       \n",
    "    return df2\n",
    "\n",
    "df.apply(f, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****\n",
    "# GA event actions data\n",
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = dt.datetime.now()\n",
    "  \n",
    "hostname_filter2 = hostname_filter + ['and', 'eventCategory==Ecommerce']\n",
    "\n",
    "event_actions_super_main = get_ga(adafruit_id,\n",
    "                                  three_months_ago,\n",
    "                                  date_end,\n",
    "\n",
    "                                  ['date',\n",
    "                                  'hostname',\n",
    "                                  'eventAction'], \n",
    "\n",
    "                                  ['totalEvents'],\n",
    "\n",
    "                                  hostname_filter2)\n",
    "        \n",
    "e = dt.datetime.now()\n",
    "print(e-s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_actions_main = event_actions_super_main.copy()\n",
    "\n",
    "event_actions_main.rename(columns = {'search sessions':'sessions with search',\n",
    "                                     'search uniques':'unique searches'}, inplace = True)\n",
    "\n",
    "# get week ending, using my function\n",
    "df = jb_week_ending(event_actions_main, 'date', 'Sunday')\n",
    "event_actions_main = pd.merge(event_actions_main, df, on = 'date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('list of event actions')\n",
    "sorted(list(set(event_actions_main['event action'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = event_actions_main['date'].min().date()\n",
    "d2 = event_actions_main['date'].max().date()\n",
    "days = (pd.to_datetime(d2) - pd.to_datetime(d1)).days\n",
    "\n",
    "drop = ['add+impression','ghostery']\n",
    "\n",
    "for hostname in set(event_actions_main['hostname']):\n",
    "    \n",
    "    report_dict[hostname + ' event actions period'] = '%s to %s (%i days).' % (d1,d2,days)\n",
    "\n",
    "    a1 = event_actions_main[~event_actions_main['event action'].isin(drop)].groupby([report_type,'event action'])[['total events']].sum().unstack().fillna(0)\n",
    "    a1.columns = a1.columns.droplevel(0)\n",
    "    a1.sort_values(a1.index[-1], ascending = False, axis = 1, inplace = True)\n",
    "    \n",
    "#=========================    \n",
    "# get event actions as a % of sessions\n",
    "#=========================\n",
    "\n",
    "    event_actions_var = 'users'\n",
    "    event_actions_var_n = 100\n",
    "    a2 = a1.div(report_dict[hostname + ' overall over time'][event_actions_var].values, axis = 0)\n",
    "    a2 = a2 * event_actions_var_n\n",
    "    \n",
    "    report_dict[hostname + ' event actions per ' + event_actions_var + ' over time'] = a2 \n",
    "    \n",
    "#=========================\n",
    "# get confidence interval\n",
    "#=========================    \n",
    "    \n",
    "    conf = jb_conf(a2).loc[:'upper'].T\n",
    "    \n",
    "    report_dict[hostname + ' event actions per ' + event_actions_var + ' conf'] = conf\n",
    "    \n",
    "#=========================\n",
    "# get trend\n",
    "#=========================    \n",
    "    \n",
    "    a3 = a2.T\n",
    "    vals = a3.values\n",
    "    ls = []\n",
    "    for i in range(len(vals)):\n",
    "        slope = get_trend(vals[i])\n",
    "        results = 'up' if slope > 0 else 'down'\n",
    "        ls.append(results)    \n",
    "        \n",
    "#=========================\n",
    "# isolate most recent week\n",
    "#=========================    \n",
    "\n",
    "    a4 = pd.DataFrame(a3.iloc[:,-1])\n",
    "    a4.columns = ['week ending ' + x for x in a4.columns]\n",
    "    \n",
    "#=========================\n",
    "# add in avg and trend\n",
    "#=========================    \n",
    "\n",
    "    a4['average'] = conf['mean']\n",
    "    a4['week to week trend'] = ls\n",
    "    \n",
    "#=========================\n",
    "# add in confidence interval results\n",
    "#=========================    \n",
    "\n",
    "    ls = []\n",
    "    for index, row in a4.iterrows():\n",
    "        lower, mean, upper = conf.loc[index].values\n",
    "        val = row.values[0]\n",
    "        if np.logical_and(val >= lower, val <= upper):\n",
    "            res = 'normal'\n",
    "        else:\n",
    "            if val < lower:\n",
    "                res = 'BELOW normal'\n",
    "            else:\n",
    "                res = 'ABOVE normal'\n",
    "                \n",
    "        ls.append(res)\n",
    "        \n",
    "    a4['comment on current value'] = ls\n",
    "    \n",
    "#=========================\n",
    "# add to dict\n",
    "#=========================        \n",
    "       \n",
    "    report_dict[hostname + ' event actions per ' + event_actions_var + ' current'] = a4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('event actions per %i %s\\n' % (event_actions_var_n, event_actions_var))\n",
    "for h in hostname_ls:\n",
    "    try:\n",
    "        print(h)\n",
    "        fmt = ['n2','n2',0,0]\n",
    "        display(report_dict[h + ' event actions per ' + event_actions_var + ' current'].format_(fmt))\n",
    "        print('\\n')\n",
    "    except:\n",
    "        print('\\nno data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****\n",
    "# Get exit page data\n",
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = dt.datetime.now()\n",
    "    \n",
    "exit_super_main = get_ga(adafruit_id,\n",
    "                         four_weeks_ago,\n",
    "                         date_end,\n",
    "\n",
    "                         ['date',\n",
    "                          'hostname',\n",
    "                          'exitPagePath'], \n",
    "\n",
    "                         ['pageviews'],\n",
    " \n",
    "                         hostname_filter)\n",
    "\n",
    "e = dt.datetime.now()\n",
    "print(e-s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit_main = exit_super_main.copy()\n",
    "\n",
    "exit_main.rename(columns = {'exit page path':'exit page'}, inplace = True)\n",
    "\n",
    "# get week ending, using my function\n",
    "df = jb_week_ending(exit_main, 'date', 'Sunday')\n",
    "exit_main = pd.merge(exit_main, df, on = 'date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up exit page names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = dt.datetime.now()\n",
    "\n",
    "exit_main['exit page'] = exit_main['exit page'].str.strip()\n",
    "exit_main['exit page clean'] = exit_main['exit page'].apply(page_clean)\n",
    "\n",
    "e = dt.datetime.now()\n",
    "print(e-s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls = exit_main[exit_main['exit page clean'].isnull()]\n",
    "prop = len(nulls)/len(exit_main)\n",
    "\n",
    "if prop >= .06:\n",
    "    raise ValueError('check your nulls')\n",
    "else:\n",
    "    print('{:,.1f}% nulls our of {:,.0f} lines\\nfill these'.format(prop * 100, len(exit_main)))\n",
    "    exit_main['exit page clean'].fillna(exit_main['exit page'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = exit_main['date'].min().date()\n",
    "d2 = exit_main['date'].max().date()\n",
    "days = (pd.to_datetime(d2) - pd.to_datetime(d1)).days\n",
    "\n",
    "for hostname in set(exit_main['hostname']):\n",
    "    \n",
    "    report_dict[hostname + ' exit pages period'] = '%s to %s (%i days).' % (d1,d2,days)\n",
    "\n",
    "#=========================\n",
    "# aggregate data over entire period\n",
    "#=========================\n",
    "    \n",
    "    a = exit_main[exit_main['hostname'] == hostname].groupby('exit page clean')[['pageviews']].sum()\n",
    "    a.sort_values('pageviews', ascending = False, inplace = True)\n",
    "    a['% of total'] = a['pageviews']/a['pageviews'].sum()\n",
    "    a['% running sum'] = a['% of total'].cumsum()\n",
    "\n",
    "#=========================\n",
    "# get top X% and bottom 1-X%\n",
    "#=========================    \n",
    "    \n",
    "    q = 0.95\n",
    "    \n",
    "    top = a[a['% running sum'] <= q]\n",
    "    bottom = a[a['% running sum'] > q]\n",
    "    \n",
    "    report_dict[hostname + ' exit pages top'] = top\n",
    "    report_dict[hostname + ' exit pages bottom'] = bottom\n",
    "        \n",
    "    top_exits = top.index.tolist()\n",
    "\n",
    "#=========================\n",
    "# take top exits, group by period\n",
    "#=========================    \n",
    "\n",
    "    b1 = exit_main[(exit_main['hostname'] == hostname)\n",
    "                 & (exit_main['exit page clean'].isin(top_exits))].groupby([report_type,'exit page clean'])[['pageviews']].sum().unstack(1)\n",
    "    b1.columns = b1.columns.droplevel(0)\n",
    "    b1.sort_values(b1.index[-1], ascending = False, axis = 1, inplace = True)\n",
    "\n",
    "# dont use raw counts, use \"exits as % of pageviews\", below\n",
    "# if some page has more views it could have more exits\n",
    "# raw counts will be misleading, while % won't be \n",
    "       \n",
    "#=========================\n",
    "# exits as % of pageviews\n",
    "#=========================    \n",
    "\n",
    "    total_pageviews = report_dict[hostname + ' overall over time'].loc[b1.index][['pageviews']]\n",
    "    total_pageviews.columns = ['total']    \n",
    "\n",
    "    b2 = b1.div(total_pageviews.values.flatten(), axis = 0)\n",
    "    \n",
    "    report_dict[hostname + ' exit pages % over time'] = b2\n",
    "    \n",
    "#=========================\n",
    "# get confidence interval\n",
    "#=========================    \n",
    "\n",
    "    conf = jb_conf(b2).loc[:'upper'].T\n",
    "    \n",
    "    report_dict[hostname + ' exit pages % conf'] = conf\n",
    "    \n",
    "#=========================\n",
    "# isolate most recent week\n",
    "#=========================    \n",
    "\n",
    "    b3 = b2.T.iloc[:,-1:]\n",
    "    b3.columns = ['week ending ' + x for x in b3.columns]   \n",
    "    \n",
    "    b3['average'] = conf['mean']\n",
    "    \n",
    "    b3['% running sum'] = b3.iloc[:,0].cumsum()\n",
    "    \n",
    "#=========================\n",
    "# get trend\n",
    "#=========================    \n",
    "    \n",
    "    vals = b2.T.values\n",
    "    ls = []\n",
    "    for i in range(len(vals)):\n",
    "        slope = get_trend(vals[i])\n",
    "        results = 'up' if slope > 0 else 'down'\n",
    "        ls.append(results)        \n",
    "        \n",
    "    b3['week to week trend'] = ls\n",
    "        \n",
    "#=========================\n",
    "# add in confidence interval results\n",
    "#=========================    \n",
    "\n",
    "    ls = []\n",
    "    for index, row in b3.iterrows():\n",
    "        lower, mean, upper = conf.loc[index].values\n",
    "        val = row.values[0]\n",
    "        if np.logical_and(val >= lower, val <= upper):\n",
    "            res = 'normal'\n",
    "        else:\n",
    "            if val < lower:\n",
    "                res = 'BELOW normal'\n",
    "            else:\n",
    "                res = 'ABOVE normal'\n",
    "                \n",
    "        ls.append(res)\n",
    "        \n",
    "    b3['comment on current value'] = ls       \n",
    "    \n",
    "    report_dict[hostname + ' exit pages % current'] = b3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('percentages are (count of exit pages) / (total pageviews)\\n')\n",
    "for h in hostname_ls:\n",
    "    print(h)\n",
    "    fmt = ['p1','p1','p1',0,0]\n",
    "    display(report_dict[h + ' exit pages % current'].format_(fmt))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****\n",
    "# GA search data\n",
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = dt.datetime.now()\n",
    "\n",
    "searches_super_main = get_ga(adafruit_id,\n",
    "                             four_weeks_ago,\n",
    "                             date_end,\n",
    "\n",
    "                             ['date',\n",
    "                              'searchKeyword',\n",
    "                              'searchKeywordRefinement',\n",
    "                              'hostname',\n",
    "                              'searchStartPage',\n",
    "\n",
    "                              # the page users immediately visited after performing an internal search on the site. This is usually the search results page.                 \n",
    "                              # this is always \"/search\", or \"/?q=\", etc, i.e. it doesn't give any meaningful info, so omit it\n",
    "                              #'searchDestinationPage', \n",
    "\n",
    "                              # the page that users visited after performing an internal search on the site.\n",
    "                              'searchAfterDestinationPage',\n",
    "                              'exitPagePath'], \n",
    "\n",
    "                             ['searchResultViews', # the number of times a search result page was viewed\n",
    "                              'searchRefinements'],\n",
    "\n",
    "                             hostname_filter)\n",
    "\n",
    "e = dt.datetime.now()\n",
    "print(e-s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add week ending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searches_main = searches_super_main.copy()\n",
    "\n",
    "# get week ending, using my function\n",
    "df = jb_week_ending(searches_main, 'date', 'Sunday')\n",
    "searches_main = pd.merge(searches_main, df, on = 'date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searches_main.rename(columns = {'search keyword refinement':'refined to',\n",
    "                                'search refinements':'refinements',\n",
    "                                'search result views':'search results',\n",
    "                                'search start page':'start page',\n",
    "                                'search after destination page':'page 01',\n",
    "                                'exit page path':'exit page'}, inplace = True)\n",
    "\n",
    "old_cols = list(searches_main.columns)\n",
    "new_cols = ['date',\n",
    "            'year and month',\n",
    "            'year and quarter',\n",
    "            'year',\n",
    "            'week ending',\n",
    "            'search keyword',\n",
    "            'search results',\n",
    "            'refined to',\n",
    "            'refinements',\n",
    "            'account id',\n",
    "            'hostname',\n",
    "            'start page',\n",
    "            'page 01',\n",
    "            'exit page']\n",
    "\n",
    "s1 = set(new_cols)\n",
    "s2 = set(old_cols)\n",
    "s3 = s1.symmetric_difference(s2)\n",
    "\n",
    "if len(s3) > 0:\n",
    "    print(s3)\n",
    "    raise ValueError('check ur columns')\n",
    "    \n",
    "else:\n",
    "    searches_main = searches_main[new_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up page results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_this = 'no'\n",
    "\n",
    "if do_this == 'yes':\n",
    "    s = dt.datetime.now()\n",
    "\n",
    "    cols = ['page 01','exit page']\n",
    "    for col in cols:\n",
    "        try:\n",
    "            searches_main[col + ' clean'].drop(axis = 1, inplace = True)\n",
    "        except:\n",
    "            searches_main[col + ' clean'] = searches_main[col].apply(page_clean)\n",
    "            searches_main[col + ' clean'].fillna(value = pd.np.nan, inplace = True)        \n",
    "            searches_main[col + ' clean'].fillna(searches_main['hostname'], inplace = True)\n",
    "\n",
    "    e = dt.datetime.now()\n",
    "    print(e-s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove top X% shortest and longest words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searches_main['keyword length'] = searches_main['search keyword'].str.len()\n",
    "\n",
    "print(searches_main['keyword length'].quantile(np.arange(0,1.05,0.05)))\n",
    "\n",
    "q = [0.05,0.95]\n",
    "\n",
    "searches_main.drop(searches_main[(searches_main['keyword length'] < searches_main['keyword length'].quantile(q[0]))\n",
    "             | (searches_main['keyword length'] > searches_main['keyword length'].quantile(q[1]))].index, inplace = True)\n",
    "\n",
    "searches_main.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# drop the length column\n",
    "searches_main.drop('keyword length',1,inplace = True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove words that are just numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_this = 'no'\n",
    "\n",
    "if do_this == 'yes':\n",
    "    a = len(searches_main[searches_main['search keyword'].str.isdigit()])/len(searches_main)\n",
    "    print('{:,.2f}% of lines contain search keywords which are only numbers\\nremove these'.format(a * 100))\n",
    "\n",
    "    searches_main.drop(searches_main[searches_main['search keyword'].str.isdigit()].index, inplace = True)\n",
    "    searches_main.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rate the similarity of strings\n",
    "* Use Jaccard Index: https://en.wikipedia.org/wiki/Jaccard_index\n",
    "* Or difflib.SequenceMatcher: http://epydoc.sourceforge.net/stdlib/difflib-module.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacc(a,b):\n",
    "    \n",
    "    s1 = set(a)\n",
    "    s2 = set(b)\n",
    "    inter = s1.intersection(s2)\n",
    "    union = s1.union(s2)\n",
    "    score = len(inter)/len(union)    \n",
    "    \n",
    "    return score\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def get_score(a,b):\n",
    "    \n",
    "    score1 = SequenceMatcher(a = a, b = b).ratio()\n",
    "    \n",
    "    s1 = set(a)\n",
    "    s2 = set(b)\n",
    "    inter = s1.intersection(s2)\n",
    "    union = s1.union(s2)\n",
    "    score2 = len(inter)/len(union)\n",
    "    \n",
    "    avg = np.mean([score1, score2])\n",
    "    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get part categories to use as top words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "categories = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "DISTINCT LOWER(categories_name) AS categories_name\n",
    "FROM categories_description\n",
    "''', db)\n",
    "\n",
    "col_fix(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rate all search keywords against category names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = dt.datetime.now()\n",
    "\n",
    "#searches_main['search keyword clean'] = [re.sub(r'([^\\s\\w.])+', '', x) for x in searches_main['search keyword']]\n",
    "#searches_main.drop(searches_main[searches_main['search keyword clean'] == ''].index, inplace = True)\n",
    "#searches_main.reset_index(drop = True, inplace = True)\n",
    "\n",
    "top_words = list(categories['categories name'])\n",
    "all_words = list(set(searches_main['search keyword']))\n",
    "\n",
    "ls = []\n",
    "for a in all_words:\n",
    "    score = 0\n",
    "    for t in top_words:\n",
    "        inter_score = jacc(a.replace(' ',''), t.replace(' ','')) # compare words without their whitespace\n",
    "        if inter_score > score:\n",
    "            score = inter_score\n",
    "            t2 = t\n",
    "    ls.append([t2,a,score])\n",
    "    \n",
    "cols = ['top word','search keyword','score']\n",
    "scores = pd.DataFrame(data = ls, columns = cols)\n",
    "\n",
    "e = dt.datetime.now()\n",
    "print(e-s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review test words and their scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "do_this = 'yes'\n",
    "\n",
    "test_words = ['arduino','raspberry pi','feather']\n",
    "\n",
    "scores_dict = {}\n",
    "for t in test_words:\n",
    "    scores_dict[t] = scores[scores['top word'] == t].sort_values('score', ascending = False)\n",
    "    \n",
    "    if do_this == 'yes':\n",
    "        \n",
    "        fmt = [0,0,'p1']\n",
    "        display(scores_dict[t].head(10).format_(fmt))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des = scores[['score']].describe().T\n",
    "fmt = ['n0','p1','n2','p1','p1','p1','p1','p1']\n",
    "des = des.format_(fmt).T\n",
    "des"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map top words to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['top word','score']:\n",
    "    searches_main[col] = searches_main['search keyword'].map(dict(zip(scores['search keyword'], scores[col])))\n",
    "\n",
    "cutoff = 0.40\n",
    "\n",
    "def top_word_clean(df):\n",
    "    if df['search keyword'].isdigit():\n",
    "        return 'number search'\n",
    "    else:\n",
    "        if pd.isnull(df['top word']) or df['score'] < cutoff:\n",
    "            return df['search keyword']\n",
    "        else:\n",
    "            return df['top word']\n",
    "        \n",
    "searches_main['top word'] = searches_main.apply(top_word_clean, axis = 1)\n",
    "\n",
    "if searches_main[searches_main['top word'].isnull()].empty == False:\n",
    "    raise VaueError('check your top_word nulls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d1 = searches_main['date'].min().date()\n",
    "d2 = searches_main['date'].max().date()\n",
    "days = (pd.to_datetime(d2) - pd.to_datetime(d1)).days\n",
    "\n",
    "N = 10\n",
    "      \n",
    "for hostname in list(set(searches_main['hostname'])):\n",
    "    \n",
    "    report_dict[hostname + ' search keyword period'] = '%s to %s (%i days).' % (d1,d2,days)    \n",
    "\n",
    "#=========================\n",
    "# by top word\n",
    "#=========================\n",
    "    \n",
    "    a1 = searches_main[searches_main['hostname'] == hostname]\n",
    "    a2 = a1.groupby('top word')[['search results']].sum()\n",
    "    a2.sort_values('search results', ascending = False, inplace = True)\n",
    "    a3 = a2.iloc[:N].copy()\n",
    "    \n",
    "    top_words = a3.index.tolist()\n",
    "    total1 = a1['search results'].sum()\n",
    "    \n",
    "    a3['% of \"hostname\"'] = a3['search results']/total1\n",
    "    a3['% of \"hostname\" running sum'] = a3['% of \"hostname\"'].cumsum()\n",
    "    \n",
    "    b1 = searches_main[(searches_main['hostname'] == hostname) & (searches_main['top word'].isin(top_words))]\n",
    "    b2 = b1.groupby(['top word', report_type])[['search results']].sum().unstack(1).fillna(0)\n",
    "    b2.columns = b2.columns.droplevel(0)    \n",
    "    b2 = b2.loc[top_words]\n",
    "    \n",
    "    vals = b2.values\n",
    "\n",
    "    ls = []\n",
    "    for i in range(len(vals)):\n",
    "        trend = get_trend(vals[i])\n",
    "        res = 'up' if trend > 0 else 'down'\n",
    "        ls.append(res)    \n",
    "        \n",
    "    a3['trending'] = ls\n",
    "    \n",
    "    report_dict[hostname + ' by top word'] = a3\n",
    "    \n",
    "#=========================\n",
    "# by keyword search\n",
    "#=========================    \n",
    "    \n",
    "    c1 = searches_main[(searches_main['hostname'] == hostname)\n",
    "                     & (searches_main['top word'].isin(top_words))]\n",
    "    c2 = c1.groupby(['top word','search keyword'])[['search results']].sum()\n",
    "    c3 = c2['search results'].groupby(level = 0, group_keys = False)\n",
    "    c4 = c3.apply(lambda x: x.sort_values(ascending = False).head(N))\n",
    "    c5 = pd.DataFrame(c4)\n",
    "    \n",
    "    total2 = a2.reset_index()\n",
    "    total2.rename(columns = {'search results':'total'}, inplace = True)    \n",
    "    \n",
    "    c6 = c5.reset_index().merge(total2, on = ['top word'])\n",
    "    c6['% of \"top words\"'] = c6['search results']/c6['total']\n",
    "    c6.sort_values(['total','search results'], ascending = [False,False], inplace = True)\n",
    "    c6.drop('total', 1, inplace = True)   \n",
    "    c7 = c6.set_index(['top word','search keyword'])\n",
    "    \n",
    "    report_dict[hostname + ' by search keyword'] = c7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = 'www.adafruit.com'\n",
    "show_this = 'yes'\n",
    "\n",
    "if show_this == 'no':\n",
    "\n",
    "    print('%s is from %s\\n' % (a, report_dict[a + ' search keyword period']))\n",
    "    print('by top word')\n",
    "    fmt = ['n0','p1','p2',0]\n",
    "    display(report_dict[a + ' by top word'].format_(fmt))\n",
    "\n",
    "    print('by keyword')\n",
    "    fmt = ['n0','p1']\n",
    "    display(report_dict[a + ' by search keyword'].format_(fmt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****\n",
    "# Search Term Refinements\n",
    "*****\n",
    "For \"number search\" only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for h in hostname_ls:\n",
    "\n",
    "    refine_main = searches_main[(searches_main['top word'] == 'number search')\n",
    "                              & (searches_main['hostname'] == h)].copy()\n",
    "    refine_main.reset_index(drop = True, inplace = True)\n",
    "    refine_main['refinements'] = np.where(refine_main['refinements'] == 0,1,refine_main['refinements'])\n",
    "\n",
    "    ls = refine_main.groupby('search keyword')[['search results']].sum().sort_values('search results', ascending = False).head(N).index.values.flatten().tolist()\n",
    "    refine_main.drop(refine_main[~refine_main['search keyword'].isin(ls)].index, inplace = True)\n",
    "    refine_main.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    a1 = refine_main.groupby(['search keyword','refined to'])[['refinements']].sum()\n",
    "    a2 = a1['refinements'].groupby(level = 0, group_keys = False)\n",
    "    a3 = a2.apply(lambda x: x.sort_values(ascending = False).head(5))\n",
    "    a4 = pd.DataFrame(a3)\n",
    "\n",
    "    a5 = a4.reset_index().set_index('search keyword').loc[ls].reset_index().set_index(['search keyword','refined to'])\n",
    "\n",
    "    t1 = a1.groupby(a1.index.get_level_values(0)).sum()\n",
    "    t1.columns = ['total refinements']\n",
    "    t2 = a1.join(t1)\n",
    "    t2['% of \"search keyword\"'] = t2['refinements']/t2['total refinements']\n",
    "\n",
    "    a6 = a5.join(t2[['% of \"search keyword\"']])    \n",
    "    \n",
    "    report_dict[h + ' number search refinements'] = a6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "do_this = 'yes'\n",
    "\n",
    "if do_this == 'yes':\n",
    "    for h in hostname_ls:\n",
    "        print(h)\n",
    "        fmt = ['n0','p1']\n",
    "        display(report_dict[h + ' number search refinements'].format_(fmt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***** \n",
    "# Excel Start\n",
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook = xlsxwriter.Workbook(csv_path + workbook_title + '.xlsx',\n",
    "                               {'nan_inf_to_errors': True,\n",
    "                               'strings_to_numbers': True})\n",
    "\n",
    "\n",
    "tabs = ['Summary',\n",
    "        'Overall Stats',\n",
    "        'Event Actions Stats',\n",
    "        'Exit Page Stats',\n",
    "        'Searches by Top Word',\n",
    "        'Searches by Keyword',\n",
    "        'Number Search Refinements',\n",
    "        'How We Define Top Words']\n",
    "\n",
    "#=========================\n",
    "# Formats\n",
    "#=========================\n",
    "\n",
    "colors = ['#343635',\n",
    "          '#2e4874',\n",
    "          '#7eaba4',\n",
    "          '#928c85',\n",
    "          '#347c83',\n",
    "          '#bfb9d6']\n",
    "colors = colors * 2\n",
    "\n",
    "title = workbook.add_format({'font_size':25,\n",
    "                             'font_name':'Arial (Bold)'})\n",
    "\n",
    "subtitle = workbook.add_format({'font_size':15,\n",
    "                                'font_name':'Arial (Bold)'})\n",
    "\n",
    "\n",
    "col_names = workbook.add_format({'font_name':'Arial (Bold)',\n",
    "                                 'font_color':'white',\n",
    "                                 'valign':'vcenter',\n",
    "                                 'align':'center',\n",
    "                                 'bg_color':colors[2],\n",
    "                                 'bottom':1,\n",
    "                                 'top':1,\n",
    "                                 'left':1,\n",
    "                                 'right':1})\n",
    "\n",
    "money = workbook.add_format({'num_format':'$#,##0', 'align':'center'})\n",
    "money2 = workbook.add_format({'num_format':'$#,##0.00', 'align':'center'})\n",
    "percent = workbook.add_format({'num_format':'0.0%', 'align':'center'})\n",
    "number = workbook.add_format({'num_format':'#,##0', 'align':'center'})\n",
    "number1 = workbook.add_format({'num_format':'#,##0.0', 'align':'center'})\n",
    "dummy = workbook.add_format({'font_color':'black', 'align':'center'})\n",
    "\n",
    "for tab in tabs:\n",
    "    workbook.add_worksheet(tab) # create each tab\n",
    "\n",
    "my_worksheets = {}\n",
    "for sht in workbook.worksheets():\n",
    "    my_worksheets[sht.get_name()] = sht # create dict like tab_name:worksheet_instance\n",
    "\n",
    "#=========================\n",
    "# Apply same formatting to each worksheet\n",
    "#=========================\n",
    "\n",
    "for k, v in my_worksheets.items():\n",
    "    sht = my_worksheets[k]\n",
    "    sht.write(0, 0,\n",
    "              k.title(),\n",
    "              title)\n",
    "    sht.write(1, 0,\n",
    "              workbook_title,\n",
    "              subtitle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = ['overall current',\n",
    "      'event actions per ' + event_actions_var + ' current',\n",
    "      'exit pages % current']    \n",
    "\n",
    "summary = {}\n",
    "df_len = []\n",
    "\n",
    "for h in hostname_ls:\n",
    "    hostname_summary = pd.DataFrame()\n",
    "    for l in ls:\n",
    "        df = report_dict[h + ' ' + l].copy()\n",
    "        df = df[['comment on current value']]\n",
    "        df.reset_index(inplace = True)\n",
    "        df.drop(df[df['comment on current value'] == 'normal'].index, inplace = True)\n",
    "        df.sort_values('comment on current value', inplace = True)\n",
    "        df.columns = ['metric','for week ending %s' % date_end]\n",
    "        \n",
    "        if df.empty == False:\n",
    "            hostname_summary = hostname_summary.append(df, ignore_index = True, sort = False)\n",
    "    \n",
    "    hostname_summary.sort_values('for week ending %s' % date_end, inplace = True)\n",
    "    hostname_summary['metric'] = hostname_summary['metric'].str.title()\n",
    "    hostname_summary.columns = hostname_summary.columns.str.title()\n",
    "    \n",
    "    df_len.append(len(hostname_summary))\n",
    "    \n",
    "    summary[h + ' website metrics'] = hostname_summary\n",
    "    \n",
    "summary2 = {}    \n",
    "for k in summary.keys():\n",
    "\n",
    "    df = report_dict[k.split(' ')[0] + ' by top word'].copy()\n",
    "    df = df[['trending']]\n",
    "    df.sort_values('trending', ascending = False, inplace = True)\n",
    "    df.reset_index(inplace = True)\n",
    "    df.rename(columns = {'top word':'search keyword'}, inplace = True)\n",
    "    df.columns = df.columns.str.title()\n",
    "    \n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].str.title()    \n",
    "        \n",
    "    summary2[k + ' search keywords'] = df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sht = my_worksheets['Summary']\n",
    "\n",
    "start_row = 3\n",
    "start_col = 0\n",
    "\n",
    "df_len = []\n",
    "\n",
    "for k in summary.keys():\n",
    "    \n",
    "    df = summary[k]\n",
    "    df_len.append(len(df))\n",
    "    \n",
    "    sht.write(start_row,\n",
    "             start_col,\n",
    "             k.split(' ')[0].title(),\n",
    "             subtitle)\n",
    "    \n",
    "    sht.write(start_row + 1,\n",
    "             start_col,\n",
    "             'Website Metrics',\n",
    "             subtitle)    \n",
    "            \n",
    "    for i in range(len(df.columns)):        \n",
    "        sht.write(start_row + 2,\n",
    "                 start_col + i,\n",
    "                 df.columns[i],\n",
    "                 col_names)\n",
    "                        \n",
    "        for j in range(len(df)):                        \n",
    "            sht.write(start_row + 3 + j,\n",
    "                     start_col + i,\n",
    "                     df.iloc[j,i],\n",
    "                     fmt)\n",
    "        \n",
    "    start_col += len(df.columns) + 2    \n",
    "    \n",
    "start_row = np.max(df_len) + 6\n",
    "start_col = 0    \n",
    "\n",
    "for k in summary2.keys():\n",
    "    \n",
    "    df = summary2[k]\n",
    "    \n",
    "    sht.write(start_row + 1,\n",
    "              start_col,\n",
    "              'Search Keywords',\n",
    "              subtitle)\n",
    "            \n",
    "    for i in range(len(df.columns)):\n",
    "               \n",
    "        sht.write(start_row + 2,\n",
    "                 start_col + i,\n",
    "                 df.columns[i],\n",
    "                 col_names)\n",
    "                \n",
    "        for j in range(len(df)):                        \n",
    "            sht.write(start_row + 3 + j,\n",
    "                     start_col + i,\n",
    "                     df.iloc[j,i],\n",
    "                     fmt)\n",
    "        \n",
    "    start_col += len(df.columns) + 2\n",
    "\n",
    "\n",
    "c = 30\n",
    "sht.set_column(0,1,c)\n",
    "sht.set_column(4,5,c)    \n",
    "\n",
    "'''\n",
    "text = open('/Users/jarad/Fake Folder/New Products/Recurring/Algolia Searches Report/Docs/Written Summary.txt', 'r').read()\n",
    "options = {'width': 510,\n",
    "           'height': 400}\n",
    "\n",
    "start_row = 3\n",
    "start_col = 8\n",
    "\n",
    "sht.write(start_row, start_col, 'Written Summary', subtitle)\n",
    "sht.insert_textbox(start_row + 1,\n",
    "                   start_col,\n",
    "                   text,\n",
    "                   options)    \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sht = my_worksheets['Overall Stats']\n",
    "\n",
    "fmts = {'Users':number,\n",
    "       'Sessions':number,\n",
    "       'Unique Searches':number,\n",
    "       'Sessions With Search':number,\n",
    "       'Search Exits As % Of Unique Searches':percent,\n",
    "       'Search Exits':number,\n",
    "       'Avg Search Per Search Session':number1,\n",
    "       '% Of Sessions With Search':percent,\n",
    "       'Pageviews':number,\n",
    "       'Avg Pageview Per Session':number1}\n",
    "\n",
    "keys = []\n",
    "for k in report_dict.keys():\n",
    "    if 'overall current' in k:\n",
    "        keys.append(k)\n",
    "keys = sorted(keys)[::-1]        \n",
    "\n",
    "start_row = 3\n",
    "start_col = 0\n",
    "\n",
    "sht.write(start_row - 1,\n",
    "          start_col,\n",
    "         'Data is from ' + report_dict[k.split(' ')[0] + ' overall period'])\n",
    "        \n",
    "for k in keys:\n",
    "    \n",
    "    df = report_dict[k].copy()\n",
    "    df.reset_index(inplace = True)\n",
    "    df.rename(columns = {'index':'metric'}, inplace = True)\n",
    "\n",
    "    df.columns = df.columns.str.title()\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'O':\n",
    "            df[col] = df[col].str.title()\n",
    "            \n",
    "    sht.write(start_row + 1,\n",
    "             start_col,\n",
    "             k.split(' ')[0].title(),\n",
    "             subtitle)\n",
    "            \n",
    "    for i in range(len(df.columns)):\n",
    "        \n",
    "        col_width = []        \n",
    "        \n",
    "        sht.write(start_row + 2,\n",
    "                 start_col + i,\n",
    "                 df.columns[i],\n",
    "                 col_names)\n",
    "        \n",
    "        col_width.append(len(df.columns[i]))\n",
    "                \n",
    "        for j in range(len(df)):            \n",
    "            \n",
    "            if df.columns[i] in ['Week Ending %s' % date_end,'Average']:\n",
    "                fmt = fmts[df.iloc[j]['Metric']]\n",
    "            else:\n",
    "                fmt = dummy            \n",
    "            \n",
    "            sht.write(start_row + 3 + j,\n",
    "                     start_col + i,\n",
    "                     df.iloc[j,i],\n",
    "                     fmt)\n",
    "            \n",
    "            col_width.append(len(str(df.iloc[j,i])))\n",
    "            \n",
    "        sht.set_column(start_col + i,\n",
    "                       start_col + i,\n",
    "                       np.max(col_width) + 1)\n",
    "        \n",
    "    start_col += len(df.columns) + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event Actions Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sht = my_worksheets['Event Actions Stats']\n",
    "\n",
    "keys = []\n",
    "for k in report_dict.keys():\n",
    "    if 'event actions per ' + event_actions_var + ' current' in k:\n",
    "        keys.append(k)\n",
    "keys = sorted(keys)[::-1]        \n",
    "        \n",
    "start_row = 3\n",
    "start_col = 0       \n",
    "\n",
    "sht.write(start_row - 1,\n",
    "          start_col,\n",
    "         'Data is from ' + report_dict[k.split(' ')[0] + ' event actions period'] + ' Data shows event actions per ' + str(event_actions_var_n) + ' ' + event_actions_var + '.')\n",
    "        \n",
    "for k in keys:\n",
    "    \n",
    "    df = report_dict[k].copy()\n",
    "    df.reset_index(inplace = True)\n",
    "\n",
    "    df.columns = df.columns.str.title()\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'O':\n",
    "            df[col] = df[col].str.title()        \n",
    "            \n",
    "    sht.write(start_row + 1,\n",
    "              start_col,\n",
    "              k.split(' ')[0].title(),\n",
    "              subtitle)\n",
    "                \n",
    "    for i in range(len(df.columns)):\n",
    "        \n",
    "        col_width = []        \n",
    "        \n",
    "        sht.write(start_row + 2,\n",
    "                 start_col + i,\n",
    "                 df.columns[i],\n",
    "                 col_names)\n",
    "        \n",
    "        col_width.append(len(df.columns[i]))\n",
    "                \n",
    "        for j in range(len(df)):            \n",
    "            \n",
    "            if df.columns[i] in ['Week Ending %s' % date_end,'Average']:\n",
    "                fmt = number1\n",
    "            else:\n",
    "                fmt = dummy            \n",
    "            \n",
    "            sht.write(start_row + 3 + j,\n",
    "                     start_col + i,\n",
    "                     df.iloc[j,i],\n",
    "                     fmt)\n",
    "            \n",
    "            col_width.append(len(str(df.iloc[j,i])))\n",
    "            \n",
    "        sht.set_column(start_col + i,\n",
    "                       start_col + i,\n",
    "                       np.max(col_width) + 1)\n",
    "        \n",
    "    start_col += len(df.columns) + 2    \n",
    "    \n",
    "text = open('/Users/jarad/Fake Folder/New Products/Recurring/Algolia Searches Report/Docs/Event Actions Key.txt', 'r').read()\n",
    "options = {'width': 733,\n",
    "           'height': 250}\n",
    "\n",
    "sht.insert_textbox(len(df) + 8,\n",
    "                   0,\n",
    "                   text,\n",
    "                   options)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exit Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sht = my_worksheets['Exit Page Stats']\n",
    "\n",
    "keys = []\n",
    "for k in report_dict.keys():\n",
    "    if 'exit pages % current' in k:\n",
    "        keys.append(k)\n",
    "keys = sorted(keys)[::-1]        \n",
    "        \n",
    "start_row = 3\n",
    "start_col = 0       \n",
    "\n",
    "sht.write(start_row - 1,\n",
    "          start_col,\n",
    "         'Data is from ' + report_dict[k.split(' ')[0] + ' exit pages period'] + ' Percentages = (exit page count) / (total exit page count). Data includes top 95% per hostname.')\n",
    "        \n",
    "for k in keys:\n",
    "    \n",
    "    df = report_dict[k].copy()\n",
    "    df.reset_index(inplace = True)\n",
    "    df.rename(columns = {'exit page clean':'exit page'}, inplace = True)\n",
    "\n",
    "    df.columns = df.columns.str.title()\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'O':\n",
    "            df[col] = df[col].str.title()        \n",
    "            \n",
    "    sht.write(start_row + 1,\n",
    "              start_col,\n",
    "              k.split(' ')[0].title(),\n",
    "              subtitle)\n",
    "                \n",
    "    for i in range(len(df.columns)):\n",
    "        \n",
    "        col_width = []        \n",
    "        \n",
    "        sht.write(start_row + 2,\n",
    "                 start_col + i,\n",
    "                 df.columns[i],\n",
    "                 col_names)\n",
    "        \n",
    "        col_width.append(len(df.columns[i]))\n",
    "                \n",
    "        for j in range(len(df)):            \n",
    "            \n",
    "            if df.columns[i] in ['Week Ending %s' % date_end,'Average','% Running Sum']:\n",
    "                fmt = percent\n",
    "            else:\n",
    "                fmt = dummy            \n",
    "            \n",
    "            sht.write(start_row + 3 + j,\n",
    "                     start_col + i,\n",
    "                     df.iloc[j,i],\n",
    "                     fmt)\n",
    "            \n",
    "            col_width.append(len(str(df.iloc[j,i])))\n",
    "            \n",
    "        sht.set_column(start_col + i,\n",
    "                       start_col + i,\n",
    "                       np.max(col_width) + 1)\n",
    "        \n",
    "    start_col += len(df.columns) + 2    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searches By Top Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sht = my_worksheets['Searches by Top Word']\n",
    "\n",
    "start_row = 3\n",
    "start_col = 0       \n",
    "\n",
    "keys = []\n",
    "for k in report_dict.keys():\n",
    "    if ' by top word' in k:\n",
    "        keys.append(k)\n",
    "keys = sorted(keys)[::-1]        \n",
    "        \n",
    "fmts = {'Top Word':dummy,\n",
    "        'Search Results':number,\n",
    "        '% Of \"Hostname\"':percent,\n",
    "        '% Of \"Hostname\" Running Sum':percent,\n",
    "        'Trending':dummy}        \n",
    "        \n",
    "sht.write(start_row - 1,\n",
    "          start_col,\n",
    "         'Data is from ' + report_dict[k.split(' ')[0] + ' search keyword period'] + ' Data shows top ten per hostname.')\n",
    "\n",
    "for k in keys:\n",
    "    \n",
    "    df = report_dict[k].copy()\n",
    "    df.reset_index(inplace = True)\n",
    "\n",
    "    df.columns = df.columns.str.title()\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'O':\n",
    "            df[col] = df[col].str.title()        \n",
    "            \n",
    "    sht.write(start_row + 1,\n",
    "              start_col,\n",
    "              k.split(' ')[0].title(),\n",
    "              subtitle)\n",
    "                \n",
    "    for i in range(len(df.columns)):\n",
    "        \n",
    "        col_width = []        \n",
    "        \n",
    "        sht.write(start_row + 2,\n",
    "                 start_col + i,\n",
    "                 df.columns[i],\n",
    "                 col_names)\n",
    "        \n",
    "        col_width.append(len(df.columns[i]))\n",
    "                \n",
    "        for j in range(len(df)):                        \n",
    "            sht.write(start_row + 3 + j,\n",
    "                     start_col + i,\n",
    "                     df.iloc[j,i],\n",
    "                     fmts[df.columns[i]])\n",
    "            \n",
    "            col_width.append(len(str(df.iloc[j,i])))\n",
    "            \n",
    "        sht.set_column(start_col + i,\n",
    "                       start_col + i,\n",
    "                       np.max(col_width) + 1)\n",
    "        \n",
    "    start_col += len(df.columns) + 2    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searches by Keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sht = my_worksheets['Searches by Keyword']\n",
    "\n",
    "fmts = {'Top Word':dummy,\n",
    "       'Search Keyword':dummy,\n",
    "       'Search Results':number,\n",
    "       '% Of \"Top Words\"':percent}\n",
    "\n",
    "start_row = 3\n",
    "start_col = 0       \n",
    "\n",
    "keys = []\n",
    "for k in report_dict.keys():\n",
    "    if ' by search keyword' in k:\n",
    "        keys.append(k)\n",
    "keys = sorted(keys)[::-1]        \n",
    "        \n",
    "sht.write(start_row - 1,\n",
    "          start_col,\n",
    "         'Data is from ' + report_dict[k.split(' ')[0] + ' search keyword period'])        \n",
    "        \n",
    "for k in keys:\n",
    "    \n",
    "    df = report_dict[k].copy()\n",
    "    df.reset_index(inplace = True)\n",
    "\n",
    "    df.columns = df.columns.str.title()\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'O':\n",
    "            df[col] = df[col].str.title()       \n",
    "            \n",
    "    sht.write(start_row + 1,\n",
    "              start_col,\n",
    "              k.split(' ')[0].title(),\n",
    "              subtitle)            \n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        if i%10 != 0:\n",
    "            df.loc[i, 'Top Word'] = ''    \n",
    "\n",
    "    for i in range(len(df.columns)):\n",
    "        \n",
    "        col_width = []        \n",
    "        \n",
    "        sht.write(start_row + 2,\n",
    "                 start_col + i,\n",
    "                 df.columns[i],\n",
    "                 col_names)\n",
    "        \n",
    "        col_width.append(len(df.columns[i]))\n",
    "                \n",
    "        for j in range(len(df)):                        \n",
    "            sht.write(start_row + 3 + j,\n",
    "                     start_col + i,\n",
    "                     df.iloc[j,i],\n",
    "                     fmts[df.columns[i]])\n",
    "            \n",
    "            col_width.append(len(str(df.iloc[j,i])))\n",
    "                        \n",
    "        sht.set_column(start_col + i,\n",
    "                       start_col + i,\n",
    "                       np.max(col_width) + 1)\n",
    "        \n",
    "    start_col += len(df.columns) + 2                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number Search Refinements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sht = my_worksheets['Number Search Refinements']\n",
    "\n",
    "fmts = {'Search Keyword':dummy,\n",
    "        'Refined To':dummy,\n",
    "        'Refinements':number,\n",
    "        '% Of \"Search Keyword\"':percent}\n",
    "\n",
    "start_row = 3\n",
    "start_col = 0       \n",
    "\n",
    "keys = []\n",
    "for k in report_dict.keys():\n",
    "    if 'number search refinements' in k:\n",
    "        keys.append(k)\n",
    "keys = sorted(keys)[::-1]        \n",
    "        \n",
    "sht.write(start_row - 1,\n",
    "          start_col,\n",
    "         'Data is from ' + report_dict[k.split(' ')[0] + ' search keyword period'])        \n",
    "        \n",
    "for k in keys:\n",
    "    \n",
    "    df = report_dict[k].copy()\n",
    "    df.reset_index(inplace = True)\n",
    "\n",
    "    df.columns = df.columns.str.title()\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'O':\n",
    "            df[col] = df[col].str.title()       \n",
    "            \n",
    "    sht.write(start_row + 1,\n",
    "              start_col,\n",
    "              k.split(' ')[0].title(),\n",
    "              subtitle)            \n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        if i%5 != 0:\n",
    "            df.loc[i, 'Search Keyword'] = ''    \n",
    "\n",
    "    for i in range(len(df.columns)):\n",
    "        \n",
    "        col_width = []        \n",
    "        \n",
    "        sht.write(start_row + 2,\n",
    "                 start_col + i,\n",
    "                 df.columns[i],\n",
    "                 col_names)\n",
    "        \n",
    "        col_width.append(len(df.columns[i]))\n",
    "                \n",
    "        for j in range(len(df)):                        \n",
    "            sht.write(start_row + 3 + j,\n",
    "                     start_col + i,\n",
    "                     df.iloc[j,i],\n",
    "                     fmts[df.columns[i]])\n",
    "            \n",
    "            col_width.append(len(str(df.iloc[j,i])))\n",
    "                        \n",
    "        sht.set_column(start_col + i,\n",
    "                       start_col + i,\n",
    "                       np.max(col_width) + 1)\n",
    "        \n",
    "    start_col += len(df.columns) + 2                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How We Define Top Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sht = my_worksheets['How We Define Top Words']\n",
    "\n",
    "text = open('/Users/jarad/Fake Folder/New Products/Recurring/Algolia Searches Report/Docs/How We Define Top Words.txt', 'r').read()\n",
    "options = {'width': 510,\n",
    "           'height': 280}\n",
    "\n",
    "start_row = 3\n",
    "start_col = 0\n",
    "\n",
    "sht.insert_textbox(start_row + 1,\n",
    "                   start_col,\n",
    "                   text,\n",
    "                   options)\n",
    "\n",
    "for k in scores_dict.keys():\n",
    "    \n",
    "    df = scores_dict[k].copy()\n",
    "    \n",
    "    df.columns = df.columns.str.title()\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'O':\n",
    "            df[col] = df[col].str.title()           \n",
    "    \n",
    "    df.drop(df[df['Score'] < cutoff].index, inplace = True)\n",
    "    df = df.groupby('Score').head(3)\n",
    "    \n",
    "    sht.write(start_row + 1,\n",
    "              start_col + 5,\n",
    "              k.split(' ')[0].title(),\n",
    "              subtitle)\n",
    "                \n",
    "    for i in range(len(df.columns)):\n",
    "        \n",
    "        col_width = []        \n",
    "        \n",
    "        sht.write(start_row + 2,\n",
    "                 start_col + i + 5,\n",
    "                 df.columns[i],\n",
    "                 col_names)\n",
    "        \n",
    "        col_width.append(len(df.columns[i]))\n",
    "                \n",
    "        for j in range(len(df)):\n",
    "            \n",
    "            if df.columns[i] == 'Score':\n",
    "                fmt = percent\n",
    "            else:\n",
    "                fmt = dummy\n",
    "            \n",
    "            sht.write(start_row + 3 + j,\n",
    "                      start_col + i + 5,\n",
    "                      df.iloc[j,i],\n",
    "                      fmt)\n",
    "            \n",
    "            col_width.append(len(str(df.iloc[j,i])))\n",
    "            \n",
    "        sht.set_column(start_col + i,\n",
    "                       start_col + i + 5,\n",
    "                       np.max(col_width) + 1)\n",
    "        \n",
    "    start_col += len(df.columns) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if write_workbook == 'yes':\n",
    "    workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
