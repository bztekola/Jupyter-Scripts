model_counter <- model_counter + 1
m1 <- HoltWinters(t1, season = c(w), beta = beta, gamma = gamma)
if (m1$SSE < sse){
sse <- m1$SSE
model <- forecast(m1, h = forecast_steps, level = c(95))
}
}, error = function(e){})
}
}
}
ret = list('model' = model, 'model counter' = model_counter)
return(ret)
}
start <- Sys.time()
# prepare counters and lists
total_models <- 0
total_pns <- 0
final_models <- list()
models <- c(naive_func,
ses_func,
arima_func,
holt_func)
# loop through all products
for (pn in all_pns){
total_pns <- total_pns + 1
model_counter <- 0
# prepare data for model building, and split into training and test sets
df <- subset(main, `part id` == pn)
n = ceiling(nrow(df) * 0.80)
train_data <- df[1:n,]
test_data <- df[(n+1):nrow(df),]
train <- train_data$`qty total`
test <- test_data$`qty total`
steps <- length(test)
RMSE <- Inf
tryCatch({
# loop through each model and choose the best
for (i in 1:length(models)){
m <- models[[i]]
# fit the model to the training set
fit <- m(train, steps)
total_models <- total_models + fit$`model counter`
# get the rmse
rmse <- accuracy(fit$model, test)[4]
# if the rmse is the lowest then choose that model
if (rmse < RMSE){
RMSE <- rmse
m2 <- m
}
}
}, error = function(e){})
# send all data through the best model and forecast over the unknown future
f <- m2(df$`qty total`, forecast_steps)
model_used <- f$model$method
mape <- accuracy(f$model)[5]
mae <- accuracy(f$model)[3]
lower <- f$model$lower[1:forecast_steps]
mean <- f$model$mean[1:forecast_steps]
upper <- f$model$upper[1:forecast_steps]
final_models[[as.character(pn)]] <- list(lower,mean,upper,mape,mae,model_used)
}
end <- Sys.time()
e <- end - start
print(paste('it took',round(e,2),'minutes to create',total_models,'models for',total_pns,'PNs'))
print(paste('that\'s an avg of',round(total_models/total_pns),'models per PN'))
v1 <- length(final_models)
v2 <- length(all_pns)
if (v1 == v2){
print('match')
} else {
print('mismatch')
}
# create empty dataframe to fill
model_summaries <- as.data.frame(matrix(ncol = 4, nrow = 0))
colnames(model_summaries) <- c('part id','mape','mae','model used')
names <- names(final_models) # all the part numbers
for (i in 1:length(names)){
# add part number to first column
model_summaries[i,1] = names[i]
# add this stuff to the rest of the columns
for (j in 2:4){
# 4: mape
# 5: mae
# 6: model_used
model_summaries[i,j] = final_models[[i]][j+2]
}
}
# join to get bom and popularity tier
model_summaries$`part id` <- as.double(model_summaries$`part id`)
y <- select(main, 'part id','bom type','popularity tier')
y <- y[!duplicated(y), ]
model_summaries <- merge(x = model_summaries, y = y, by = 'part id', all.x = TRUE)
head(model_summaries)
# round these numbers
model_summaries$mae <- round(model_summaries$mae)
model_summaries$mape <- round(model_summaries$mape, 2)
# check it out
summary(model_summaries[,c('mae','mape')])
# first, create a single worksheet that holds all part numbers, and forecasts for all months
for_xl <- as.data.frame(matrix(ncol = 4, nrow = 0))
for_xl$`part id` <- strtoi(for_xl$`part id`)
# for each part number do this:
for (i in 1:length(names)){
# get the part number
a <- final_models[[i]]
# create temp df to hold the lower, avg, upper, and forecast months
temp <- as.data.frame(cbind(a[[1]], a[[2]], a[[3]], as.Date(ds, origin = lubridate::origin)))
# name the columns
colnames(temp) <- c('lower','average','upper','forecast month')
# change the datatype
temp$`forecast month` <- as.Date(temp$`forecast month`, origin = lubridate::origin)
# create the part id column
temp$`part id` <- names[i]
# bind by row so that all data is on a single page
for_xl <- rbind(for_xl, temp)
}
# get just year_and_month from the dates
for_xl$`forecast month` <- substr(as.character(for_xl$`forecast month`),1,7)
# join BOM, popularity tier, and model used
y <- select(model_summaries, 'part id','bom type','popularity tier','model used')
for_xl <- merge(x = for_xl, y = y, by = 'part id', all.x = TRUE)
# quick count, to make sure you didn't miss any parts
print('check the count of unique PNs')
l1 <- length(unique(main$`part id`))
l2 <- length(unique(for_xl$`part id`))
if (l1 == l2){
print('match')
} else {
print('mismatch')
}
# rearrange columns to make the output nicer
cols <- c('part id','bom type','popularity tier','forecast month','lower','average','upper')
for_xl <- for_xl[, c(cols)]
# if the lower estimate is negative, then make is zero
for_xl$`lower`[for_xl$`lower` < 0] <- 0
# round mae, lower, average, and upper to be whole numbers
for (col in list('lower','average','upper')){
for_xl[[col]] <- round(for_xl[[col]])
}
subset(for_xl, `part id` == 1018)
subset(model_summaries, `part id` == 1018)
parts <- '/Users/jarad/Fake Folder/Fab/Projects/War\ Chest\ 2018/Python/Parts\ Used\ in\ the\ War\ Chest\ 2018\ Forecasts - For GitHub Portfolio.xlsx'
used <- read_excel(parts, 1)
excluded <- read_excel(parts, 2)
t1 <- paste('Fab War Chest 2018 Forecasts for', d1, 'to', d2)
t2 <- paste('Kitting War Chest 2018 Forecasts for', d1, 'to', d2)
wrk_ls <- list('pnp' = t1,
'kitted' = t2)
head(used)
head(excluded)
if (write_workbook == 'yes'){
# for each bom, make a separate workbook, so one workbook for Kitting and one for Fab
for (w in names(wrk_ls)){
# get the model summaries
sum2 <- subset(model_summaries, `bom type` == w)
# sort first by popularity tier, then part id
sum2 <- arrange(sum2, `popularity tier`,`part id`)
# subset the actual forecasts by bom
df <- subset(for_xl, `bom type` == w)
# create a list for the excel sheet order, and put model_summaries first
ls <- list('Model Summaries' = sum2)
# get unique popularity tiers
ls2 <- sort(unique(main$`popularity tier`))
# for each populaity tier, do this:
for (p in ls2){
# write one popularity tier per worksheet
d <- subset(df, `popularity tier` == p)
# change part id to integer
d$`part id` <- strtoi(d$`part id`)
# for each bom, sort by part id then forecast month
d <- arrange(d, `part id`,`forecast month`)
# send it all to this list
ls[[p]] <- d
}
# add these sheets to the end of the workbook
ls[['Parts Used']] <- subset(used, `bom type` == w)
ls[['Parts Excluded']] <- subset(excluded, `bom type` == w)
# create a workbook for both fab and kitting
write.xlsx(ls, file = paste(wrk_ls[[w]], ' - For GitHub Portfolio.xlsx'))
}
}
print('done')
library(readxl)
library(forecast)
library(dplyr)
library(lubridate)
library(openxlsx)
write_workbook <- 'yes'
forecast_steps <- 3
# get main data from CSV
p = '/Users/jarad/fake_folder/Fab/Projects/War\ Chest\ 2018/CSVs/War\ Chest\ Part\ sales\ for\ R.xlsx'
main <- read_excel(p)
# get main data from CSV
p = '/Users/jarad/Fake Folder/Fab/Projects/War\ Chest\ 2018/CSVs/War\ Chest\ Part\ sales\ for\ R.xlsx'
main <- read_excel(p)
main$`year and month` <- as.Date(main$`year and month`)
# get a list of all unique part numbers
all_pns <- unique(main$`part id`)
# get date ranges of forecast period, for later
# start from one month after the final date of your main data
# then get the next M months; you'll then have a total of M+1 months
d <- max(main$`year and month`)
d <- as.Date(d) + months(1)
ds <- seq(as.Date(d), by = 'month', length.out = forecast_steps)
# create Excel workbook attributes, for later, we're going to write the finish data to Excel
d1 <- substring(ds[1], 1,7)
d2 <- substring(ds[length(ds)], 1,7)
head(main)
l <- length(unique(main$`part id`))
print(paste('the unique (umbrella) part id count is', l))
naive_func <- function(t1, forecast_steps){
model <- rwf(t1, h = forecast_steps, level = c(95))
model_counter <- 1
ret = list('model' = model, 'model counter' = model_counter)
return(ret)
}
ses_func <- function(t1, forecast_steps){
model <- ses(t1, h = forecast_steps, level = c(95))
model_counter <- 1
ret = list('model' = model, 'model counter' = model_counter)
return(ret)
}
arima_func <- function(t1, forecast_steps){
trace <- capture.output({
m1 <- auto.arima(t1, trace = TRUE)
model <- forecast(m1, h = forecast_steps, level = c(95))
})
con    <- textConnection(trace)
models <- read.table(con, sep=":")
model_counter <- length(models[,1]) - 1
close(con)
ret <- list('model' = model, 'model counter' = model_counter)
return(ret)
}
holt_func <- function(t1, forecast_steps){
model_counter <- 0
sse <- Inf
for (w in list('additive','multiplicative')){
for (beta in list(TRUE,FALSE)){
for (gamma in list(TRUE,FALSE)){
tryCatch({
model_counter <- model_counter + 1
m1 <- HoltWinters(t1, season = c(w), beta = beta, gamma = gamma)
if (m1$SSE < sse){
sse <- m1$SSE
model <- forecast(m1, h = forecast_steps, level = c(95))
}
}, error = function(e){})
}
}
}
ret = list('model' = model, 'model counter' = model_counter)
return(ret)
}
start <- Sys.time()
# prepare counters and lists
total_models <- 0
total_pns <- 0
final_models <- list()
models <- c(naive_func,
ses_func,
arima_func,
holt_func)
# loop through all PNs
for (pn in all_pns){
total_pns <- total_pns + 1
model_counter <- 0
# prepare data for model building; split into training and test sets
df <- subset(main, `part id` == pn)
n = ceiling(nrow(df) * 0.80)
train_data <- df[1:n,]
test_data <- df[(n+1):nrow(df),]
train <- train_data$`qty total`
test <- test_data$`qty total`
steps <- length(test)
RMSE <- Inf
tryCatch({
# loop through each model and choose the best
for (i in 1:length(models)){
m <- models[[i]]
# fit the model to the training set
fit <- m(train, steps)
total_models <- total_models + fit$`model counter`
# get the rmse
rmse <- accuracy(fit$model, test)[4]
# if the rmse is the lowest then choose that model
if (rmse < RMSE){
RMSE <- rmse
m2 <- m
}
}
}, error = function(e){})
# send all data through the best model and forecast over the unknown future
f <- m2(df$`qty total`, forecast_steps)
model_used <- f$model$method
mape <- accuracy(f$model)[5]
mae <- accuracy(f$model)[3]
lower <- f$model$lower[1:forecast_steps]
mean <- f$model$mean[1:forecast_steps]
upper <- f$model$upper[1:forecast_steps]
final_models[[as.character(pn)]] <- list(lower,mean,upper,mape,mae,model_used)
}
end <- Sys.time()
e <- end - start
print(paste('it took',round(e,2),'minutes to create',total_models,'models for',total_pns,'PNs'))
print(paste('that\'s an avg of',round(total_models/total_pns),'models per PN'))
v1 <- length(final_models)
v2 <- length(all_pns)
if (v1 == v2){
print('match')
} else {
print('mismatch')
}
# create empty dataframe to fill
model_summaries <- as.data.frame(matrix(ncol = 4, nrow = 0))
colnames(model_summaries) <- c('part id','mape','mae','model used')
names <- names(final_models)
for (i in 1:length(names)){
# add PN to first column
model_summaries[i,1] = names[i]
# add this stuff in the rest of the columns
for (j in 2:4){
# 4: mape
# 5: mae
# 6: model_used
model_summaries[i,j] = final_models[[i]][j+2]
}
}
# join to get bom and popularity tier
model_summaries$`part id` <- as.double(model_summaries$`part id`)
y <- select(main, 'part id','bom type','popularity tier')
y <- y[!duplicated(y), ]
model_summaries <- merge(x = model_summaries, y = y, by = 'part id', all.x = TRUE)
# check it out
head(model_summaries)
# round these numbers
model_summaries$mae <- round(model_summaries$mae)
model_summaries$mape <- round(model_summaries$mape, 2)
# check it out
summary(model_summaries[,c('mae','mape')])
# first, create a single worksheet that holds all part numbers and forecasts for all months
for_xl <- as.data.frame(matrix(ncol = 4, nrow = 0))
for_xl$`part id` <- strtoi(for_xl$`part id`)
# for each PN do this:
for (i in 1:length(names)){
# get the part number
a <- final_models[[i]]
# create temp df to hold the lower, avg, upper, and forecast months
temp <- as.data.frame(cbind(a[[1]], a[[2]], a[[3]], as.Date(ds, origin = lubridate::origin)))
# name the columns
colnames(temp) <- c('lower','average','upper','forecast month')
# change the datatype
temp$`forecast month` <- as.Date(temp$`forecast month`, origin = lubridate::origin)
# create the part id column
temp$`part id` <- names[i]
# bind by row so that all data is on a single page
for_xl <- rbind(for_xl, temp)
}
# get just year_and_month from the dates
for_xl$`forecast month` <- substr(as.character(for_xl$`forecast month`),1,7)
# join BOM and popularity tier
y <- select(model_summaries, 'part id','bom type','popularity tier','model used')
for_xl <- merge(x = for_xl, y = y, by = 'part id', all.x = TRUE)
# quick count, to make sure you didn't miss any parts
print('check the count of unique PNs')
l1 <- length(unique(main$`part id`))
l2 <- length(unique(for_xl$`part id`))
if (l1 == l2){
print('match')
} else {
print('mismatch')
}
# rearrange columns to make the output nicer
cols <- c('part id','bom type','popularity tier','forecast month','lower','average','upper')
for_xl <- for_xl[, c(cols)]
# if the lower estimate is negative, then make is zero
for_xl$`lower`[for_xl$`lower` < 0] <- 0
# round mae, lower, average, and upper to be whole numbers
for (col in list('lower','average','upper')){
for_xl[[col]] <- round(for_xl[[col]])
}
parts <- '/Users/jarad/fake_folder/Fab/Projects/War\ Chest\ 2018/Python/Parts\ Used\ in\ the\ War\ Chest\ 2018\ Forecasts.xlsx'
used <- read_excel(parts, 1)
parts <- '/Users/jarad/Fake Folder/Fab/Projects/War\ Chest\ 2018/Python/Parts\ Used\ in\ the\ War\ Chest\ 2018\ Forecasts.xlsx'
used <- read_excel(parts, 1)
parts <- '/Users/jarad/Fake Folder/Fab/Projects/War\ Chest\ 2018/CSVs/Parts\ Used\ in\ the\ War\ Chest\ 2018\ Forecasts.xlsx'
used <- read_excel(parts, 1)
excluded <- read_excel(parts, 2)
t1 <- paste('Fab War Chest 2018 Forecasts for', d1, 'to', d2)
t2 <- paste('Kitting War Chest 2018 Forecasts for', d1, 'to', d2)
wrk_ls <- list('pnp' = t1,
'kitted' = t2)
head(used)
head(excluded)
if (write_workbook == 'yes'){
# for each bom of make a separate workbook
for (w in names(wrk_ls)){
# get the model summaries
sum2 <- subset(model_summaries, `bom type` == w)
# sort first by popularity tier, then part id
sum2 <- arrange(sum2, `popularity tier`,`part id`)
# subset the actual forecasts by bom
df <- subset(for_xl, `bom type` == w)
# create a list for the excel sheet order, and put model_summaries first
ls <- list('Model Summaries' = sum2)
# get unique popularity tiers
ls2 <- sort(unique(main$`popularity tier`))
# for each populaity tier, do this:
for (p in ls2){
# write one popularity tier per worksheet
d <- subset(df, `popularity tier` == p)
# change part id to integer
d$`part id` <- strtoi(d$`part id`)
# for each bom, sort by part id then forecast month
d <- arrange(d, `part id`,`forecast month`)
# send it all to this list
ls[[p]] <- d
}
# add these sheets to the end of the workbook
ls[['Parts Used']] <- subset(used, `bom type` == w)
ls[['Parts Excluded']] <- subset(excluded, `bom type` == w)
# create a workbook for both fab and kitting
write.xlsx(ls, file = paste(wrk_ls[[w]], '.xlsx'))
}
}
print('done')
wrk_ls
file
paste(wrk_ls[[w]], '.xlsx'
paste(wrk_ls[[w]], '.xlsx')
# first, create a single worksheet that holds all part numbers and forecasts for all months
for_xl <- as.data.frame(matrix(ncol = 4, nrow = 0))
for_xl$`part id` <- strtoi(for_xl$`part id`)
# for each PN do this:
for (i in 1:length(names)){
# get the part number
a <- final_models[[i]]
# create temp df to hold the lower, avg, upper, and forecast months
temp <- as.data.frame(cbind(a[[1]], a[[2]], a[[3]], as.Date(ds, origin = lubridate::origin)))
# name the columns
colnames(temp) <- c('lower','average','upper','forecast month')
# change the datatype
temp$`forecast month` <- as.Date(temp$`forecast month`, origin = lubridate::origin)
# create the part id column
temp$`part id` <- names[i]
# bind by row so that all data is on a single page
for_xl <- rbind(for_xl, temp)
}
# get just year_and_month from the dates
for_xl$`forecast month` <- substr(as.character(for_xl$`forecast month`),1,7)
# join BOM and popularity tier
y <- select(model_summaries, 'part id','bom type','popularity tier','model used')
for_xl <- merge(x = for_xl, y = y, by = 'part id', all.x = TRUE)
# quick count, to make sure you didn't miss any parts
print('check the count of unique PNs')
l1 <- length(unique(main$`part id`))
l2 <- length(unique(for_xl$`part id`))
if (l1 == l2){
print('match')
} else {
#print('mismatch')
stop('mismatch')
}
# rearrange columns to make the output nicer
cols <- c('part id','bom type','popularity tier','forecast month','lower','average','upper')
for_xl <- for_xl[, c(cols)]
# if the lower estimate is negative, then make is zero
for_xl$`lower`[for_xl$`lower` < 0] <- 0
# round mae, lower, average, and upper to be whole numbers
for (col in list('lower','average','upper')){
for_xl[[col]] <- round(for_xl[[col]])
}
# first, create a single worksheet that holds all part numbers and forecasts for all months
for_xl <- as.data.frame(matrix(ncol = 4, nrow = 0))
for_xl$`part id` <- strtoi(for_xl$`part id`)
# for each PN do this:
for (i in 1:length(names)){
# get the part number
a <- final_models[[i]]
# create temp df to hold the lower, avg, upper, and forecast months
temp <- as.data.frame(cbind(a[[1]], a[[2]], a[[3]], as.Date(ds, origin = lubridate::origin)))
# name the columns
colnames(temp) <- c('lower','average','upper','forecast month')
# change the datatype
temp$`forecast month` <- as.Date(temp$`forecast month`, origin = lubridate::origin)
# create the part id column
temp$`part id` <- names[i]
# bind by row so that all data is on a single page
for_xl <- rbind(for_xl, temp)
}
# get just year_and_month from the dates
for_xl$`forecast month` <- substr(as.character(for_xl$`forecast month`),1,7)
# join BOM and popularity tier
y <- select(model_summaries, 'part id','bom type','popularity tier','model used')
for_xl <- merge(x = for_xl, y = y, by = 'part id', all.x = TRUE)
# quick count, to make sure you didn't miss any parts
print('check the count of unique PNs')
l1 <- length(unique(main$`part id`))
l2 <- length(unique(for_xl$`part id`))
if (l1 == l2){
} else {
stop('mismatch')
}
# rearrange columns to make the output nicer
cols <- c('part id','bom type','popularity tier','forecast month','lower','average','upper')
for_xl <- for_xl[, c(cols)]
# if the lower estimate is negative, then make is zero
for_xl$`lower`[for_xl$`lower` < 0] <- 0
# round mae, lower, average, and upper to be whole numbers
for (col in list('lower','average','upper')){
for_xl[[col]] <- round(for_xl[[col]])
}
