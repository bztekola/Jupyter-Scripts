{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "part_cost.py start\n",
      "match\n",
      "no nulls\n",
      "match\n",
      "no nulls\n",
      "you're df is called all_cost2\n",
      "the mean stripe margin is 77.44%\n",
      "part_cost.py end\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/Users/jarad/fake_folder/Python Libraries')\n",
    "\n",
    "import datetime\n",
    "\n",
    "from jb_libraries import *\n",
    "from part_cost import * # to see which combos or parts contain the parts we want to forecast\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "from scipy import stats\n",
    "\n",
    "# use 2018-09-30 if this output is for your GitHub script\n",
    "date_end = '2018-09-30'\n",
    "write = 'yes'\n",
    "\n",
    "six_months_ago = str((pd.to_datetime(date_end) - pd.DateOffset(months = 5)).date())\n",
    "six_months_ago = six_months_ago[:7] + '-01'\n",
    "\n",
    "three_months_ago = str((pd.to_datetime(date_end) - pd.DateOffset(months = 2)).date())\n",
    "three_months_ago = three_months_ago[:7] + '-01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "* See email \"@Brian - seeking help with internal skus\" for info on how to exclude PNs that are flagged as \"do not sell to customers\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Fab and Kitting skus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "skus_main = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "sku_id,\n",
    "k.part_id,\n",
    "pd.products_name,\n",
    "bom_type,\n",
    "\n",
    "# to exclude internal parts\n",
    "# from email with subject line \"@Brian - seeking help with internal skus\"\n",
    "CASE WHEN p.products_dont_sell_alone = 1\n",
    "OR p.products_carrot_only = 1\n",
    "OR p.products_meta_type = 'Base Product'\n",
    "OR p.products_coming_soon = 1\n",
    "OR p.discontinue_status = 'Discontinued'\n",
    "\n",
    "# if the status != 1 then exclude it\n",
    "# but if the status != 1 AND the PN is a stripe, keep it in\n",
    "OR (p.products_status != 1 AND p.products_stripes = 0)\n",
    "\n",
    "OR p.products_discontinued = 1\n",
    "THEN 'yes'\n",
    "ELSE 'no' END AS excluded_from_models\n",
    "\n",
    "FROM skus k\n",
    "JOIN products_description pd ON k.part_id = pd.part_id\n",
    "JOIN parts p ON k.part_id = p.part_id\n",
    "\n",
    "WHERE bom_type IN ('kitted','pnp') # get just pnp and kitted\n",
    "AND sku_status = 'working' # only working skus\n",
    "''', db)\n",
    "\n",
    "col_fix(skus_main)\n",
    "\n",
    "skus = skus_main[skus_main['excluded from models'] == 'no'].copy()\n",
    "skus.drop('excluded from models', 1, inplace = True)\n",
    "\n",
    "# some parts have more than one active skus, here we only care about parts\n",
    "skus.drop_duplicates('part id', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scramble part names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = skus_main['products name'].to_dict()\n",
    "\n",
    "for k,v in d.items():\n",
    "    skus_main['products name'] = skus_main['products name'].replace(v,k)\n",
    "    \n",
    "skus_main['products name'] = ['Products Name ' + str(x) for x in skus_main['products name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out the parts that were excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 unique excluded PNs\n"
     ]
    }
   ],
   "source": [
    "excluded = skus_main[skus_main['excluded from models'] == 'yes'].copy()\n",
    "\n",
    "reasons = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "part_id,\n",
    "products_dont_sell_alone,\n",
    "products_carrot_only,\n",
    "products_meta_type,\n",
    "products_coming_soon,\n",
    "discontinue_status,\n",
    "products_status,\n",
    "products_discontinued,\n",
    "products_stripes\n",
    "FROM parts\n",
    "WHERE part_id IN '''+ str(tuple(excluded['part id'].tolist())) +'''\n",
    "''', db)\n",
    "\n",
    "col_fix(reasons)\n",
    "\n",
    "excluded = pd.merge(excluded, reasons, on = 'part id')\n",
    "print('{} unique excluded PNs'.format(len(set(excluded['part id']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out excluded parts that could be stripes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 excluded PNs are stripes\n"
     ]
    }
   ],
   "source": [
    "s = excluded[excluded['products stripes'] == 1]\n",
    "print('{} excluded PNs are stripes'.format(len(s)))\n",
    "\n",
    "if len(s) == 0:\n",
    "    pass\n",
    "else:\n",
    "    s1 = pd.read_sql(\n",
    "    '''\n",
    "    SELECT\n",
    "    DATE(date_purchased) AS date_purchased,\n",
    "    DATE_FORMAT(date_purchased, '%Y-%m') AS year_and_month,\n",
    "    op.orders_id,\n",
    "    part_id,\n",
    "    products_quantity_free AS qty_free,\n",
    "    products_quantity - products_quantity_free AS qty_bought,\n",
    "    products_quantity AS qty_total,\n",
    "    products_price * (products_quantity - products_quantity_free) AS revenue,\n",
    "    IF(orders_reseller = 0 AND orders_super_reseller = 0, 'non reseller','reseller/super') AS customer\n",
    "    FROM orders_products op\n",
    "    JOIN orders o ON op.orders_id = o.orders_id\n",
    "    WHERE op.part_id IN '''+ str(tuple(excluded['part id'][excluded['products stripes'] == 1])) +'''\n",
    "    ''', db)\n",
    "\n",
    "    col_fix(s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the combos that these PNs are contained in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptc_main = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "part_id,\n",
    "contains_part_id,\n",
    "pts_quantity\n",
    "FROM products_to_stuff\n",
    "WHERE part_id > 0\n",
    "''', db)\n",
    "\n",
    "col_fix(ptc_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate the fab and kitting PNs, for later\n",
    "ptc_clean = ptc_main[ptc_main['contains part id'].isin(skus['part id'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This following is just for reference and not used in the script to make any changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the combos that contain a kitted or fab part\n",
    "ptc1 = ptc_main[ptc_main['contains part id'].isin(skus['part id'].tolist())].copy()\n",
    "\n",
    "# rename the columns to suit our purposes here in this script\n",
    "ptc1.rename(columns = {'part id':'contained in', 'contains part id':'part id'}, inplace = True)\n",
    "ptc1['(contained in, pts quantity)'] = list(zip(ptc1['contained in'], ptc1['pts quantity']))\n",
    "\n",
    "# in this block we'll just make a table of skus, parts, pop tiers, and the combos that those \n",
    "# PNs are contained in, to write to excel later on\n",
    "# this is not used in the script, it's only here for reference\n",
    "# create tuples of (contained in PN, pts quantity)\n",
    "ptc2 = pd.DataFrame(ptc1.groupby('part id')['(contained in, pts quantity)'].apply(lambda x: '; '.join(x.map(str))))\n",
    "ptc2.reset_index(inplace = True)\n",
    "\n",
    "# join to main sku data\n",
    "skus_for_excel = pd.merge(skus, ptc2, how = 'left', on = 'part id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scramble part names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = skus_for_excel['products name'].to_dict()\n",
    "\n",
    "for k,v in d.items():\n",
    "    skus_for_excel['products name'] = skus_for_excel['products name'].replace(v,k)\n",
    "    \n",
    "skus_for_excel['products name'] = ['Products Name ' + str(x) for x in skus_for_excel['products name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sales data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "*\n",
    "FROM orders_status\n",
    "ORDER BY orders_status_id\n",
    "''', db)\n",
    "\n",
    "col_fix(os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data is from 2006-05-21 to 2018-10-27\n"
     ]
    }
   ],
   "source": [
    "sales_super_main = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "DATE(date_purchased) AS date_purchased,\n",
    "DATE_FORMAT(date_purchased, '%Y-%m') AS year_and_month,\n",
    "op.orders_id,\n",
    "part_id,\n",
    "\n",
    "# forecast qty_bought and qty_free together\n",
    "# i.e. don't do freebies separately, do them all together as one\n",
    "products_quantity AS qty_total, \n",
    "\n",
    "products_price * (products_quantity - products_quantity_free) AS revenue,\n",
    "IF(orders_reseller = 0 AND orders_super_reseller = 0, 'non reseller','reseller/super') AS customer\n",
    "FROM orders_products op\n",
    "JOIN orders o ON op.orders_id = o.orders_id\n",
    "AND orders_status NOT IN (8,9,10,11,12,14,15)\n",
    "\n",
    "# get sales of the kitted/pnp PN and the PNs that contain the kitted/pnp PN\n",
    "WHERE (op.part_id IN '''+ str(tuple(skus['part id'].tolist())) +''' \n",
    "OR op.part_id IN '''+ str(tuple(ptc_clean['part id'])) +''')\n",
    "''', db)\n",
    "\n",
    "col_fix(sales_super_main)\n",
    "\n",
    "# change to datetime\n",
    "sales_super_main['date purchased'] = pd.to_datetime(sales_super_main['date purchased'])\n",
    "\n",
    "d1 = sales_super_main['date purchased'].min().date()\n",
    "d2 = sales_super_main['date purchased'].max().date()\n",
    "\n",
    "print('data is from {} to {}'.format(d1,d2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_main = sales_super_main[sales_super_main['date purchased'] <= date_end].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the umbrella_part_id\n",
    "This is the PN we will forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part id</th>\n",
       "      <th>(contained in, pts quantity)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>(143, 2.0); (144, 1.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   part id (contained in, pts quantity)\n",
       "2      128       (143, 2.0); (144, 1.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PN 128 is sold alone and in PN 143, 144\n",
    "# so any order that containes one of these parts should have a corresponding umbrella PN of 128\n",
    "ptc2[ptc2['part id'] == 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_main['umbrella part id'] = sales_main['part id'].map(dict(zip(ptc_clean['part id'], ptc_clean['contains part id'])))\n",
    "sales_main['umbrella part id'].fillna(sales_main['part id'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check umbrella PN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{128, 143, 144}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it works: the PNs uder the umbrella PN should be itself and the two combos its contained in\n",
    "set(sales_main[sales_main['umbrella part id'] == 128]['part id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no nulls\n"
     ]
    }
   ],
   "source": [
    "if sales_main[sales_main.isnull().any(1)].empty:\n",
    "    print('no nulls')\n",
    "else:\n",
    "    print('nulls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get stock data, to see how many days OOS on average per PN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_this = 'no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_this == 'yes':\n",
    "\n",
    "    d1 = sales_main['date purchased'].min().date()\n",
    "    d2 = sales_main['date purchased'].max().date()\n",
    "\n",
    "    stock_main = pd.read_sql(\n",
    "    '''\n",
    "    SELECT\n",
    "    part_id,\n",
    "    DATE(timestamp) AS date,\n",
    "    AVG(visible_stock) AS visible_stock # assume snapshot is 4 times per day, therefore get the avg per day per PN\n",
    "    FROM parts_stock_snapshots\n",
    "    WHERE DATE(timestamp) BETWEEN ' '''+ str(d1) +''' ' AND ' '''+ str(d2) +''' '\n",
    "    AND part_id IN '''+ str(tuple(skus['part id'].tolist())) +'''\n",
    "    GROUP BY DATE(timestamp), part_id\n",
    "    ''', db)\n",
    "\n",
    "    col_fix(stock_main)\n",
    "\n",
    "    # get year and month\n",
    "    stock_main['year and month'] = [str(x)[:7] for x in stock_main['date']]\n",
    "\n",
    "    # flag days out of stock\n",
    "    stock_main['oos'] = np.where(stock_main['visible stock'] <= 0,1,0)\n",
    "\n",
    "    stock = stock_main.groupby(['year and month','part id'])[['oos']].sum()\n",
    "\n",
    "    # for simplicity, split the difference between months with 30 days and months with 31 days\n",
    "    stock['% oos'] = stock['oos']/30.5\n",
    "\n",
    "    print('from {} to {}\\nfor {} parts\\nbelow is the oos % per PN per month:\\n'.format(d1,d2,len(set(skus['part id']))))\n",
    "    print(stock['% oos'].describe(percentiles = np.arange(0,1.05,0.05)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find PNs that have no sales data but should"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 PNs with missing sales data\n",
      "\n",
      "check this with a db query:\n",
      "True, these parts do not have sales data; ok to move on\n"
     ]
    }
   ],
   "source": [
    "# find skus that have no sales data\n",
    "missing = skus[~skus['part id'].isin(sales_main['umbrella part id'])].copy()\n",
    "print('{} PNs with missing sales data'.format(len(missing)))\n",
    "print('\\ncheck this with a db query:')\n",
    "\n",
    "# verify that these PNs with missing sales data truly do not have any sales data\n",
    "# if they truly do not, they will not show up here\n",
    "# if they do show up here, then to have missing data they must have been last purchased before our date_start\n",
    "    # or after our end date\n",
    "    \n",
    "if len(missing) > 0:\n",
    "    m = pd.read_sql(\n",
    "    '''\n",
    "    SELECT\n",
    "    part_id,\n",
    "    DATE_FORMAT(MAX(DATE(date_purchased)), '%Y-%m') AS max_year_and_month,\n",
    "    COUNT(op.orders_id) AS oid_count\n",
    "    FROM orders_products op\n",
    "    JOIN orders o ON op.orders_id = o.orders_id\n",
    "    WHERE part_id IN '''+ str(tuple(missing['part id'])) +'''\n",
    "    AND DATE(date_purchased) <= ' '''+ date_end +''' '\n",
    "    GROUP BY part_id\n",
    "    ''', db)\n",
    "\n",
    "    col_fix(m)\n",
    "    \n",
    "    if m.empty:\n",
    "        print('True, these parts do not have sales data; ok to move on')\n",
    "    else:\n",
    "        print('False, these parts DO have sales data; check your work')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOM proportions\n",
    "Using the umbrella PN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no nulls\n",
      "BOM proportions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% Of Total Count</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pnp</th>\n",
       "      <td>52.31%</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kitted</th>\n",
       "      <td>47.69%</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>100.00%</td>\n",
       "      <td>822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       % Of Total Count Count\n",
       "pnp              52.31%   430\n",
       "kitted           47.69%   392\n",
       "total           100.00%   822"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_boms = pd.concat([skus[['part id','bom type']], excluded[['part id','bom type']]])\n",
    "\n",
    "sales_main['bom type'] = sales_main['umbrella part id'].map(dict(zip(for_boms['part id'], for_boms['bom type'])))\n",
    "\n",
    "n = sales_main[sales_main.isnull().any(1)]\n",
    "if n.empty:\n",
    "    print('no nulls')\n",
    "else:\n",
    "    print('{} null(s)'.format(len(n)))\n",
    "\n",
    "s = sales_main.dropna().copy()\n",
    "s.drop_duplicates('part id', inplace = True)\n",
    "\n",
    "v1 = s['bom type'].value_counts()\n",
    "v2 = s['bom type'].value_counts().sum()\n",
    "\n",
    "print('BOM proportions')\n",
    "df = pd.DataFrame(v1/v2)\n",
    "df.columns = ['% of total count']\n",
    "df['count'] = v1\n",
    "df.loc['total'] = df.sum()\n",
    "df.format_(['p2','n0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find and fix outliers\n",
    "DON'T use the umbrella PN, use the PN\n",
    "\n",
    "Start in year 2006\n",
    "\n",
    "This is qty bought per order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this PN has a standard dev of zero: 2500\n",
      "this PN has a standard dev of zero: 2526\n",
      "this PN has a standard dev of zero: 2527\n",
      "this PN has a standard dev of zero: 2543\n",
      "this PN has a standard dev of zero: 2554\n",
      "this PN has a standard dev of zero: 2567\n",
      "this PN has a standard dev of zero: 2580\n",
      "this PN has a standard dev of zero: 2584\n",
      "this PN has a standard dev of zero: 2592\n",
      "this PN has a standard dev of zero: 2955\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# find the lower and upper threshold for an outlier\n",
    "outlier_dict = {}\n",
    "for pn in set(sales_main['part id']):\n",
    "    df = sales_main[sales_main['part id'] == pn].copy()\n",
    "    mean = df['qty total'].mean()\n",
    "    s = df['qty total'].std()\n",
    "    \n",
    "    # if s is null because there is only one data point, make it zero\n",
    "    if np.isnan(s):\n",
    "        s = 0\n",
    "        print('this PN has a standard dev of zero: {}'.format(str(pn)))\n",
    "    lower = int(np.ceil(mean - 3 * s))\n",
    "    upper = int(np.ceil(mean + 3 * s))\n",
    "    outlier_dict[pn] = [lower, int(np.ceil(mean)), upper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag and fix these outliers\n",
    "def outlier_flag(x):\n",
    "    \n",
    "    pn = x['part id']\n",
    "    qty = x['qty total']\n",
    "    \n",
    "    lower = outlier_dict[pn][0]\n",
    "    mean = outlier_dict[pn][1]\n",
    "    upper = outlier_dict[pn][2]\n",
    "    \n",
    "    if np.logical_or(qty < lower, qty > upper):\n",
    "        return 'yes'\n",
    "    else:\n",
    "        return 'no'\n",
    "    \n",
    "sales_main['outlier'] = sales_main.apply(outlier_flag, axis = 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outliers as % of total lines in dataset\n",
      "    Outlier\n",
      "no   98.87%\n",
      "yes   1.13%\n"
     ]
    }
   ],
   "source": [
    "# view results\n",
    "v1 = sales_main['outlier'].value_counts()\n",
    "v2 = sales_main['outlier'].value_counts().sum()\n",
    "\n",
    "print('outliers as % of total lines in dataset')\n",
    "print(pd.DataFrame(v1/v2).format_(['p2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "time elapsed is 3 minutes\n"
     ]
    }
   ],
   "source": [
    "def outlier_fix(x):\n",
    "\n",
    "    pn = x['part id']\n",
    "    qty = x['qty total']\n",
    "    \n",
    "    lower = outlier_dict[pn][0]\n",
    "    upper = outlier_dict[pn][2]\n",
    "    \n",
    "    if x['outlier'] == 'yes':\n",
    "        if qty < lower:\n",
    "            return lower\n",
    "        else:\n",
    "            return upper\n",
    "    else:\n",
    "        return qty\n",
    "    \n",
    "sales_main['clean qty total'] = sales_main.apply(outlier_fix, axis = 1)\n",
    "\n",
    "end = time.time()\n",
    "print('\\ntime elapsed is {:,.0f} minutes'.format((end - start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine mod qty total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_main['pts qty total'] = sales_main['part id'].map(dict(zip(ptc_clean['part id'], ptc_clean['pts quantity'])))\n",
    "# if the PN is NOT contained in anything else, call this number 1 so the mod qty total is the same as the clean qty total\n",
    "sales_main['pts qty total'].fillna(1, inplace = True)\n",
    "sales_main['mod qty total'] = sales_main['pts qty total'] * sales_main['clean qty total']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mod qty total example\n",
    "* PN 128 is a kitted BOM\n",
    "* We need to forecast this PN\n",
    "* x2 units of PN 128 are contained in COMBO PN 143\n",
    "* If someone buys x1 unit of COMBO PN 143, they have really purchased x2 units of PN 128\n",
    "* So the mod qty total for the umbrella PN 128 is x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date purchased</th>\n",
       "      <th>year and month</th>\n",
       "      <th>orders id</th>\n",
       "      <th>part id</th>\n",
       "      <th>qty total</th>\n",
       "      <th>revenue</th>\n",
       "      <th>customer</th>\n",
       "      <th>umbrella part id</th>\n",
       "      <th>bom type</th>\n",
       "      <th>outlier</th>\n",
       "      <th>clean qty total</th>\n",
       "      <th>pts qty total</th>\n",
       "      <th>mod qty total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16134</th>\n",
       "      <td>2009-03-23</td>\n",
       "      <td>2009-03</td>\n",
       "      <td>26429</td>\n",
       "      <td>143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>non reseller</td>\n",
       "      <td>128.0</td>\n",
       "      <td>kitted</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      date purchased year and month  orders id  part id  qty total  revenue  \\\n",
       "16134     2009-03-23        2009-03      26429      143        1.0     85.0   \n",
       "\n",
       "           customer  umbrella part id bom type outlier  clean qty total  \\\n",
       "16134  non reseller             128.0   kitted      no              1.0   \n",
       "\n",
       "       pts qty total  mod qty total  \n",
       "16134            2.0            2.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_main[sales_main['part id'] == 143].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For PN 128 which is the umbrella PN, the mod qty total will be the same as clean qty total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date purchased</th>\n",
       "      <th>year and month</th>\n",
       "      <th>orders id</th>\n",
       "      <th>part id</th>\n",
       "      <th>qty total</th>\n",
       "      <th>revenue</th>\n",
       "      <th>customer</th>\n",
       "      <th>umbrella part id</th>\n",
       "      <th>bom type</th>\n",
       "      <th>outlier</th>\n",
       "      <th>clean qty total</th>\n",
       "      <th>pts qty total</th>\n",
       "      <th>mod qty total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10483</th>\n",
       "      <td>2008-11-04</td>\n",
       "      <td>2008-11</td>\n",
       "      <td>19204</td>\n",
       "      <td>128</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>non reseller</td>\n",
       "      <td>128.0</td>\n",
       "      <td>kitted</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      date purchased year and month  orders id  part id  qty total  revenue  \\\n",
       "10483     2008-11-04        2008-11      19204      128        2.0     60.0   \n",
       "\n",
       "           customer  umbrella part id bom type outlier  clean qty total  \\\n",
       "10483  non reseller             128.0   kitted      no              2.0   \n",
       "\n",
       "       pts qty total  mod qty total  \n",
       "10483            1.0            2.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_main[sales_main['part id'] == 128].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine popularity tiers\n",
    "Using the umbrella PN\n",
    "\n",
    "Using mod qty total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "popularity tiers are based on data from 2018-07-01 to 2018-09-30\n",
      "which is about 3 months\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "date = three_months_ago\n",
    "print('popularity tiers are based on data from %s to %s' % (date, date_end))\n",
    "print('which is about {} months'.format(n))\n",
    "\n",
    "# get main data for popularity tiers\n",
    "pop_main = sales_main[sales_main['date purchased'] >= date[:7]].copy()\n",
    "\n",
    "# groupby bom and part id\n",
    "pop1 = pop_main.groupby(['bom type','umbrella part id'], as_index = False).agg({'mod qty total':'sum','revenue':'sum'})\n",
    "\n",
    "# describe by bom > part id\n",
    "des = pop1.groupby('bom type')[['mod qty total','revenue']].describe(percentiles = np.arange(0,1.05,0.05)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check unique part count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 120 PNs which are not in pop_main\n"
     ]
    }
   ],
   "source": [
    "t1 = des.loc[('mod qty total','count'),('kitted','pnp')].sum()\n",
    "t2 = len(set(sales_main['part id']))\n",
    "\n",
    "print('there are %i PNs which are not in pop_main' % (t2 - t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label pop tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no nulls\n"
     ]
    }
   ],
   "source": [
    "# label the key parts\n",
    "# which are the parts that reside in the top P% of both qty_total and revenue\n",
    "top = '85.0%'\n",
    "for index, row in pop1.iterrows():\n",
    "    \n",
    "    bom = row['bom type']\n",
    "    \n",
    "    q = des.loc[('mod qty total', top), bom] \n",
    "    r = des.loc[('revenue', top), bom]\n",
    "    \n",
    "    if np.logical_and(row['mod qty total'] > q, row['revenue'] > r):\n",
    "        pop1.loc[index, 'popularity tier'] = '01 - key'\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "# get quantiles for not-key parts    \n",
    "des2 = pop1[pop1['popularity tier'].isnull()].groupby('bom type')[['mod qty total']].describe().T    \n",
    "\n",
    "# assign to these not-key parts a popularity tier\n",
    "for index, row in pop1[pop1['popularity tier'].isnull()].iterrows():\n",
    "    \n",
    "    bom = row['bom type']\n",
    "    d = des[bom]\n",
    "    qty = row['mod qty total']\n",
    "    \n",
    "    l = d.loc[('mod qty total','50%')]\n",
    "    m = d.loc[('mod qty total','75%')]\n",
    "    \n",
    "    if qty <= l:\n",
    "        pop1.loc[index, 'popularity tier'] = '04 - low'\n",
    "        \n",
    "    elif np.logical_and(qty > l, qty <= m):\n",
    "        pop1.loc[index, 'popularity tier'] = '03 - medium'\n",
    "        \n",
    "    elif qty > m:\n",
    "        pop1.loc[index, 'popularity tier'] = '02 - high'\n",
    "\n",
    "    else:\n",
    "        pass    \n",
    "    \n",
    "n = np.sum(pop1.isnull().any(1))\n",
    "if n == 0:\n",
    "    print('no nulls')\n",
    "else:\n",
    "    print('nulls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map popularity tiers\n",
    "Using umbrella part id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_main['popularity tier'] = sales_main['umbrella part id'].map(dict(zip(pop1['umbrella part id'], pop1['popularity tier'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find parts that have fewer than 3 months of recent data\n",
    "We'll label these with popularity = 'not enough data'\n",
    "\n",
    "These are parts which are in sales_main but not in pop_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = set(sales_main['part id'])\n",
    "s2 = set(pop_main['part id'])\n",
    "s3 = list(s1 - s2)\n",
    "\n",
    "sales_main['popularity tier'] = np.where(sales_main['part id'].isin(s3), '05 - not enough data', sales_main['popularity tier'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check popularity tier counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">part id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bom type</th>\n",
       "      <th>kitted</th>\n",
       "      <th>pnp</th>\n",
       "      <th>row total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>popularity tier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01 - key</th>\n",
       "      <td>35</td>\n",
       "      <td>38</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02 - high</th>\n",
       "      <td>63</td>\n",
       "      <td>69</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03 - medium</th>\n",
       "      <td>88</td>\n",
       "      <td>101</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04 - low</th>\n",
       "      <td>173</td>\n",
       "      <td>214</td>\n",
       "      <td>387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05 - not enough data</th>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>column total</th>\n",
       "      <td>392</td>\n",
       "      <td>430</td>\n",
       "      <td>822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     part id               \n",
       "bom type              kitted  pnp row total\n",
       "popularity tier                            \n",
       "01 - key                  35   38        73\n",
       "02 - high                 63   69       132\n",
       "03 - medium               88  101       189\n",
       "04 - low                 173  214       387\n",
       "05 - not enough data      33    8        41\n",
       "column total             392  430       822"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc = sales_main.groupby(['popularity tier','bom type'])[['part id']].nunique().unstack(1)\n",
    "vc.loc['column total'] = vc.sum()\n",
    "vc[('part id','row total')] = vc.sum(1)\n",
    "vc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check unique part id count after mapping pop tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match\n"
     ]
    }
   ],
   "source": [
    "v1 = vc.loc['column total',('part id','row total')]\n",
    "v2 = len(set(sales_main['part id']))\n",
    "\n",
    "if v1 == v2:\n",
    "    print('match')\n",
    "else:\n",
    "    print('mismatch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no nulls\n"
     ]
    }
   ],
   "source": [
    "n = np.sum(sales_main.isnull().any(1))\n",
    "if n == 0:\n",
    "    print('no nulls')\n",
    "else:\n",
    "    print('nulls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check over all qty total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "v1 = sales_super_main[sales_super_main['date purchased'] <= date_end]['qty total'].sum()\n",
    "v2 = sales_main['qty total'].sum()\n",
    "if  v1 == v2:\n",
    "    print('match')\n",
    "else:\n",
    "    print('mismatch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write parts to Excel, for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if write == 'yes':\n",
    "    k = skus_for_excel.copy()\n",
    "    k['popularity tier'] = k['part id'].map(dict(zip(sales_main['umbrella part id'], sales_main['popularity tier'])))\n",
    "    k.sort_values(['bom type','popularity tier','part id'], inplace = True)\n",
    "\n",
    "    excluded.sort_values(['bom type','part id'], inplace = True)\n",
    "\n",
    "    writer = pd.ExcelWriter('Parts Used in the War Chest 2018 Forecasts - for GitHub Portfolio.xlsx', engine = 'xlsxwriter')\n",
    "\n",
    "    k.to_excel(writer, 'parts used', index = False)\n",
    "    excluded.to_excel(writer, 'parts excluded', index = False)\n",
    "\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for forecasting\n",
    "Use umbrella PN\n",
    "\n",
    "Use mod qty total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_forecast = pd.DataFrame()\n",
    "\n",
    "for pn in list(set(sales_main['umbrella part id'])):\n",
    "    \n",
    "    # get qty per month\n",
    "    df1 = sales_main[sales_main['umbrella part id'] == pn].groupby('year and month')[['mod qty total']].sum()\n",
    "\n",
    "    # fill in months where no one bought anything\n",
    "    # make the final year and month the date_end of this script\n",
    "    d1 = df1.index.min()\n",
    "    d2 = date_end[:7]\n",
    "    \n",
    "    dates = pd.date_range(d1, d2, freq = 'MS')\n",
    "    \n",
    "    # make it so that every PN has at least 6 months of data\n",
    "    n = 6\n",
    "    l = len(dates)\n",
    "    if l < n:\n",
    "        new_d1 = pd.to_datetime(d1) - pd.DateOffset(months = (n-l))\n",
    "        new_d1 = str(new_d1)[:7]\n",
    "        dates = pd.date_range(new_d1, d2, freq = 'MS')\n",
    "    \n",
    "    dates = pd.DataFrame(dates, columns = ['year and month']).set_index('year and month')\n",
    "    # join them\n",
    "    df2 = dates.join(df1).fillna(0) \n",
    "    df2['umbrella part id'] = pn\n",
    "    df2.reset_index(inplace = True)\n",
    "    \n",
    "    # create one big dataframe, for the forecast\n",
    "    for_forecast = for_forecast.append(df2, ignore_index = True)\n",
    "\n",
    "# map popularity tier and bom\n",
    "for col in ['bom type','popularity tier']:\n",
    "    for_forecast[col] = for_forecast['umbrella part id'].map(dict(zip(sales_main['umbrella part id'], sales_main[col])))\n",
    "    \n",
    "# rename these for a layman to understand\n",
    "for_forecast.rename(columns = {'umbrella part id':'part id',\n",
    "                              'mod qty total':'qty total'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sku ids and part names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "k.sku_id,\n",
    "k.part_id,\n",
    "pd.products_name\n",
    "FROM skus k\n",
    "JOIN products_description pd ON k.part_id = pd.part_id\n",
    "WHERE k.sku_status = 'working'\n",
    "AND k.part_id IN '''+ str(tuple(for_forecast['part id'].tolist())) +'''\n",
    "''', db)\n",
    "\n",
    "col_fix(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['sku id','products name']:\n",
    "    for_forecast[col] = for_forecast['part id'].map(dict(zip(s['part id'], s[col])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no nulls\n"
     ]
    }
   ],
   "source": [
    "n = np.sum(for_forecast.isnull().any(1))\n",
    "if n == 0:\n",
    "    print('no nulls')\n",
    "else:\n",
    "    print('nulls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check count of data points per PN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match\n"
     ]
    }
   ],
   "source": [
    "c = np.sum(for_forecast.groupby('part id')[['year and month']].count() < n).values[0]\n",
    "if c == 0:\n",
    "    print('match')\n",
    "else:\n",
    "    print('mismatch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check unique PN count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match\n",
      "the total unique part count is 723\n"
     ]
    }
   ],
   "source": [
    "v1 = len(set(for_forecast['part id']))\n",
    "v2 = len(set(sales_main['umbrella part id']))\n",
    "if v1 == v2:\n",
    "    print('match')\n",
    "    print('the total unique part count is {}'.format(v1))\n",
    "else:\n",
    "    print('mismatch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match\n"
     ]
    }
   ],
   "source": [
    "q1 = for_forecast['qty total'].sum()\n",
    "q2 = sales_main['mod qty total'].sum()\n",
    "\n",
    "if np.abs(q1 - q2) < 0.01:\n",
    "    print('match')\n",
    "else:\n",
    "    print('mismatch')    \n",
    "    \n",
    "# fill zeros with 0.1, to ease forecasting\n",
    "for_forecast['qty total'] = np.where(for_forecast['qty total'] == 0, 0.1, for_forecast['qty total'])        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Excel, for R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if write == 'yes':\n",
    "    writer = pd.ExcelWriter('War Chest Part sales for R -  for GitHub Portfolio.xlsx', engine = 'xlsxwriter')\n",
    "    for_forecast.to_excel(writer, 'data', index = False)\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
