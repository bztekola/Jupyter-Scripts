jupyter script you want:
XGBoost Normalized Large

storage:
S3 > Shop SageMaker > Box pred > test_set_xg, training_set_xg, validation_set_xg > DL CSVs

parts table for k means group column

check out github link for k means in-depth

stats > shipping boxes > create training data button


#=====

PLM > shipping boxes
add a box
create training data
this creates the training CSV
then in sagemaker, AWS takes in this training CSV via your jupyter notebook ("XGBoost normalized large" script)

#=====

plenty of box/predictor/k means shit on github, to look at for example