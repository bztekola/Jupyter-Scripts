{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/Users/jarad/fake_folder/Python Libraries/')\n",
    "\n",
    "from jb_libraries import *\n",
    "%matplotlib inline\n",
    "\n",
    "date_start = '2017-09-09'\n",
    "date_end = '2018-10-09'\n",
    "\n",
    "ww_date_start = '2018-09-09'\n",
    "ww_date_end = '2018-10-09'\n",
    "\n",
    "a = str((pd.to_datetime(date_end) - pd.DateOffset(months = 3)).date())\n",
    "three_months_ago = a[:7] + '-01'\n",
    "\n",
    "one_month_ago = date_end[:7] + '-01'\n",
    "\n",
    "predictor_date_start = '2018-04-01' # it was actually 2018-03-25 but start it in april\n",
    "\n",
    "loss_date_start = three_months_ago\n",
    "loss_date_end = date_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stuff\n",
    "* Info in email with subject line \"Jupyter notebook for shipping box predictor\"\n",
    "* And in email with subject line \"Box Predictor Assessment\"\n",
    "* And Shipping Audit (Monthly and Weekly) Basecamp\n",
    "\n",
    "*****\n",
    "\n",
    "### Links\n",
    "* [UPS Actual vs Dim Weight](https://www.ups.com/us/en/help-center/packaging-and-supplies/determine-billable-weight.page)\n",
    "* [Quick Reference Guide to Avoid Shipping Charge Corrections](https://www.ups.com/us/en/help-center/billing-payment/avoid-charges.page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current state of UPS shipping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get UPS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ups_super_main = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "*\n",
    "FROM ups_billing\n",
    "WHERE orders_id IN (SELECT orders_id FROM orders WHERE DATE(date_purchased) BETWEEN ' '''+ date_start +''' ' AND ' '''+ date_end +''' ')\n",
    "AND orders_id NOT IN (SELECT orders_id FROM subscriptions_history) # exclude adabox\n",
    "''', db)\n",
    "\n",
    "col_fix(ups_super_main)\n",
    "ups_super_main['charge description'] = ups_super_main['charge description'].str.lower()\n",
    "\n",
    "# clean up charge descriptions\n",
    "df = ups_super_main['charge description'].str.split(' ', expand = True)\n",
    "ups_super_main = ups_super_main.join(df)\n",
    "\n",
    "# get the first two words of each charge description\n",
    "ups_super_main['jb charge description'] = ups_super_main[0] + ' ' + ups_super_main[1]\n",
    "\n",
    "# manual fix\n",
    "ups_super_main['jb charge description'] = np.where(ups_super_main['charge description'] == 'qst', 'qst', ups_super_main['jb charge description'])\n",
    "\n",
    "# clean further\n",
    "def clean(x):\n",
    "    if 'ground' in x['jb charge description'] and 'return' not in x['jb charge description']:\n",
    "        return 'ground'\n",
    "    elif 'return' in x['jb charge description']:\n",
    "        return 'returns'\n",
    "    elif 'broker' in x['jb charge description']:\n",
    "        return 'brokerage fees'\n",
    "    elif 'shipping charge' in x['jb charge description']:\n",
    "        return 'shipping charge correction'    \n",
    "    else:\n",
    "        return x['jb charge description']\n",
    "    \n",
    "# this just shortens the original UPS charge description, doesn't change anything else\n",
    "ups_super_main['jb charge description'] = ups_super_main.apply(clean, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get orders data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ot_main = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "DATE(date_purchased) AS date_purchased,\n",
    "DATE_FORMAT(date_purchased, '%Y-%m') AS year_and_month,\n",
    "ot1.orders_id,\n",
    "ot1.value + IFNULL(ot2.value,0) AS shipping_revenue\n",
    "FROM orders_total ot1\n",
    "\n",
    "RIGHT JOIN orders o ON ot1.orders_id = o.orders_id\n",
    "AND DATE(date_purchased) BETWEEN ' '''+ date_start +''' ' AND ' '''+ date_end +''' '\n",
    "AND o.orders_id NOT IN (SELECT orders_id FROM subscriptions_history) # exclude adabox\n",
    "\n",
    "LEFT JOIN orders_total ot2 ON o.orders_id = ot2.orders_id\n",
    "AND ot2.class = 'ot_ddp'\n",
    "\n",
    "WHERE ot1.class = 'ot_shipping'\n",
    "AND ot1.value > 0 # exclude \"free shipping\"\n",
    "''', db)\n",
    "\n",
    "col_fix(ot_main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join the two and clean it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the two\n",
    "# not that this is a left join onto orders_total\n",
    "# recall that we excluded adabox and free shipping\n",
    "df1 = ot_main.set_index('orders id')\n",
    "df2 = ups_super_main.groupby('orders id')[['netAmount']].sum()\n",
    "\n",
    "ups_main = df1.join(df2)\n",
    "\n",
    "# find nulls\n",
    "nulls = ups_main[ups_main.isnull().any(1)].copy()\n",
    "\n",
    "# veiw shipping_modeul_codes of nulls\n",
    "a = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "shipping_module_code,\n",
    "COUNT(shipping_module_code) AS count\n",
    "FROM orders\n",
    "WHERE orders_id IN '''+ str(tuple(nulls.index.tolist())) +'''\n",
    "GROUP BY shipping_module_code\n",
    "''', db)\n",
    "\n",
    "print('shipping module codes of nulls\\n')\n",
    "print(a)\n",
    "print('we only care about UPS and where we have UPS billing data, so drop these nulls')\n",
    "print('assume the UPS nulls are because we do not yet have shipping billing data')\n",
    "\n",
    "# clean it up\n",
    "ups_main.reset_index(inplace = True)\n",
    "ups_main.dropna(inplace = True)\n",
    "ups_main.rename(columns = {'netAmount':'ups charge'}, inplace = True)\n",
    "\n",
    "# create cols\n",
    "ups_main['overcharge'] = np.where(ups_main['ups charge'] > ups_main['shipping revenue'], 'yes', 'no')\n",
    "ups_main['shipping profit'] = ups_main['shipping revenue'] - ups_main['ups charge']\n",
    "\n",
    "# put all charges on one line per OID\n",
    "# omit fuel because it's pretty much in every order\n",
    "a = ups_super_main.groupby(['orders id','jb charge description'], as_index = False)[['tracking']].count() # we're not really counting anything; this is just a grupby trick\n",
    "a.drop(a[a['jb charge description'] == 'fuel surcharge'].index, inplace = True)\n",
    "\n",
    "b = a.groupby('orders id')['jb charge description'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "c = pd.DataFrame(b)\n",
    "c.reset_index(inplace = True)\n",
    "\n",
    "# this is just a sentence that lists the ups_main charges, so no changes to any values\n",
    "ups_main = pd.merge(ups_main, c, on = 'orders id')\n",
    "\n",
    "# get date purchased\n",
    "ups_main['date purchased'] = pd.to_datetime(ups_main['date purchased'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ups_main.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overcharges by year and month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_month = ups_main.groupby(['year and month','overcharge'])[['shipping profit']].sum().unstack(1).fillna(0)\n",
    "by_month.columns = by_month.columns.droplevel(0)\n",
    "by_month['net'] = by_month.sum(1)\n",
    "\n",
    "print(by_month.describe())\n",
    "by_month.format_(['m0'] * len(by_month.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = by_month.plot(kind = 'bar',\n",
    "                     subplots = True,\n",
    "                     figsize = (5,7),\n",
    "                     alpha = 0.65,\n",
    "                     grid = True,\n",
    "                     title = 'UPS shipping profit ($)',\n",
    "                     legend = False,\n",
    "                     rot = 45,\n",
    "                     width = 0.45,\n",
    "                     edgecolor = 'black')\n",
    "axes[0].set_title('did not incur a loss')\n",
    "axes[1].set_title('did incur a loss')\n",
    "axes[2].set_title('overall profit')\n",
    "for i in range(3):\n",
    "    axes[i].set_yticklabels('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_main = ups_main[(ups_main['overcharge'] == 'yes')\n",
    "                     & (ups_main['date purchased'].between(loss_date_start, loss_date_end))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall that this groupby column is just a sentence of all the UPS charges, excluding fuel\n",
    "# no values have been changed anywhere\n",
    "by_charge = losses_main.groupby('jb charge description')[['shipping profit']].sum()\n",
    "by_charge.sort_values('shipping profit', inplace = True)\n",
    "\n",
    "for_chart = by_charge.iloc[:10][::-1]\n",
    "for_chart = for_chart * -1\n",
    "\n",
    "\n",
    "ax = for_chart.plot(kind = 'barh',\n",
    "                    grid = True,\n",
    "                    color = 'red',\n",
    "                    alpha = 0.45,\n",
    "                    title = 'UPS profit losses by charge descriptions per order\\nfrom {} to {}'.format(loss_date_start, loss_date_end),\n",
    "                    edgecolor = 'black',\n",
    "                    legend = False)\n",
    "ax.set_ylabel('')\n",
    "ax.set_xticklabels(['-${:,.0f}'.format(x) for x in ax.get_xticks()])\n",
    "plt.show()\n",
    "\n",
    "for_chart = for_chart * -1\n",
    "print(for_chart.iloc[::-1].format_(['m0']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of charge combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the value counts of each charge description\n",
    "v = losses_main['jb charge description'].value_counts()\n",
    "\n",
    "# get the count of all unique OIDs\n",
    "t = len(set(losses_main['orders id']))\n",
    "\n",
    "# divide count of charge descriptions by total OID count to get the frequency of each charge description combination\n",
    "df = pd.DataFrame(v/t)\n",
    "df.columns = ['frequency']\n",
    "\n",
    "top = 10\n",
    "for_chart = df.iloc[:top][::-1] # get the top ten; reverse the order of counts, for the chart\n",
    "\n",
    "ax = for_chart.plot(kind = 'barh',\n",
    "                    grid = True,\n",
    "                    color = 'green',\n",
    "                    alpha = 0.45,\n",
    "                    title = 'frequency of top ten charges per order which incurred a loss\\nfrom {} to {}'.format(loss_date_start, loss_date_end),\n",
    "                    edgecolor = 'black',\n",
    "                    legend = False)\n",
    "ax.set_ylabel('')\n",
    "ax.set_xticklabels(['{:,.0f}%'.format(x * 100) for x in ax.get_xticks()])\n",
    "plt.show()\n",
    "\n",
    "print(for_chart.iloc[::-1].format_(['p2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get box predictor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('predictor data from {} to {}'.format(predictor_date_start, date_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get shipping quotes\n",
    "sq_main = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "DATE(date_purchased) AS date_purchased,\n",
    "DATE_FORMAT(date_purchased, '%Y-%m') AS year_and_month,\n",
    "s.*,\n",
    "o.shipping_module_code AS service\n",
    "FROM shipping_quotes s\n",
    "LEFT JOIN orders o ON s.orders_id = o.orders_id\n",
    "WHERE DATE(date_purchased) BETWEEN ' '''+ predictor_date_start +''' ' AND ' '''+ date_end +''' '\n",
    "''', db)\n",
    "\n",
    "col_fix(sq_main)\n",
    "\n",
    "# get actual\n",
    "sl_main = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "orders_id,\n",
    "sl_weight,\n",
    "sl_box\n",
    "FROM ship_log\n",
    "WHERE shipped_date BETWEEN ' '''+ predictor_date_start +''' ' AND ' '''+ date_end +''' '\n",
    "''', db)\n",
    "\n",
    "col_fix(sl_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the data together\n",
    "# note the left join into sl_main\n",
    "box_main = pd.merge(sl_main, sq_main, how = 'left', on = 'orders id')\n",
    "\n",
    "# rename cols\n",
    "box_main.rename(columns = {'sl weight':'pred weight',\n",
    "                           'sl box':'pred box',\n",
    "                           'weight':'actual weight',\n",
    "                           'box':'actual box'}, inplace = True)\n",
    "\n",
    "# rearrange them,\n",
    "ls = box_main.columns.tolist()\n",
    "for x in ['pred weight','pred box','actual weight','actual box']:\n",
    "    ls.remove(x)\n",
    "ls = ls + ['pred weight','actual weight','pred box','actual box']\n",
    "\n",
    "box_main = box_main[ls]\n",
    "\n",
    "# find nulls\n",
    "nulls = box_main[box_main.isnull().any(1)]\n",
    "print('{:,.0f} nulls after joining ship_log and shipping_quotes'.format(len(nulls)))\n",
    "print('or {:,.2f}% of total lines'.format(len(nulls)/len(box_main) * 100))\n",
    "print('remove these')\n",
    "box_main.dropna(inplace = True)\n",
    "\n",
    "# find zeros\n",
    "zero = box_main[box_main['actual weight'] == 0]\n",
    "print('\\n{:,.0f} lines where actual weight is zero'.format(len(zero)))\n",
    "print('drop these')\n",
    "box_main = box_main[box_main['actual weight'] > 0].copy()\n",
    "\n",
    "# to int; round up\n",
    "for col in ['actual','pred']:\n",
    "    box_main[col + ' box'] = box_main[col + ' box'].astype(int)\n",
    "    box_main[col + ' weight rounded'] = np.ceil(box_main[col + ' weight'])    \n",
    "\n",
    "# get summary columns    \n",
    "box_main['weight error %'] = np.abs((box_main['actual weight'] - box_main['pred weight'])/box_main['actual weight'])\n",
    "box_main['weight error % rounded'] = np.abs((box_main['actual weight rounded'] - box_main['pred weight rounded'])/box_main['actual weight rounded'])\n",
    "box_main['correct box'] = np.where(box_main['actual box'] == box_main['pred box'], 1, 0)    \n",
    "\n",
    "# exclude these services\n",
    "ls = ['','resellershipping','sameday']\n",
    "box_main = box_main[~box_main['service'].isin(ls)].copy()\n",
    "\n",
    "# view results\n",
    "print('\\ncount of services in this data:')\n",
    "print(box_main['service'].value_counts())\n",
    "\n",
    "# get box-qty\n",
    "print('\\nvalue counts of box-qty per OID:')\n",
    "print(box_main['qty'].value_counts())\n",
    "print('\\nthe majority of box-qty\\'s are x1\\nexclude anything greater than one\\n')\n",
    "box_main = box_main[box_main['qty'] == 1].copy()\n",
    "\n",
    "dupes = np.sum(box_main['orders id'].duplicated())\n",
    "print('\\n{} dupe OIDs\\nremove them'.format(dupes))\n",
    "box_main.drop_duplicates('orders id', inplace = True)\n",
    "\n",
    "print('\\ntotal count of lines in dataset: {:,.0f}'.format(len(box_main)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose your service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = ['upsxml']\n",
    "\n",
    "box_main.drop(box_main[~box_main['service'].isin(service)].index, inplace = True)\n",
    "\n",
    "m1 = box_main['date purchased'].min()\n",
    "m2 = box_main['date purchased'].max()\n",
    "print('service is {}\\ncount of lines is {:,.0f}\\ndata is from {} to {}'.format(service, len(box_main), m1, m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_main.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Error %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_summary = box_main.groupby('year and month')[['weight error %']].describe()\n",
    "weight_summary.columns = weight_summary.columns.droplevel(0)\n",
    "\n",
    "mean = box_main['weight error %'].mean()\n",
    "print('mean weight error % for {} is {:,.2f}%'.format(service, mean * 100))\n",
    "\n",
    "weight_summary.format_(['n0'] + ['p2'] * (len(weight_summary.columns) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = box_main['weight error %'].hist(bins = 900)\n",
    "ax.set_xlim(0,4)\n",
    "ax.set_title('Histogram of \"weight error %\" per box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct box?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_summary = box_main.groupby('year and month').agg({'orders id':'count',\n",
    "                                                      'correct box':'sum'}).rename(columns = {'orders id':'unique OID count'})\n",
    "box_summary['% correct'] = box_summary['correct box']/box_summary['unique OID count']\n",
    "\n",
    "val1 = box_main['correct box'].sum()\n",
    "val2 = len(box_main)\n",
    "print('from {} to {}'.format(predictor_date_start, date_end))\n",
    "print('overall correct-box result is {:,.2f}% correct'.format(val1/val2 * 100))\n",
    "\n",
    "box_summary.format_(['n0','n0','p2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = box_main['correct box'].value_counts().plot(kind = 'bar', color = 'purple', alpha = 0.65, edgecolor = 'black')\n",
    "ax.set_xticklabels(['Correct Box','Incorrect Box'], rotation = 0)\n",
    "ax.set_title('Box Prediction Results\\nfrom {} to {}'.format(predictor_date_start, date_end))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only WW Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charge = 'worldwide'\n",
    "\n",
    "# get data\n",
    "ww_main = ups_main[ups_main['date purchased'].between(ww_date_start, ww_date_end)\n",
    "                & (ups_main['jb charge description'].str.contains(charge))].copy()\n",
    "\n",
    "# create this flag\n",
    "ww_main['residential charge'] = np.where(ww_main['jb charge description'].str.contains('residential'),\n",
    "                                        'yes','no')\n",
    "\n",
    "# view some descriptors\n",
    "dupes = np.sum(ww_main['orders id'].duplicated())\n",
    "print('{} dupe OIDs'.format(dupes))\n",
    "\n",
    "print('\\ntotal count of OIDs: {:,.0f}\\n'.format(len(ww_main)))\n",
    "\n",
    "print('\\ndata is from {} to {}'.format(ww_date_start, ww_date_end))\n",
    "\n",
    "print('\\nthese are all of the charge-combinations and their counts for the WW services only:\\n')\n",
    "print(ww_main['jb charge description'].value_counts())\n",
    "\n",
    "print('\\ncount of overcharges within this dataset:\\n')\n",
    "print(ww_main['overcharge'].value_counts())\n",
    "\n",
    "print('\\ncount of overcharges WITH residential charges within this dataset:\\n')\n",
    "print(ww_main[ww_main['residential charge'] == 'yes']['overcharge'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Service and Accessorial Charge, and Shipping Charge Correction flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ups_super_main[ups_super_main['orders id'].isin(ww_main['orders id'].tolist())].copy()\n",
    "\n",
    "# isolate \"service charges\"\n",
    "service = ['fuel surcharge',\n",
    "          'worldwide expedited',\n",
    "          'worldwide expedited shipment',\n",
    "          'worldwide express',\n",
    "          'worldwide saver',\n",
    "          'worldwide saver shipment']\n",
    "\n",
    "# isolate shipping charge corrections\n",
    "correction = ['shipping charge correction expedited',\n",
    "              'shipping charge correction express',\n",
    "              'shipping charge correction fuel surcharge',\n",
    "              'shipping charge correction worldwide saver']\n",
    "\n",
    "# isolate accessorial charges\n",
    "accessorial = list(set(df['charge description']))\n",
    "\n",
    "# then remove \"service\" and \"corrections\"\n",
    "for x in service + correction:\n",
    "    try:\n",
    "        accessorial.remove(x)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "# now you have just \"accessorial charges\"    \n",
    "\n",
    "# store them in this dict\n",
    "d = {'service charge':service,\n",
    "    'shipping charge correction':correction,\n",
    "    'accessorial charge':accessorial}\n",
    "\n",
    "print('these are all of the charges in this dataset')\n",
    "for k,v in d.items():\n",
    "    print('\\n' + k + '\\n')\n",
    "    for v2 in v:\n",
    "        print(v2)\n",
    "        \n",
    "# create this column        \n",
    "df['charge type'] = df['charge description']\n",
    "for k,v in d.items():\n",
    "    for v2 in v:\n",
    "        df['charge type'] = df['charge type'].replace(v,k)        \n",
    "        \n",
    "# groupby OID\n",
    "df2 = df.groupby(['orders id','charge type'])[['netAmount']].sum().unstack(1).fillna(0)\n",
    "df2.columns = df2.columns.droplevel(0)     \n",
    "df2.reset_index(inplace = True)\n",
    "\n",
    "# map these \"charge types\" to ww_main\n",
    "for col in df2.columns:\n",
    "    ww_main[col] = ww_main['orders id'].map(dict(zip(df2['orders id'], df2[col])))\n",
    "    \n",
    "print('\\n{} null(s)'.format(np.sum(ww_main.isnull().any(1))))    \n",
    "\n",
    "# push some columns to the end of the data\n",
    "cols = ww_main.columns.tolist()\n",
    "ls = ['ups charge','shipping revenue','shipping profit']\n",
    "for x in ls:\n",
    "    cols.remove(x)\n",
    "cols = cols + ls\n",
    "\n",
    "ww_main = ww_main[cols]\n",
    "ww_main.rename(columns = {'ups charge':'ups total charge'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Did or did not cover service charge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_book = 'no'\n",
    "\n",
    "# this data consists of OIDs that:\n",
    "# went via some WW service\n",
    "# AND incurred an overcharge\n",
    "# AND incurred a residential charge\n",
    "\n",
    "# then we go further and ask: of these OIDs,\n",
    "    # which ones did the shipping revenue cover the service charge,\n",
    "    # and which ones did not\n",
    "for_x = ww_main[(ww_main['overcharge'] == 'yes')\n",
    "              & (ww_main['jb charge description'].str.contains('residential'))].copy()\n",
    "\n",
    "d1 = for_x['date purchased'].min().date()\n",
    "d2 = for_x['date purchased'].max().date()\n",
    "print('data is from {} to {}\\n'.format(d1,d2))\n",
    "\n",
    "a = for_x[for_x['shipping revenue'] >= for_x['service charge']] # covered service charge\n",
    "b = for_x[for_x['shipping revenue'] < for_x['service charge']] # did not cover service charge\n",
    "t = len(for_x)\n",
    "print('count of all lines: {}\\ncovered service charge: {}\\ndid not cover service charge: {}'.format(t, len(a), len(b)))\n",
    "\n",
    "if write_book == 'yes':\n",
    "    m1 = str(for_x['date purchased'].min().date())\n",
    "    m2 = str(for_x['date purchased'].max().date())\n",
    "    \n",
    "    title = 'Worldwide and Residential Charge data from {} to {}'.format(m1,m2)\n",
    "    writer = pd.ExcelWriter(title + '.xlsx', engine = 'xlsxwriter')    \n",
    "    \n",
    "    a.to_excel(writer, 'covered basis cost', index = False)\n",
    "    b.to_excel(writer, 'did not cover basis cost', index = False)\n",
    "    \n",
    "    # to show which UPS charges are in each \"charge type\"\n",
    "    c = pd.DataFrame.from_dict(d, orient = 'index').T.fillna('')\n",
    "    c.to_excel(writer, 'breakdown of charge types', index = False)\n",
    "    \n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entered vs Billed Weight \n",
    "* From Daigo via Shipping Audit (Monthly and Weekly) Basecamp\n",
    "* 1.) box predictor picks a weight and a box. \n",
    "* 2.) We send the weight and the box size to UPS's api, and they return to us a quoted price.\n",
    "* 3.)  this price shows up on checkout, and if the customer makes an order then the box and weight is saved into shipping_quotes. \n",
    "* 4.) shipper actually ships it, which involves weighing the actual box. this weight and box gets logged to ship_log, and hob sends that weight and box size to a different UPS api\n",
    "* 5.) UPS returns us a shipping label, which has price and dim weight recorded. This is the weight that will eventually be returned to us as 'entered weight' as well\n",
    "* 6.) UPS sends us an invoice with 'entered weight' and 'billed weight', where entered weight is what we sent them for the package in step 4 (supposedly),  and 'billed weight' is the value that they got when they weighed and measured it independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ww_date_start\n",
    "e = ww_date_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_main = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "\n",
    "DATE(date_purchased) AS date_purchased,\n",
    "DATE_FORMAT(date_purchased, '%Y-%m') AS year_and_month,\n",
    "ups.orders_id,\n",
    "tracking,\n",
    "LOWER(charge_description) AS charge_description,\n",
    "entered_weight,\n",
    "billed_weight\n",
    "\n",
    "FROM orders o\n",
    "\n",
    "LEFT JOIN ups_billing ups ON o.orders_id = ups.orders_id\n",
    "\n",
    "WHERE DATE(date_purchased) BETWEEN ' '''+ s +''' ' AND ' '''+ e +''' '\n",
    "AND shipping_module_code = 'upsxml'\n",
    "AND shippingcost > 0 # exclude free shipping\n",
    "AND ups.orders_id IS NOT NULL\n",
    "AND ups.billed_weight > 0\n",
    "''', db)\n",
    "\n",
    "# this function replaces the underscore in the column header with a space\n",
    "col_fix(weight_main)\n",
    "\n",
    "# find nulls, any and all\n",
    "print('{} null(s)'.format(np.sum(weight_main.isnull().any(1))))\n",
    "\n",
    "# get rid of the words \"residential\" and \"commercial\"\n",
    "weight_main['charge description'] = weight_main['charge description'].str.replace('residential|commercial','')\n",
    "\n",
    "# get rid of \"returns\", \"delivery intercepts\", and \"undeliverable\"\n",
    "ls = ['return','intercept','undeliverable']\n",
    "weight_main.drop(weight_main[weight_main['charge description'].str.contains('|'.join(ls))].index, inplace = True)\n",
    "\n",
    "d1 = weight_main['date purchased'].min()\n",
    "d2 = weight_main['date purchased'].max()\n",
    "\n",
    "print('\\ndata is from {} to {}\\n'.format(d1,d2))\n",
    "\n",
    "# view all the charge descriptions and their counts\n",
    "print('\\ncharge description counts over all UPS packages:\\n')\n",
    "\n",
    "v1 = weight_main['charge description'].value_counts()\n",
    "v2 = weight_main['charge description'].value_counts().sum()\n",
    "v = pd.DataFrame(v1)\n",
    "v.columns = ['count']\n",
    "v['%'] = v1/v2\n",
    "\n",
    "print(v.format_(['n0','p2']))\n",
    "\n",
    "# groupby year/month and tracking\n",
    "# grouping by tracking and not OID ensures that we capture multi-box shipments\n",
    "# get the min entered weight per tracking\n",
    "# get the max billed weight per tracking\n",
    "    # if there was a shipping charge correction,\n",
    "    # then this max weight is the final billed weight value after this correction\n",
    "weight = weight_main.groupby(['year and month','tracking'], as_index = False).agg({'entered weight':'min',\n",
    "                                                                                    'billed weight':'max'})\n",
    "# map OIDs to tracking\n",
    "weight['orders id'] = weight['tracking'].map(dict(zip(weight_main['tracking'], weight_main['orders id'])))\n",
    "\n",
    "# flag tracking for shipping charge corrections\n",
    "ls = weight_main[weight_main['charge description'].str.contains('shipping charge correction')]['tracking'].tolist()\n",
    "weight['shipping charge correction'] = np.where(weight['tracking'].isin(ls), 'yes', 'no')\n",
    "\n",
    "# get the weight difference\n",
    "weight['weight difference'] = weight['billed weight'] - weight['entered weight']\n",
    "\n",
    "# get the date purchased\n",
    "weight['date purchased'] = weight['orders id'].map(dict(zip(ot_main['orders id'], ot_main['date purchased'])))\n",
    "\n",
    "# get shipping revenue\n",
    "ship_revenue = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "ot1.orders_id,\n",
    "ot1.value + IFNULL(ot2.value, 0) AS shipping_revenue\n",
    "FROM orders_total ot1\n",
    "LEFT JOIN orders_total ot2 ON ot1.orders_id = ot2.orders_id\n",
    "AND ot2.class = 'ot_ddp'\n",
    "WHERE ot1.class = 'ot_shipping'\n",
    "AND ot1.orders_id IN '''+ str(tuple(weight_main['orders id'].tolist())) +'''\n",
    "''', db)\n",
    "\n",
    "col_fix(ship_revenue)\n",
    "\n",
    "# get shipping charges\n",
    "ship_charge = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "orders_id,\n",
    "SUM(netAmount) AS shipping_charge\n",
    "FROM ups_billing\n",
    "WHERE orders_id IN '''+ str(tuple(weight_main['orders id'].tolist())) +'''\n",
    "GROUP BY orders_id\n",
    "''', db)\n",
    "\n",
    "col_fix(ship_charge)\n",
    "\n",
    "# merge the two on OID\n",
    "df = pd.merge(ship_revenue, ship_charge, on = 'orders id')\n",
    "\n",
    "# flag overcharges\n",
    "df['overcharge'] = np.where(df['shipping revenue'] < df['shipping charge'], 'yes','no')\n",
    "ls = df[df['overcharge'] == 'yes']['orders id'].tolist()\n",
    "\n",
    "# map this result to your weight data\n",
    "# note that the data in the \"weight\" df is by tracking,\n",
    "    # so there are dupe OIDs,\n",
    "    # that's why we map the yes/no flag and not the actual rev/charge amounts\n",
    "weight['overcharge'] = np.where(weight['orders id'].isin(ls), 'yes', 'no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary and stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = len(weight)\n",
    "print('To ensure that we catch multi-box shipments, these counts are by tracking number and not by OID.')\n",
    "print('\\n{:,.0f} total tracking numbers considered\\nfrom dates {} to {}'.format(t, d1, d2)) # recall that the weight df is by tracking, not by OID\n",
    "\n",
    "print('\\nWHERE entered weight == 0\\nAND billed weight == 1')\n",
    "df1 = weight[(weight['entered weight'] == 0)\n",
    "           & (weight['billed weight'] == 1)]\n",
    "val1 = len(df1)\n",
    "print('{:,.2f}%\\nor {:,.0f} tracking numbers'.format(val1/t * 100, val1))\n",
    "\n",
    "print('\\nWHERE entered weight != billed weight\\nAND billed weight > 1')\n",
    "df2 = weight[(weight['entered weight'] != weight['billed weight'])\n",
    "           & (weight['billed weight'] > 1)]\n",
    "val2 = len(df2)\n",
    "print('{:,.2f}%\\nor {:,.0f} tracking numbers'.format(val2/t * 100, val2))\n",
    "\n",
    "print('\\nWHERE entered weight = billed weight')\n",
    "df3 = weight[weight['billed weight'] == weight['entered weight']]\n",
    "val3 = len(df3)\n",
    "print('{:,.2f}%\\nor {:,.0f} tracking numbers'.format(val3/t * 100, val3))\n",
    "\n",
    "print('\\nproportions check: they sum to {:,.0f}%'.format((val1 + val2 + val3)/t * 100))\n",
    "\n",
    "print('\\n=====\\n\\nGeneral Stats')\n",
    "\n",
    "print('\\nCount of overcharges')\n",
    "val6 = len(weight[(weight['overcharge'] == 'yes')])\n",
    "print('{:,.2f}%\\nor {:,.0f} tracking numbers'.format(val6/t * 100, val6))\n",
    "\n",
    "print('\\nCount of Shipping Charge Corrections')\n",
    "val4 = len(weight[weight['shipping charge correction'] == 'yes'])\n",
    "print('{:,.2f}%\\nor {:,.0f} tracking numbers'.format(val4/t * 100, val4))\n",
    "\n",
    "print('\\nCount of Shipping Charge Corrections AND Overcharges')\n",
    "val5 = len(weight[(weight['shipping charge correction'] == 'yes') & (weight['overcharge'] == 'yes')])\n",
    "print('{:,.2f}%\\nor {:,.0f} tracking numbers'.format(val5/t * 100, val5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write = 'no'\n",
    "\n",
    "if write == 'yes':\n",
    "    title = 'UPS Weight Data from {} to {}'.format(m1, m2)\n",
    "    writer = pd.ExcelWriter(title + '.xlsx', engine = 'xlsxwriter')\n",
    "    weight.to_excel(writer, 'data', index = False)\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See how many mismatched weights resulted in Shipping Charge Corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('data is from {} to {}'.format(d1,d2))\n",
    "df = weight_main[(weight_main['entered weight'] != weight_main['billed weight'])\n",
    "               & (weight_main['billed weight'] > 1)].copy()\n",
    "\n",
    "otb = pd.read_sql(\n",
    "'''\n",
    "SELECT \n",
    "orders_id,\n",
    "COUNT(orders_id) AS count\n",
    "FROM orders_to_boxes\n",
    "GROUP BY orders_id HAVING COUNT(orders_id) = 1 # only consider tracking numbers that were shipped using a single box, for simplicity\n",
    "''', db)\n",
    "\n",
    "col_fix(otb)\n",
    "\n",
    "c = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "tracking,\n",
    "SUM(netAmount) AS ups_charge,\n",
    "GROUP_CONCAT(LOWER(charge_description) SEPARATOR ', ') AS charge_description\n",
    "FROM ups_billing\n",
    "WHERE tracking IN '''+ str(tuple(df['tracking'].tolist())) +'''\n",
    "AND charge_description NOT LIKE '%fuel%' # for ease of reading, remove this charge\n",
    "GROUP BY tracking\n",
    "''', db)\n",
    "\n",
    "col_fix(c)\n",
    "\n",
    "t_to_o = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "orders_id,\n",
    "tracking\n",
    "FROM ups_billing\n",
    "WHERE tracking IN '''+ str(tuple(df['tracking'].tolist())) +'''\n",
    "''', db)\n",
    "col_fix(t_to_o)\n",
    "\n",
    "c['orders id'] = c['tracking'].map(dict(zip(t_to_o['tracking'], t_to_o['orders id'])))\n",
    "\n",
    "# only consider tracking numbers that were shipped using a single box, for simplicity\n",
    "c = c[c['orders id'].isin(otb['orders id'].tolist())].copy()\n",
    "\n",
    "df['charge description'] = df['tracking'].map(dict(zip(c['tracking'], c['charge description'])))\n",
    "df['billed minus entered'] = df['billed weight'] - df['entered weight']\n",
    "\n",
    "df['shipping charge correction'] = np.where(df['charge description'].str.contains('shipping charge correction'),\n",
    "                                           'yes', 'no')\n",
    "df['ups charge'] = df['tracking'].map(dict(zip(c['tracking'],c['ups charge'])))\n",
    "df['shipping revenue'] = df['orders id'].map(dict(zip(ot_main['orders id'],ot_main['shipping revenue'])))\n",
    "df['shipping profit'] = df['shipping revenue'] - df['ups charge']\n",
    "df['overcharge'] = np.where(df['shipping profit'] < 0,'yes','no')\n",
    "\n",
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['shipping charge correction','overcharge'])[['billed minus entered']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['billed minus entered'] > 35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Daigo:\n",
    "* From basecamp: \"...pick an order that we can look at the measurements for and confirm whether they're getting rounded down\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whelp, nice find! I've made a push to update these columns to have decimal accuracy, but unfortunately it'll\n",
    "    # only take effect for invoices that we import going forward. \n",
    "    # I'm thinking we can ignore those in the context of this conversation, \n",
    "    # except when the billed_weight is != 1 (ex 1809911), since that still \n",
    "    # isn't explained away by the rounding issue. \n",
    "    # this was on aug 9\n",
    "\n",
    "d = '2018-08-09'\n",
    "\n",
    "# get this data\n",
    "df1 = weight[(weight['entered weight'] > 0)\n",
    "           & (pd.to_datetime(weight['date purchased']) > d)]\n",
    "\n",
    "if df1.empty:\n",
    "    print('from {} onwards all entered_weight > zero'.format(d))\n",
    "else:\n",
    "\n",
    "    # make a list of OIDs\n",
    "    ls = df1['orders id'].tolist()\n",
    "\n",
    "    # get the actual weight of the package\n",
    "    s = pd.read_sql(\n",
    "    '''\n",
    "    SELECT\n",
    "    DATE(shipped_date) AS shipped_date,\n",
    "    orders_id,\n",
    "    sl_weight\n",
    "    FROM ship_log \n",
    "    WHERE orders_id IN '''+ str(tuple(ls)) +'''\n",
    "    ORDER BY orders_id\n",
    "    ''', db)\n",
    "\n",
    "    col_fix(s)\n",
    "\n",
    "    # join the two\n",
    "    df2 = df1[['orders id','entered weight']].set_index('orders id').join(s.set_index('orders id'))\n",
    "\n",
    "    # organize and rename\n",
    "    df2 = df2[['sl weight','entered weight','shipped date']]\n",
    "    df2.rename(columns = {'entered weight':'ups_billing.entered weight',\n",
    "                          'sl weight':'ship_log.sl_weight'}, inplace = True)\n",
    "\n",
    "    df2.reset_index(inplace = True)\n",
    "\n",
    "    # view this info\n",
    "    a = df2['shipped date'].min()\n",
    "    b = df2['shipped date'].max()\n",
    "    print('data is from {} to {}'.format(a,b))\n",
    "    print('WHERE ups_billing.entered_weight > 0 AND orders_total.date_purchased > 2018-08-09\\n')\n",
    "\n",
    "    # make this columns\n",
    "    df2['result'] = ''\n",
    "    for index, row in df2.iterrows():\n",
    "\n",
    "        if np.abs(row['ship_log.sl_weight'] - row['ups_billing.entered weight']) < 0.01:\n",
    "            df2.loc[index, 'result'] = 'equal'\n",
    "\n",
    "        else:\n",
    "            if np.ceil(row['ship_log.sl_weight']) == row['ups_billing.entered weight']:\n",
    "                df2.loc[index, 'result'] = 'rounded up'\n",
    "\n",
    "            elif np.floor(row['ship_log.sl_weight']) == row['ups_billing.entered weight']:\n",
    "                df2.loc[index, 'result'] = 'rounded down'     \n",
    "\n",
    "            else:\n",
    "                df2.loc[index, 'result'] = 'off by more than one pound'\n",
    "\n",
    "    # get a nice result\n",
    "    v1 = df2['result'].value_counts()\n",
    "    v2 = df2['result'].value_counts().sum()\n",
    "    v = pd.DataFrame(v1)\n",
    "    v.columns = ['count']\n",
    "    v['% of total'] = v1/v2\n",
    "    v.loc['total'] = v.sum()\n",
    "    print(v.format_(['n0','p2']))\n",
    "\n",
    "    print('\\ntop five \"rounded down\" by \"shipped date\"')\n",
    "    df2[df2['result'] == 'rounded down'].sort_values('shipped date', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = 'no'\n",
    "\n",
    "if close == 'yes':\n",
    "    writer = pd.ExcelWriter('UPS weight rounded down or up? from {} to {}.xlsx'.format(a,b), engine = 'xlsxwriter')\n",
    "    df2.to_excel(writer, 'data', index = False)\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Daigo, again, now with more conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = list(box_main[box_main['correct box'] == 1]['orders id'])\n",
    "\n",
    "df = weight[(weight['overcharge'] == 'yes')\n",
    "          & (weight['shipping charge correction'] == 'no')\n",
    "          & (weight['orders id'].isin(ls))\n",
    "          & (weight['entered weight'] != 0)].copy()\n",
    "\n",
    "for col in ['pred box','actual box','correct box']:\n",
    "    df[col] = df['orders id'].map(dict(zip(box_main['orders id'], box_main[col])))\n",
    "    \n",
    "for col in ['shipping revenue','ups charge','shipping profit','jb charge description']:\n",
    "    df[col] = df['orders id'].map(dict(zip(ups_main['orders id'], ups_main[col])))\n",
    "    \n",
    "df.sort_values('shipping profit', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FTP weight data\n",
    "### Be sure to check the CSV that you are uploading!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get and clean CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = r'/Users/jarad/fake_folder/Shipping/Projects/Box Predictor/Docs/FTP data for WW weights.csv'\n",
    "path = r'/Users/jarad/fake_folder/Shipping/Projects/Box Predictor/Docs/08_22_2018_ftp_csv.csv'\n",
    "\n",
    "# get data\n",
    "csv_main = pd.read_csv(path, low_memory = False, header = None)\n",
    "\n",
    "# rename cols\n",
    "cols = {11:'transaction date',\n",
    "        15:'orders id',\n",
    "        20:'tracking',\n",
    "        26:'entered weight',\n",
    "        28:'billed weight',        \n",
    "        35:'service',\n",
    "        44:'charge description code',\n",
    "        45:'charge description'}\n",
    "\n",
    "for k,v in cols.items():\n",
    "    csv_main.rename(columns = {k:v}, inplace = True)\n",
    "    \n",
    "# clean these    \n",
    "csv_main['transaction date'] = pd.to_datetime(csv_main['transaction date'])\n",
    "csv_main['charge description'] = [x.lower() for x in csv_main['charge description']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a copy and clean it\n",
    "* This data has exclusions; be sure to view them below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to exclude\n",
    "# note that we include Shipping Charge Corrections\n",
    "ls = ['return','undeliverable','not previously','collect','shipment']\n",
    "ls2 = '|'.join(ls)\n",
    "\n",
    "# make a copy\n",
    "csv_clean = csv_main[list(cols.values())][(csv_main['entered weight'] > 0) # to return only fields with an entered weight\n",
    "                                        & (~csv_main['charge description'].str.contains(ls2))].copy()\n",
    "\n",
    "# UPS should round any fractions of a pound up to the nearest whole pound\n",
    "# let's do that here\n",
    "csv_clean['entered weight (rounded)'] = np.ceil(csv_clean['entered weight'])\n",
    "\n",
    "# get difference\n",
    "csv_clean['weight difference'] = csv_clean['billed weight'] - csv_clean['entered weight (rounded)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare CSV with database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = csv_clean.set_index('tracking')\n",
    "a = a[['orders id','entered weight','billed weight']]\n",
    "a.columns = ['orders id','ftp entered weight','ftp billed weight']\n",
    "\n",
    "b = df1.set_index('tracking')\n",
    "b = b[['entered weight','billed weight','year and month']]\n",
    "b.columns = ['db entered weight','db billed weight','year and month']\n",
    "\n",
    "c = a.join(b).dropna()\n",
    "\n",
    "c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c[c['ftp billed weight'] > 1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View all charge descriptions after cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_clean['charge description'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data on the tracking number level\n",
    "# by getting the max billed weight, we get the weight of the shipping charge correction, if applicable\n",
    "    # if none, then this max weight is simply the max billed weight\n",
    "csv = csv_clean.groupby('tracking', as_index = False).agg({'entered weight':'min',\n",
    "                                                           'billed weight':'max'}) \n",
    "\n",
    "# map OID and date\n",
    "for col in ['orders id','transaction date']:\n",
    "    csv[col] = csv['tracking'].map(dict(zip(csv_main['tracking'], csv_main[col])))\n",
    "\n",
    "# UPS rounds up to the nearest whole pound\n",
    "csv['entered weight (rounded)'] = np.ceil(csv['entered weight'])\n",
    "\n",
    "# get the diff\n",
    "csv['weight difference'] = csv['billed weight'] - csv['entered weight (rounded)']\n",
    "\n",
    "# flag tracking numbers that incurred a shipping charge correction\n",
    "tracking = csv_clean[csv_clean['charge description'].str.contains('shipping charge correction')]['tracking'].tolist()\n",
    "csv['correction'] = np.where(csv['tracking'].isin(tracking), 'yes', 'no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entered weight (rounded) vs billed weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv[['entered weight (rounded)','billed weight']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportions of weight differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val1 = csv['weight difference'].value_counts()\n",
    "val2 = csv['weight difference'].value_counts().sum()\n",
    "\n",
    "d = pd.DataFrame(val1/val2)\n",
    "d['count'] = d['weight difference'] * val2\n",
    "\n",
    "# check your calcs\n",
    "if np.abs(d.iloc[:,0].sum() - 1) < 0.1 and np.abs(d.iloc[:,1].sum() - val2) < 0.1:\n",
    "    print('match\\n')\n",
    "else:\n",
    "    print('misatch\\n')\n",
    "\n",
    "# get the min and max date, for reference\n",
    "d1 = str((csv['transaction date'].min()).date())\n",
    "d2 = str((csv['transaction date'].max()).date())\n",
    "\n",
    "# print some info\n",
    "print('data is from {} to {}'.format(d1,d2))\n",
    "print('{:,.0f} unique tracking numbers'.format(len(set(csv['tracking']))))\n",
    "\n",
    "print('\\nweight difference proportions and counts\\n')\n",
    "print(d.format_(['p2','n0']))\n",
    "\n",
    "ax = d.iloc[:,0].iloc[:5].plot(kind = 'barh',\n",
    "                               color = 'purple',\n",
    "                               title = 'Difference between billed and entered weight (rounded)\\nTop 5',\n",
    "                               grid = True)\n",
    "ax.set_xticklabels(['{:,.0f}%'.format(x * 100) for x in ax.get_xticks()])\n",
    "ax.set_xlabel('proportion of whole')\n",
    "ax.set_ylabel('weight difference')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 95% Confidence interval for proportion of orders where entered != billed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = d['count'].sum()\n",
    "\n",
    "# return lines where \"weight diff\" > 0\n",
    "p = d[d.index > 0]['weight difference'].sum()\n",
    "phi = 1.96\n",
    "s = np.sqrt((p * (1-p))/n)\n",
    "\n",
    "lower = p - phi * s\n",
    "upper = p + phi * s\n",
    "\n",
    "print('95% confidence interval for proportion of orders with mismatched entered and billed weights\\n')\n",
    "print('lower: {:,.2f}%\\nmiddle: {:,.2f}%\\nupper: {:,.2f}%'.format(lower * 100, p * 100, upper * 100))\n",
    "print('sample size: {:,.0f} tracking numbers'.format(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shipping Charge Corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val1 = len(csv[csv['correction'] == 'yes'])\n",
    "val2 = len(csv)\n",
    "\n",
    "print('{:,.2f}% tracking numbers incurred a Shipping Charge Correction'.format(val1/val2 * 100))\n",
    "print('or {:,.0f} out of {:,.0f}'.format(val1, val2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight differences of trackings that incurred a shipping charge correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only tracking numbers that incurred this charge\n",
    "scc = csv[csv['correction'] == 'yes'].copy()\n",
    "\n",
    "# get the value counts per weight difference\n",
    "val1 = scc['weight difference'].value_counts()\n",
    "val2 = scc['weight difference'].value_counts().sum()\n",
    "\n",
    "df = pd.DataFrame(val1/val2)\n",
    "df['count'] = val1\n",
    "\n",
    "# check totals\n",
    "if np.abs(df.iloc[:,0].sum() - 1) < 0.1 and np.abs(df.iloc[:,1].sum() - val2) < 0.1:\n",
    "    print('match')\n",
    "else:\n",
    "    print('mismatch')\n",
    "\n",
    "# view it\n",
    "df.format_(['p2','n0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Follow-up check on 2018-10-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Aug 09 from Daigo via basecamp: Whelp, nice find! I've made a push to update these columns to have decimal accuracy, but unfortunately it'll only take effect for invoices that we import going forward. \n",
    "\n",
    "Below we check to see when the last orders_id had an entered_weight = zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_main = pd.read_csv(r'/Users/jarad/fake_folder/Shipping/Projects/Box Predictor/Docs/US_A71EY05 8.csv', encoding = 'ISO-8859-1', low_memory = False, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename cols\n",
    "cols = {11:'transaction date',\n",
    "        15:'orders id',\n",
    "        20:'tracking',\n",
    "        26:'ftp entered weight',\n",
    "        28:'ftp billed weight',        \n",
    "        35:'service',\n",
    "        44:'charge description code',\n",
    "        45:'charge description'}\n",
    "\n",
    "for k,v in cols.items():\n",
    "    csv_main.rename(columns = {k:v}, inplace = True)\n",
    "    \n",
    "# clean these    \n",
    "csv_main['transaction date'] = pd.to_datetime(csv_main['transaction date'])\n",
    "csv_main['charge description'] = [x.lower() for x in csv_main['charge description']]\n",
    "\n",
    "a = csv_main.groupby('tracking')[['ftp entered weight']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "DATE(o.date_purchased) AS date_purchased,\n",
    "ups.tracking,\n",
    "SUM(ups.entered_weight) AS ups_billing_entered_weight\n",
    "FROM ups_billing ups\n",
    "LEFT JOIN orders o ON ups.orders_id = o.orders_id\n",
    "WHERE DATE(transaction_date) >= '''+ str(d1) +'''\n",
    "GROUP BY ups.tracking\n",
    "''', db)\n",
    "col_fix(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a.join(b.set_index('tracking')[['ups billing entered weight']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['orders id','transaction date']:\n",
    "    c[col] = c.index.to_series().map(dict(zip(csv_main['tracking'], csv_main[col])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:,.0f} nulls'.format(np.sum(np.sum(c.isnull().any(1)))))\n",
    "c.dropna(inplace = True)\n",
    "\n",
    "d1 = csv_main['transaction date'].min().date()\n",
    "d2 = csv_main['transaction date'].max().date()\n",
    "print('ftp data from {} to {}'.format(d1,d2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(c[np.floor(c['ftp entered weight']) == c['ups billing entered weight']]))\n",
    "print('out of')\n",
    "print(len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c[np.floor(c['ftp entered weight']) == c['ups billing entered weight']].head(10)['orders id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order progression, for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oid = 1860847"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entered vs Billed Weight \n",
    "* From Daigo via Shipping Audit (Monthly and Weekly) Basecamp\n",
    "* 1.) box predictor picks a weight and a box. \n",
    "* 2.) We send the weight and the box size to UPS's api, and they return to us a quoted price.\n",
    "* 3.)  this price shows up on checkout, and if the customer makes an order then the box and weight is saved into shipping_quotes. \n",
    "* 4.) shipper actually ships it, which involves weighing the actual box. this weight and box gets logged to ship_log, and hob sends that weight and box size to a different UPS api\n",
    "* 5.) UPS returns us a shipping label, which has price and dim weight recorded. This is the weight that will eventually be returned to us as 'entered weight' as well\n",
    "* 6.) UPS sends us an invoice with 'entered weight' and 'billed weight', where entered weight is what we sent them for the package in step 4 (supposedly),  and 'billed weight' is the value that they got when they weighed and measured it independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "s.*,\n",
    "b.name,\n",
    "b.length,\n",
    "b.width,\n",
    "b.height,\n",
    "b.volume/139 AS dim_weight,\n",
    "CEILING(b.volume/139) AS dim_weight_rounded\n",
    "FROM shipping_quotes s\n",
    "JOIN boxes b ON s.box = b.sku_id\n",
    "WHERE orders_id = '''+ str(oid) +'''\n",
    "''', db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "s.*,\n",
    "b.name,\n",
    "b.length,\n",
    "b.width,\n",
    "b.height,\n",
    "b.volume/139 AS dim_weight,\n",
    "CEILING(b.volume/139) AS dim_weight_rounded\n",
    "FROM ship_log s\n",
    "JOIN boxes b ON s.sl_box = b.sku_id\n",
    "WHERE orders_id = '''+ str(oid) +'''\n",
    "''', db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "charge_description,\n",
    "entered_weight,\n",
    "billed_weight\n",
    "FROM ups_billing\n",
    "WHERE orders_id = '''+ str(oid) +'''\n",
    "''', db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_main[csv_main['orders id'] == str(oid)][['orders id','ftp entered weight','ftp billed weight']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare dim weights by rounding as explained here:\n",
    "https://www.ups.com/us/en/help-center/packaging-and-supplies/determine-billable-weight.page#contentBlock-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_log = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "s.orders_id,\n",
    "DATE(s.shipped_date) AS shipped_date,\n",
    "CEILING(s.sl_weight) AS sl_weight, # round up to the nearest pound, as per UPS\n",
    "b.name,\n",
    "b.length,\n",
    "b.width,\n",
    "b.height\n",
    "FROM ship_log s\n",
    "JOIN boxes b ON s.sl_box = b.sku_id\n",
    "WHERE DATE(s.shipped_date) >= '2018-09-01'\n",
    "''', db)\n",
    "\n",
    "col_fix(ship_log)\n",
    "ship_log.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounding example using this overly confusing module\n",
    "# https://gist.github.com/jackiekazil/6201722 \n",
    "\n",
    "from decimal import Decimal, ROUND_HALF_UP\n",
    "# Here are all your options for rounding:\n",
    "# This one offers the most out of the box control\n",
    "# ROUND_05UP       ROUND_DOWN       ROUND_HALF_DOWN  ROUND_HALF_UP\n",
    "# ROUND_CEILING    ROUND_FLOOR      ROUND_HALF_EVEN  ROUND_UP\n",
    "\n",
    "our_value = Decimal(2.5)\n",
    "output = Decimal(our_value.quantize(Decimal('1'), rounding = ROUND_HALF_UP))\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ups_rounding(x):\n",
    "    val = Decimal(x)\n",
    "    output = Decimal(val.quantize(Decimal('1'), rounding = ROUND_HALF_UP))\n",
    "    return output\n",
    "\n",
    "for col in ['length','width','height']:\n",
    "    ship_log[col + ' rounded'] = ship_log[col].apply(ups_rounding, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ups_main = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "orders_id,\n",
    "charge_description,\n",
    "billed_weight\n",
    "FROM ups_billing\n",
    "WHERE orders_id IN '''+ str(tuple(ship_log['orders id'])) +'''\n",
    "''', db)\n",
    "\n",
    "col_fix(ups_main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rounding example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oid = 1808679"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ups_main[ups_main['orders id'] == oid].sort_values('billed weight', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = ship_log[ship_log['orders id'] == oid].copy()\n",
    "ex['dim weight'] = np.ceil(ex[['length rounded','width rounded','height rounded']].product(1)/139)\n",
    "ex['billable weight'] = ex[['sl weight','dim weight']].max(1)\n",
    "ex.sort_values('billable weight', ascending = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the billable weights from ship_log match those from ups_billing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test this ups rounding on the entire data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dim weight and billed weight\n",
    "ship_log['dim weight'] = np.ceil(ship_log[['length rounded','width rounded','height rounded']].product(1)/139)\n",
    "ship_log['ship log billed weight'] = ship_log[['sl weight','dim weight']].max(1)\n",
    "\n",
    "# sum billed weight by OID\n",
    "ship_log_billed = ship_log.groupby('orders id', as_index = False)[['ship log billed weight']].sum()\n",
    "\n",
    "# leave out shipping charge corrections, sum billed weight by OID\n",
    "ups_billed = ups_main[~ups_main['charge description'].str.contains('Shipping Charge Correction')].groupby('orders id', as_index = False)[['billed weight']].sum()\n",
    "ups_billed.rename(columns = {'billed weight':'ups billed weight'}, inplace = True)\n",
    "\n",
    "# map UPS to ship_log\n",
    "billed = pd.merge(ship_log_billed, ups_billed, on = 'orders id', how = 'left')\n",
    "\n",
    "# remove where we do not yet have UPS data\n",
    "billed.dropna(subset = ['ups billed weight'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = len(billed)\n",
    "print('count of unique OIDs considered: {:,.0f}'.format(t))\n",
    "\n",
    "a = np.sum(billed['ship log billed weight'] < billed['ups billed weight'])\n",
    "print('ship_log < ups: {:,.2f}%'.format(a/t * 100))\n",
    "\n",
    "b = np.sum(billed['ship log billed weight'] == billed['ups billed weight'])\n",
    "print('ship_log = ups: {:,.2f}%'.format(b/t * 100))\n",
    "\n",
    "c = np.sum(billed['ship log billed weight'] > billed['ups billed weight'])\n",
    "print('ship_log > ups: {:,.2f}%'.format(c/t * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results without rounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_round = ship_log[['orders id','sl weight','name','length','width','height']].copy()\n",
    "no_round['dim weight'] = np.ceil(no_round[['length','width', 'height']].prod(1)/139)\n",
    "no_round['ship log billed weight'] = no_round[['sl weight','dim weight']].max(1)\n",
    "\n",
    "no_round_ship_log = no_round.groupby('orders id', as_index = False)[['ship log billed weight']].sum()\n",
    "\n",
    "no_round_billed = pd.merge(no_round_ship_log, ups_billed, on = 'orders id', how = 'left')\n",
    "no_round_billed.dropna(subset = ['ups billed weight'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = len(no_round_billed)\n",
    "print('count of unique OIDs considered: {:,.0f}'.format(t))\n",
    "\n",
    "a = np.sum(no_round_billed['ship log billed weight'] < no_round_billed['ups billed weight'])\n",
    "print('ship_log < ups: {:,.2f}%'.format(a/t * 100))\n",
    "\n",
    "b = np.sum(no_round_billed['ship log billed weight'] == no_round_billed['ups billed weight'])\n",
    "print('ship_log = ups: {:,.2f}%'.format(b/t * 100))\n",
    "\n",
    "c = np.sum(no_round_billed['ship log billed weight'] > no_round_billed['ups billed weight'])\n",
    "print('ship_log > ups: {:,.2f}%'.format(c/t * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Follow-up on 2018-10-03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oid = 1865347"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "s.*,\n",
    "b.name,\n",
    "b.length,\n",
    "b.width,\n",
    "b.height,\n",
    "CEILING((ROUND(b.length) * ROUND(b.height) * ROUND(b.width))/139) AS dim_weight\n",
    "FROM shipping_quotes s\n",
    "JOIN boxes b ON s.box = b.sku_id\n",
    "WHERE orders_id = '''+ str(oid) +'''\n",
    "''', db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "sl.orders_id,\n",
    "CEILING(sl.sl_weight) AS sl_weight,\n",
    "sl.sl_box,\n",
    "b.name,\n",
    "b.length,\n",
    "b.width,\n",
    "b.height,\n",
    "CEILING((ROUND(b.length) * ROUND(b.height) * ROUND(b.width))/139) AS dim_weight\n",
    "FROM ship_log sl\n",
    "JOIN boxes b ON sl.sl_box = b.sku_id\n",
    "WHERE sl.orders_id = '''+ str(oid) +'''\n",
    "''', db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "charge_description,\n",
    "entered_weight,\n",
    "billed_weight\n",
    "FROM ups_billing\n",
    "WHERE orders_id = '''+ str(oid) +'''\n",
    "''', db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get some recent overcharges and see what's up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/Users/jarad/fake_folder/Python Libraries/')\n",
    "\n",
    "from jb_libraries import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = '2018-09-15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ot = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "DATE(o.date_purchased) AS date_purchased, \n",
    "ot.orders_id,\n",
    "ot.value AS shipping_revenue,\n",
    "ups.ups_charge,\n",
    "ot.value - ups.ups_charge AS shipping_profit,\n",
    "#ups.entered_weight,\n",
    "ups.billed_weight AS ups_billed_weight\n",
    "\n",
    "FROM orders o\n",
    "\n",
    "LEFT JOIN orders_total ot ON o.orders_id = ot.orders_id\n",
    "\n",
    "LEFT JOIN\n",
    "(SELECT\n",
    "orders_id,\n",
    "SUM(netAmount) AS ups_charge,\n",
    "SUM(entered_weight) AS entered_weight,\n",
    "SUM(billed_weight) AS billed_weight\n",
    "FROM ups_billing\n",
    "GROUP BY orders_id) ups ON ot.orders_id = ups.orders_id\n",
    "\n",
    "WHERE ot.class = 'ot_shipping'\n",
    "AND ot.value != 0\n",
    "AND DATE(o.date_purchased) >= '''+ str(d) +'''\n",
    "''', db)\n",
    "\n",
    "col_fix(ot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ot['date purchased'] = pd.to_datetime(ot['date purchased'])\n",
    "ot = ot[ot['date purchased'] >= d].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_quotes = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "sq.orders_id,\n",
    "sq.box AS sq_box,\n",
    "CEILING(sq.weight) AS sq_weight,\n",
    "#b.name,\n",
    "#b.length,\n",
    "#b.width,\n",
    "#b.height,\n",
    "CEILING((ROUND(b.length) * ROUND(b.height) * ROUND(b.width))/139) AS sq_dim_weight\n",
    "FROM shipping_quotes sq\n",
    "JOIN boxes b ON sq.box = b.sku_id\n",
    "WHERE sq.orders_id IN '''+ str(tuple(ot['orders id'])) +'''\n",
    "''', db)\n",
    "\n",
    "col_fix(ship_quotes)\n",
    "ship_quotes['sq billed weight'] = ship_quotes[['sq weight','sq dim weight']].max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_log = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "sl.orders_id,\n",
    "sl.sl_box,\n",
    "CEILING(sl.sl_weight) AS sl_weight,\n",
    "#b.name,\n",
    "#b.length,\n",
    "#b.width,\n",
    "#b.height,\n",
    "CEILING((ROUND(b.length) * ROUND(b.height) * ROUND(b.width))/139) AS sl_dim_weight\n",
    "FROM ship_log sl\n",
    "JOIN boxes b ON sl.sl_box = b.sku_id\n",
    "WHERE sl.orders_id IN '''+ str(tuple(ot['orders id'])) +'''\n",
    "''', db)\n",
    "\n",
    "col_fix(ship_log)\n",
    "ship_log['sl billed weight'] = ship_log[['sl weight','sl dim weight']].max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charges = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "orders_id,\n",
    "charge_description\n",
    "FROM ups_billing\n",
    "WHERE orders_id IN '''+ str(tuple(ot['orders id'])) +'''\n",
    "''', db)\n",
    "\n",
    "col_fix(charges)\n",
    "\n",
    "charges2 = charges.groupby('orders id')['charge description'].apply(lambda x: ', '.join(x))\n",
    "charges3 = pd.DataFrame(charges2).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit = pd.merge(ot, ship_quotes, on = 'orders id').merge(ship_log, on = 'orders id')\n",
    "audit['ups charges'] = audit['orders id'].map(dict(zip(charges3['orders id'], charges3['charge description'])))\n",
    "audit.dropna(subset = ['ups charge'], inplace = True) # remove where we do not yet have UPS billing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = audit[(audit['shipping profit'] < 0)].copy()\n",
    "print(len(loss))\n",
    "print(loss['shipping profit'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = loss[loss['sq billed weight'] < loss['ups billed weight']].copy()\n",
    "print(len(a))\n",
    "a['shipping profit'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = loss[loss['sq billed weight'] >= loss['ups billed weight']].copy()\n",
    "print(len(b))\n",
    "b['shipping profit'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = b[b['sl billed weight'] <= b['ups billed weight']].copy()\n",
    "len(c)\n",
    "c['shipping profit'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = c.groupby('ups charges')[['shipping profit']].sum().sort_values('shipping profit').plot(kind = 'barh')\n",
    "ax.legend(loc = 'upper left')\n",
    "ax.grid()\n",
    "ax.set_xticklabels(['${:,.0f}'.format(x) for x in ax.get_xticks()])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.sort_values('shipping profit').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To excel, per Daigo request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl_main = audit[audit['sq billed weight'] < audit['ups billed weight']]\n",
    "xl_gain = xl_main[xl_main['shipping profit'] >= 0].copy()\n",
    "xl_loss = xl_main[xl_main['shipping profit'] < 0].copy()\n",
    "\n",
    "print(len(xl_main) == len(xl_gain) + len(xl_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(xl_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(xl_gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(xl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write = 'no'\n",
    "\n",
    "if write == 'yes':\n",
    "    writer = pd.ExcelWriter('2018-09-15 to 2018-10-03 - shipping_quotes.billed_weight and ups_billing.billed_weight.xlsx', engine = 'xlsxwriter')\n",
    "\n",
    "    xl_main.to_excel(writer, 'all data', index = False)\n",
    "    xl_gain.to_excel(writer, 'zero profit or gain', index = False)\n",
    "    xl_loss.to_excel(writer, 'profit loss', index = False)\n",
    "    \n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Under Prediction\" comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = len(audit)\n",
    "b = len(audit[audit['sq billed weight'] < audit['ups billed weight']])\n",
    "b/a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2018-10-04 follow-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl_main[xl_main['orders id'] == 1853173]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "sq.orders_id,\n",
    "sq.box AS sq_box,\n",
    "sq.weight,\n",
    "b.name,\n",
    "b.length,\n",
    "b.width,\n",
    "b.height,\n",
    "CEILING((ROUND(b.length) * ROUND(b.height) * ROUND(b.width))/139) AS sq_dim_weight\n",
    "FROM shipping_quotes sq\n",
    "JOIN boxes b ON sq.box = b.sku_id\n",
    "WHERE sq.orders_id = 1853173\n",
    "''', db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "sl.orders_id,\n",
    "sl.sl_box,\n",
    "sl.sl_weight,\n",
    "#b.name,\n",
    "b.length,\n",
    "b.width,\n",
    "b.height,\n",
    "CEILING((ROUND(b.length) * ROUND(b.height) * ROUND(b.width))/139) AS sl_dim_weight\n",
    "FROM ship_log sl\n",
    "JOIN boxes b ON sl.sl_box = b.sku_id\n",
    "WHERE sl.orders_id = 1853173\n",
    "''', db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2018-10-09: Create interval for additional non-box packaging weight, like bubble wrap, etc.\n",
    "* This is the difference in dim weight between shipping_quotes and ship_log \n",
    "* [Confidence interval for a proportion](https://onlinecourses.science.psu.edu/stat100/node/56/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/Users/jarad/fake_folder/Python Libraries/')\n",
    "\n",
    "from jb_libraries import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_start = '2018-09-08'\n",
    "date_end = '2018-10-08'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "sku_id,\n",
    "name,\n",
    "CEILING((ROUND(length) * ROUND(width) * ROUND(height))/139) AS box_dim_weight\n",
    "FROM boxes\n",
    "''', db)\n",
    "\n",
    "col_fix(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "*\n",
    "FROM orders_status\n",
    "ORDER BY orders_status_id\n",
    "''', db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "DATE(o.date_purchased) AS date_purchased,\n",
    "sq.orders_id,\n",
    "sq.box AS sq_box,\n",
    "sq.weight AS sq_weight,\n",
    "CEILING(sq.weight) AS sq_weight_rounded,\n",
    "b.name,\n",
    "b.length,\n",
    "b.width,\n",
    "b.height,\n",
    "CEILING((ROUND(b.length) * ROUND(b.height) * ROUND(b.width))/139) AS sq_dim_weight\n",
    "FROM shipping_quotes sq\n",
    "JOIN boxes b ON sq.box = b.sku_id\n",
    "JOIN orders o ON sq.orders_id = o.orders_id\n",
    "WHERE DATE(o.date_purchased) BETWEEN ' '''+ date_start +''' ' AND ' '''+ date_end +''' '\n",
    "AND o.orders_status NOT IN (8,9,10,11,12,13,14,15)\n",
    "''', db)\n",
    "\n",
    "col_fix(sq)\n",
    "sq['sq billed weight'] = sq[['sq weight rounded','sq dim weight']].max(1)\n",
    "\n",
    "dupes1 = sq[sq['orders id'].duplicated()]['orders id'].tolist()\n",
    "sq = sq[~sq['orders id'].isin(dupes1)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "DATE(o.date_purchased) AS date_purchased,\n",
    "sl.orders_id,\n",
    "sl.sl_box,\n",
    "sl.sl_weight AS sl_weight,\n",
    "CEILING(sl.sl_weight) AS sl_weight_rounded,\n",
    "b.name,\n",
    "b.length,\n",
    "b.width,\n",
    "b.height,\n",
    "CEILING((ROUND(b.length) * ROUND(b.height) * ROUND(b.width))/139) AS sl_dim_weight\n",
    "FROM ship_log sl\n",
    "JOIN boxes b ON sl.sl_box = b.sku_id\n",
    "JOIN orders o ON sl.orders_id = o.orders_id\n",
    "WHERE DATE(o.date_purchased) BETWEEN ' '''+ date_start +''' ' AND ' '''+ date_end +''' '\n",
    "AND o.orders_status NOT IN (8,9,10,11,12,13,14,15)\n",
    "''', db)\n",
    "\n",
    "col_fix(sl)\n",
    "sl['sl billed weight'] = sl[['sl weight rounded','sl dim weight']].max(1)\n",
    "\n",
    "dupes2 = sl[sl['orders id'].duplicated()]['orders id'].tolist()\n",
    "sl = sl[~sl['orders id'].isin(dupes2)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('data is between %s and %s' % (date_start, date_end))\n",
    "print('{:,.0f} OIDs were shipped in multiple boxes, and these have been excluded here\\n'.format(len(dupes2)))\n",
    "\n",
    "a = len(sq)\n",
    "b = len(sq[sq['orders id'].isin(sl['orders id'].tolist())])\n",
    "c = a-b\n",
    "\n",
    "print('{:,.0f} OIDs in shipping_quotes\\n{:,.0f} of these OIDs are in ship_log'.format(a,b))\n",
    "print('which leaves {:,.0f} boxes ({:,.2f}% of shipping_quotes total) that were not scanned by shippers'.format(c, c/a*100))\n",
    "\n",
    "ls1 = ['date purchased','orders id','sl box','sl weight','sl weight rounded','sl billed weight']\n",
    "ls2 = ['orders id','sq box','sq weight','sq weight rounded','sq billed weight']\n",
    "main = pd.merge(sl[ls1], sq[ls2], how = 'inner', on = 'orders id')\n",
    "\n",
    "d = len(main[main['sq box'] == main['sl box']])\n",
    "print('\\n{:,.0f} OIDs were shipped in the same box as quoted'.format(d))\n",
    "print('this is {:,.2f}% of ship_log total'.format(d/b*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = main.columns.tolist()\n",
    "ls = ['sl box','sl weight','sl weight rounded','sl billed weight']\n",
    "for w in ls:\n",
    "    cols.remove(w)\n",
    "    cols.append(w)\n",
    "main = main[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same box quoted and shipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = main[main['sl box'] == main['sq box']].copy()\n",
    "print('{:,.0f} OIDs were shipped in the same box as quoted'.format(len(w1)))\n",
    "print('or {:,.2f}% of total'.format(len(w1)/len(main) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(w1)\n",
    "s1 = len(w1[w1['sq billed weight'] >= w1['sl billed weight']])/n\n",
    "\n",
    "st_error = np.sqrt((s1 * (1-s1))/n)\n",
    "z = 1.96\n",
    "\n",
    "lower = s1 - z * st_error\n",
    "upper = s1 + z * st_error\n",
    "\n",
    "print('out of all OIDs where the same box was quoted and shipped')\n",
    "print('confidence interval for proportion of orders where shipping_quotes billed weight >= ship_log billed weight')\n",
    "print('\\nlower {:,.2f}%\\nactual: {:,.2f}%\\nupper: {:,.2f}%'.format(lower * 100, s1 * 100, upper * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different box quoted and shipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = main[main['sl box'] != main['sq box']].copy()\n",
    "print('{:,.0f} OIDs were NOT shipped in the same box as quoted'.format(len(w2)))\n",
    "print('this is {:,.2f}% of ship_log total'.format(len(w2)/len(main) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2['sq box dim weight'] = w2['sq box'].map(dict(zip(boxes['sku id'], boxes['box dim weight'])))\n",
    "w2['sl box dim weight'] = w2['sl box'].map(dict(zip(boxes['sku id'], boxes['box dim weight'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(w2)\n",
    "s1 = len(w2[w2['sq billed weight'] < w2['sl billed weight']])/n\n",
    "\n",
    "st_error = np.sqrt((s1 * (1-s1))/n)\n",
    "z = 1.96\n",
    "\n",
    "lower = s1 - z * st_error\n",
    "upper = s1 + z * st_error\n",
    "\n",
    "print('out of all OIDs where the same box was NOT quoted and shipped')\n",
    "print('confidence interval for proportion of orders where quoted billed weight < shipped billed weight')\n",
    "print('\\nlower {:,.2f}%\\nactual: {:,.2f}%\\nupper: {:,.2f}%'.format(lower * 100, s1 * 100, upper * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(w2[w2['sq billed weight'] < w2['sl billed weight']])/len(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = len(w2[(w2['sq billed weight'] < w2['sl billed weight'])])\n",
    "\n",
    "b = len(w2[(w2['sq billed weight'] < w2['sl billed weight'])\n",
    "  & (w2['sq weight rounded'] < w2['sl weight rounded'])])\n",
    "\n",
    "c = len(w2[(w2['sq billed weight'] < w2['sl billed weight'])\n",
    "  & (w2['sq box dim weight'] < w2['sl box dim weight'])])\n",
    "\n",
    "print('total OID count of the orders where a different box was quoted and shipped: {:,.0f}'.format(len(w2)))\n",
    "print('of this count, {:,.0f} or {:,.2f}% of OIDs had shipping_quote billed weight < ship_log billed weight'.format(a,a/len(w2) * 100))\n",
    "print('\\n{:,.2f}% of this count had an under-quoted rounded actual weight'.format(b/a*100))\n",
    "print('{:,.2f}% of this count contained had an under-quoted box dim weight'.format(c/a * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Follow-up on numerical truncation issue\n",
    "* Fix was pushed 2018-10-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/Users/jarad/fake_folder/Python Libraries/')\n",
    "\n",
    "from jb_libraries import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trunc = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "ups.orders_id,\n",
    "entered_weight,\n",
    "billed_weight\n",
    "FROM ups_billing ups\n",
    "JOIN orders o ON ups.orders_id = o.orders_id\n",
    "AND DATE(date_purchased) >= '2018-10-01'\n",
    "''', db)\n",
    "\n",
    "col_fix(trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trunc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
