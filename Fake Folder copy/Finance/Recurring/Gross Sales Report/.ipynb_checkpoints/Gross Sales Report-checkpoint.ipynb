{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/Users/jarad/fake_folder/Python Libraries')\n",
    "from jb_libraries import *\n",
    "%matplotlib inline\n",
    "\n",
    "close_workbook = 'yes'\n",
    "\n",
    "#report_type = 'other'\n",
    "report_type = 'year and month'\n",
    "#report_type = 'year and quarter'\n",
    "\n",
    "title = '2018 - 10 - Oct - Gross Sales Report.xlsx'\n",
    "#title = '2018-06-01 to 2018-08-31 - Gross Sales Report.xlsx'\n",
    "#title = '2018 - Q3 - Gross Sales Report.xlsx'\n",
    "\n",
    "date_start = '2018-10-01'\n",
    "date_end = '2018-10-31'\n",
    "\n",
    "if report_type == 'year and month':\n",
    "    pretty_date = []\n",
    "    dt = calendar.month_abbr[int(date_start[5:7])] + ' ' + date_start[:4]\n",
    "    pretty_date.append(dt)     \n",
    "else:\n",
    "    ls = pd.date_range(date_start, date_end, freq = 'MS').tolist()\n",
    "    pretty_date = [calendar.month_abbr[int(str(x)[5:7])] + ' ' + str(x)[:4] for x in ls]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REMINDER\n",
    "check to make sure that in orders_total that ot_total is the actual total of the OID\n",
    "\n",
    "an ot_coupon value is positive but the ot_total should treat it like it's negative\n",
    "\n",
    "check this because you turn some classes negative and you make your own total column\n",
    "\n",
    "consider NOT doing this and taking the total to be ot_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check our order statuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orders status id</th>\n",
       "      <th>orders status name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Pending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Shipped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Printed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Billed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Payment Received</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Fraud - Pending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Fraud - Confirmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Replaced Defective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Refunded Defective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>No Shipment Necessary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Voided</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Fraud - Void</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    orders status id     orders status name\n",
       "0                  1                Pending\n",
       "1                  2             Processing\n",
       "2                  3                Shipped\n",
       "3                  4                 Update\n",
       "4                  5                Printed\n",
       "5                  6                 Billed\n",
       "6                  7       Payment Received\n",
       "7                  8        Fraud - Pending\n",
       "8                  9      Fraud - Confirmed\n",
       "9                 10                 Return\n",
       "10                11     Replaced Defective\n",
       "11                12     Refunded Defective\n",
       "12                13  No Shipment Necessary\n",
       "13                14                 Voided\n",
       "14                15           Fraud - Void"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "orders_status_id,\n",
    "orders_status_name\n",
    "FROM orders_status\n",
    "ORDER BY orders_status_id\n",
    "''', db)\n",
    "\n",
    "col_fix(os)\n",
    "\n",
    "os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out billing statutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "bs_status_id,\n",
    "bs_status_name\n",
    "FROM billing_status\n",
    "ORDER BY bs_status_id\n",
    "''', db)\n",
    "\n",
    "col_fix(bs)\n",
    "\n",
    "#bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_super_main = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "DATE(o.date_purchased) AS date_purchased,\n",
    "DATE_FORMAT(o.date_purchased, '%Y-%m') AS year_and_month,\n",
    "ot.*,\n",
    "bs.bs_status_name\n",
    "FROM orders_total ot\n",
    "JOIN orders o ON ot.orders_id = o.orders_id\n",
    "AND orders_status NOT IN (8,9,10,11,12,14,15)\n",
    "AND payment_method != 'Replacement Order'\n",
    "AND DATE(o.date_purchased) BETWEEN ' '''+ date_start +''' ' AND ' '''+ date_end +''' '\n",
    "JOIN billing_status bs ON o.orders_billing_status = bs.bs_status_id\n",
    "''', db)\n",
    "\n",
    "col_fix(sales_super_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check out the classes\n",
      "\n",
      "ot_subtotal            22704\n",
      "ot_total               22704\n",
      "ot_shipping            22704\n",
      "ot_tax                 15565\n",
      "ot_ddp                  1200\n",
      "ot_coupon                892\n",
      "                         594\n",
      "ot_gv                     40\n",
      "ot_check_fee              23\n",
      "ot_wiretransfer_fee       16\n",
      "ot_deduction               1\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('check out the classes\\n')\n",
    "print(sales_super_main['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_super_main[sales_super_main['class'] == '']['value'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check, if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_year_ago = str((pd.to_datetime(date_end) - pd.DateOffset(months = 12)).date())[:7] + '-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year And Month     Ot Rev     Ds Rev     Op Rev\n",
      "0         2017-10  3,698,425  3,698,425  3,698,057\n",
      "1         2017-11  4,346,924  4,346,924  4,344,983\n",
      "2         2017-12  3,929,416  3,929,415  3,926,969\n",
      "3         2018-01  3,539,520  3,539,520  3,538,819\n",
      "4         2018-02  3,312,539  3,312,539  3,309,758\n",
      "5         2018-03  4,370,265  4,370,265  4,366,918\n",
      "6         2018-04  3,705,791  3,705,969  3,703,936\n",
      "7         2018-05  3,934,945  3,934,945  3,934,183\n",
      "8         2018-06  3,272,854  3,272,854  3,272,137\n",
      "9         2018-07  3,449,179  3,449,220  3,448,533\n",
      "10        2018-08  3,142,594  3,142,594  3,142,176\n",
      "11        2018-09  3,083,782  3,083,782  3,081,714\n",
      "12        2018-10  4,204,413  4,205,927  4,204,045\n"
     ]
    }
   ],
   "source": [
    "run_this = 'yes'\n",
    "\n",
    "if run_this == 'yes':\n",
    "    ds = pd.read_sql(\n",
    "    '''\n",
    "    SELECT\n",
    "    DATE_FORMAT(timestamp, '%Y-%m') AS year_and_month,\n",
    "    SUM(d_value) AS ds_rev\n",
    "    FROM daily_stats\n",
    "    WHERE DATE(timestamp) BETWEEN ' '''+ one_year_ago +''' ' AND ' '''+ date_end +''' '\n",
    "    AND d_class = 'd_all'\n",
    "    GROUP BY DATE_FORMAT(timestamp, '%Y-%m') \n",
    "    ''', db)\n",
    "\n",
    "    ot = pd.read_sql(\n",
    "    '''\n",
    "    SELECT\n",
    "    DATE_FORMAT(date_purchased, '%Y-%m') AS year_and_month,\n",
    "    SUM(value) AS ot_rev\n",
    "    FROM orders_total ot\n",
    "    JOIN orders o ON ot.orders_id = o.orders_id\n",
    "    AND DATE(date_purchased) BETWEEN ' '''+ one_year_ago +''' ' AND ' '''+ date_end +''' '\n",
    "    AND orders_status NOT IN (8,9,10,11,12,14,15)\n",
    "    AND payment_method != 'Replacement Order'\n",
    "    WHERE class = 'ot_subtotal'\n",
    "    GROUP BY DATE_FORMAT(date_purchased, '%Y-%m')\n",
    "    ''', db)\n",
    "\n",
    "    op = pd.read_sql(\n",
    "    '''\n",
    "    SELECT\n",
    "    DATE_FORMAT(date_purchased, '%Y-%m') AS year_and_month,\n",
    "    SUM((products_quantity - products_quantity_free) * products_price) AS op_rev\n",
    "    FROM orders_products op\n",
    "    JOIN orders o ON op.orders_id = o.orders_id\n",
    "    AND DATE(date_purchased) BETWEEN ' '''+ one_year_ago +''' ' AND ' '''+ date_end +''' '\n",
    "    AND orders_status NOT IN (8,9,10,11,12,14,15)\n",
    "    AND payment_method != 'Replacement Order'\n",
    "    GROUP BY DATE_FORMAT(date_purchased, '%Y-%m')\n",
    "    ''', db)\n",
    "\n",
    "    col_fix(ds)\n",
    "    col_fix(ot)\n",
    "    col_fix(op)\n",
    "\n",
    "    df = pd.merge(ot,ds,on = 'year and month').merge(op,on = 'year and month')\n",
    "    print(df.format_([0,'n0','n0','n0']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up sales data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy to keep the original, for reference if needed\n",
    "sales_main = sales_super_main.copy()\n",
    "\n",
    "# create date columns\n",
    "sales_main['date purchased'] = pd.to_datetime(sales_main['date purchased'])\n",
    "sales_main['year and month'] = [str(x)[:7] for x in sales_main['date purchased']]\n",
    "sales_main['year and quarter'] = sales_main['date purchased'].dt.year.map(str) + '-0' + sales_main['date purchased'].dt.quarter.map(str)\n",
    "\n",
    "# clean orders_totals \"class\"\n",
    "sales_main['class'] = sales_main['class'].str.replace('ot_','').str.replace('_',' ')\n",
    "\n",
    "# if the text begins with a minus sign, then the value is negative\n",
    "# if the class is \"refund\" or \"coupon\" or \"deduction\", then the value should be negative\n",
    "# if title = 'store credit', then the value should be negative\n",
    "ls = ['refund','coupon','deduction']\n",
    "sales_main['value'] = np.where((sales_main['text'].str.contains('^-')) | (sales_main['class'].isin(ls) | (sales_main['title'].str.contains('store credit', case = False))),\n",
    "                               sales_main['value'] * -1,\n",
    "                               sales_main['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales by OID; get mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 mismatche(s)\n",
      "22,704 total OIDs\n",
      "that's 0.00% of the total count\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# group by OID and class\n",
    "by_oid = sales_main.groupby(['orders id','class'])[['value']].sum().unstack(1).fillna(0)\n",
    "by_oid.columns = by_oid.columns.droplevel(0)\n",
    "\n",
    "# if it's an adabox subscription charge, the total does not equal the sum\n",
    "# so make the total = SUM(parts)\n",
    "by_oid['total'] = by_oid.sum(1) - by_oid['total']\n",
    "\n",
    "# drop all zeros\n",
    "drop_ls = by_oid.loc[:,(by_oid == 0).all()].columns.tolist()\n",
    "by_oid.drop(drop_ls,1,inplace = True)\n",
    "\n",
    "by_oid['date purchased'] = by_oid.index.to_series().map(dict(zip(sales_super_main['orders id'], sales_super_main['date purchased'])))\n",
    "\n",
    "# move some columns\n",
    "cols = by_oid.columns.tolist()\n",
    "for x in ['date purchased','subtotal','shipping','total']:\n",
    "    cols.remove(x)\n",
    "cols = ['date purchased','subtotal'] + cols + ['shipping','total']\n",
    "\n",
    "by_oid = by_oid[cols]\n",
    "by_oid['bs status name'] = by_oid.index.to_series().map(dict(zip(sales_main['orders id'], sales_main['bs status name'])))\n",
    "\n",
    "# get where the sum of lines != the total listed in orders_total\n",
    "mismatch = by_oid[np.abs((by_oid.sum(1) - by_oid['total']) - by_oid['total']) > 1].copy()\n",
    "\n",
    "tot_mis = len(set(mismatch.index))\n",
    "tot_count = len(set(sales_super_main['orders id']))\n",
    "\n",
    "print('{:,.0f} mismatche(s)\\n{:,.0f} total OIDs\\nthat\\'s {:,.2f}% of the total count\\n'.format(tot_mis, tot_count, tot_mis/tot_count * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall that your sales_main df is now clean, as in there are no mismatches on the OID level\n",
    "by_class = sales_main.groupby(['year and month','class'])[['value']].sum().unstack(1).fillna(0)\n",
    "by_class.columns = by_class.columns.droplevel(0)\n",
    "\n",
    "# if the OID is an adabox shipment, the orders_total.total != SUM(orders_total)\n",
    "by_class['total'] = by_class.sum(1) - by_class['total']\n",
    "\n",
    "# some columns have all zeros; drop them\n",
    "zero_cols = by_class.loc[:, (by_class == 0).all()].columns[0]\n",
    "by_class.drop(zero_cols, 1, inplace = True)\n",
    "\n",
    "# move some columns\n",
    "cols = by_class.columns.tolist()\n",
    "for x in ['subtotal','shipping','total']:\n",
    "    cols.remove(x)\n",
    "cols = ['subtotal'] + cols + ['shipping','total']\n",
    "   \n",
    "by_class = by_class[cols]\n",
    "by_class.index = pretty_date\n",
    "\n",
    "if report_type == 'year and quarter':\n",
    "    by_class.loc['total'] = by_class.sum()\n",
    "    \n",
    "by_class = by_class.reset_index().rename(columns = {'index':'date'})        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Subtotal</th>\n",
       "      <th>Check Fee</th>\n",
       "      <th>Coupon</th>\n",
       "      <th>Ddp</th>\n",
       "      <th>Deduction</th>\n",
       "      <th>Gv</th>\n",
       "      <th>Tax</th>\n",
       "      <th>Wiretransfer Fee</th>\n",
       "      <th>Shipping</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Oct 2018</td>\n",
       "      <td>$4,204,413</td>\n",
       "      <td>$460</td>\n",
       "      <td>$-14,819</td>\n",
       "      <td>$20,549</td>\n",
       "      <td>$-16</td>\n",
       "      <td>$-2,431</td>\n",
       "      <td>$57,520</td>\n",
       "      <td>$400</td>\n",
       "      <td>$254,698</td>\n",
       "      <td>$4,520,774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date    Subtotal Check Fee    Coupon      Ddp Deduction       Gv  \\\n",
       "0  Oct 2018  $4,204,413      $460  $-14,819  $20,549      $-16  $-2,431   \n",
       "\n",
       "       Tax Wiretransfer Fee  Shipping       Total  \n",
       "0  $57,520             $400  $254,698  $4,520,774  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_class.format_([0] + ['m0'] * (len(by_class.columns) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match\n",
      "match\n"
     ]
    }
   ],
   "source": [
    "if report_type == 'year and month':\n",
    "    if np.abs(by_oid['total'].sum() - by_class['total'].values[0]) < 1:\n",
    "        print('match')\n",
    "    else:\n",
    "        print('mismatch')\n",
    "        \n",
    "    a = sales_main[sales_main['class'] != 'total']['value'].sum()\n",
    "    b = by_oid['total'].sum()\n",
    "    c = by_class['total'].values[0]\n",
    "\n",
    "    if (np.round(a) + np.round(b) + np.round(c))/np.round(a) == 3:\n",
    "        print('match')\n",
    "    else:\n",
    "        print('mismatch')        \n",
    "        \n",
    "elif report_type == 'year and quarter':\n",
    "    if np.abs(by_oid['total'].sum() - by_class[by_class['date'] == 'total']['total'].values[0]) < 1:\n",
    "        print('match')\n",
    "    else:\n",
    "        print('mismatch')    \n",
    "        \n",
    "    a = sales_main[sales_main['class'] != 'total']['value'].sum()\n",
    "    b = by_oid['total'].sum()\n",
    "    c = by_class[by_class['date'] == 'total']['total'].values[0]\n",
    "\n",
    "    if (np.round(a) + np.round(b) + np.round(c))/np.round(a) == 3:\n",
    "        print('match')\n",
    "    else:\n",
    "        print('mismatch')        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if close_workbook == 'yes':\n",
    "    writer = pd.ExcelWriter(title, engine = 'xlsxwriter')\n",
    "    by_oid.to_excel(writer, 'by OID', index = False)\n",
    "    by_class.to_excel(writer, 'by ' + report_type, index = False)\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State-by-State Sales Numbers - Sales Tax\n",
    "* Started July 6,2018\n",
    "* Continued July 18, 2018\n",
    "*****\n",
    "### From Stella:\n",
    "* From email with subject line \"state-by-state sales numbers - sales tax\"\n",
    "* Please run state-by-state gross sales and number of sales transactions for the whole of 2017. Break up by month and then have a grand total (sum of all months) for the annual. You can create one workbook with one tab per state. If you'd prefer to configure the workbook in a different way, please feel free.\n",
    "* We can pull 2018 Q1 and Q2 numbers after the completion of this month (June). It would have the same format - broken down by month and then total sum of all months."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State and abbrev dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_state_abbrev = {\n",
    "    'Alabama': 'AL',\n",
    "    'Alaska': 'AK',\n",
    "    'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'California': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'Delaware': 'DE',\n",
    "    'Florida': 'FL',\n",
    "    'Georgia': 'GA',\n",
    "    'Hawaii': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI',\n",
    "    'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY',\n",
    "    'District Of Columbia':'DC',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get state data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_main = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "orders_id,\n",
    "customers_state,\n",
    "customers_postcode,\n",
    "customers_country\n",
    "FROM orders\n",
    "WHERE DATE(date_purchased) >= '2017-01-01'\n",
    "''', db)\n",
    "\n",
    "col_fix(states_main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean it up and map it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states before extracting just \"united states\"\n",
      "\n",
      "{'united kingdom', 'united states', 'united states minor outlying islands', 'united arab emirates'}\n",
      "\n",
      "excluded \"states\"\n",
      "['AE', 'American Samoa', 'GU', 'Virginiaflorida', 'Puerto Rico', 'Armed Forces Europe', 'Armed Forces Americas', 'Northern Mariana Islands', 'MP', 'Armed Forces Pacific', 'Federated States Of Micronesia', 'AA', 'Boaz', 'Guam', 'Alberta', 'Virgin Islands', 'South Beach', 'VI', 'PR', 'Exeter', 'AP']\n"
     ]
    }
   ],
   "source": [
    "# cast to lowercase\n",
    "states_main['customers country'] = [x.lower() for x in states_main['customers country']]\n",
    "\n",
    "# strip whitespace\n",
    "for col in ['state','country']:\n",
    "    states_main['customers ' + col] = [x.strip() for x in states_main['customers ' + col]]\n",
    "\n",
    "# print these, just to see\n",
    "print('states before extracting just \"united states\"\\n')\n",
    "print(set(states_main['customers country'][states_main['customers country'].str.contains('united')]))\n",
    "\n",
    "# consider only this \n",
    "states_main = states_main[states_main['customers country'] == 'united states']\n",
    "\n",
    "# clean state abbrevs\n",
    "def state_clean(x):\n",
    "    if len(x['customers state']) == 2:\n",
    "        state = x['customers state'].upper()\n",
    "    else:\n",
    "        state = x['customers state'].title()\n",
    "    return state\n",
    "states_main['customers state'] = states_main.apply(state_clean, axis = 1)\n",
    "\n",
    "# map\n",
    "states_main['state name'] = states_main['customers state'].replace(us_state_abbrev.values(), us_state_abbrev.keys())\n",
    "\n",
    "# find true states \n",
    "states_main['is state'] = np.where(states_main['state name'].isin(us_state_abbrev.keys()), 'yes','no')\n",
    "\n",
    "# save for later viewing, if needed\n",
    "exclude = list(set(states_main[states_main['is state'] == 'no']['customers state']))\n",
    "print('\\nexcluded \"states\"')\n",
    "print(exclude)\n",
    "\n",
    "# map state date to main data\n",
    "# recall that your sales_main df does not have any mismatches on the OID level\n",
    "for x in ['state name','is state']:\n",
    "    sales_main[x] = sales_main['orders id'].map(dict(zip(states_main['orders id'], states_main[x])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excluded \"states\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orders id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Puerto Rico</th>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Armed Forces Europe</th>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Armed Forces Pacific</th>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PR</th>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AE</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Armed Forces Americas</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virgin Islands</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AA</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VI</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GU</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guam</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American Samoa</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Beach</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Federated States Of Micronesia</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Northern Mariana Islands</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MP</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exeter</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boaz</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alberta</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virginiaflorida</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                orders id\n",
       "state name                               \n",
       "Puerto Rico                           338\n",
       "Armed Forces Europe                   201\n",
       "Armed Forces Pacific                  185\n",
       "PR                                    113\n",
       "AE                                    100\n",
       "AP                                     71\n",
       "Armed Forces Americas                  25\n",
       "Virgin Islands                         13\n",
       "AA                                      9\n",
       "VI                                      6\n",
       "GU                                      6\n",
       "Guam                                    3\n",
       "American Samoa                          2\n",
       "South Beach                             1\n",
       "Federated States Of Micronesia          1\n",
       "Northern Mariana Islands                1\n",
       "MP                                      1\n",
       "Exeter                                  1\n",
       "Boaz                                    1\n",
       "Alberta                                 1\n",
       "Virginiaflorida                         1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_main[states_main['is state'] == 'no'].groupby('state name')[['orders id']].count().sort_values('orders id', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate what is and is not \"gross\", as per Stella"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gross = ['check fee',\n",
    "        'ddp',\n",
    "        'production fee',\n",
    "        'refund reversal',\n",
    "        'shipping',\n",
    "        'subtotal',\n",
    "        'tax',\n",
    "        'wiretransfer fee']\n",
    "\n",
    "not_gross = list(set(sales_main['class']) - set(gross))\n",
    "\n",
    "for x in ['','total']:\n",
    "    not_gross.remove(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # make nice columns\n",
    "    cols = list(set(sales_main['class']))\n",
    "    for x in ['subtotal','shipping','tax','total','']:\n",
    "        cols.remove(x)\n",
    "    cols = ['subtotal'] + cols + ['shipping','tax','total']\n",
    "\n",
    "    # start to write\n",
    "    title = 'State-by-State Sales Numbers - Sales Tax - v1'\n",
    "    workbook = xlsxwriter.Workbook(title + '.xlsx')\n",
    "\n",
    "    # set formats\n",
    "    set_col = 18\n",
    "    money = workbook.add_format({'num_format': '$#,##0'})\n",
    "    number = workbook.add_format({'num_format': '#,##0'})\n",
    "    header = workbook.add_format({'bold': True, 'valign': 'center', 'align':'center'})\n",
    "    merge = workbook.add_format({'bold': True, 'valign': 'center', 'align':'center', 'bg_color':'#e0ffff','font_size':14,'border':1})\n",
    "\n",
    "    conf_dict = {}\n",
    "\n",
    "    # create summary sheet\n",
    "    worksheet = workbook.add_worksheet('Summary')\n",
    "\n",
    "    # create confidence intervals for each state\n",
    "    df1 = sales_main[(sales_main['is state'] == 'yes')\n",
    "                  & (sales_main['class'].isin(gross))].copy()\n",
    "\n",
    "    df2 = df1.groupby(['year and month','state name'])[['value']].sum().unstack(1).fillna(0)\n",
    "    df2.columns = df2.columns.droplevel(0)\n",
    "\n",
    "    d = {}\n",
    "    for col in df2.columns:\n",
    "        x_bar = df2[col].mean()\n",
    "        s = df2[col].std()\n",
    "        n = len(df2[col])\n",
    "\n",
    "        deg_freed = n - 1\n",
    "        phi = stats.t.ppf(0.95, deg_freed)\n",
    "\n",
    "        lower = x_bar - phi * (s/np.sqrt(n))\n",
    "        upper = x_bar + phi * (s/np.sqrt(n))\n",
    "\n",
    "        d[col] = [lower,x_bar,upper]\n",
    "\n",
    "    df3 = pd.DataFrame(d).T\n",
    "    df3.reset_index(inplace = True)\n",
    "    df3.columns = ['state','lower 95%','avg','upper 95%']\n",
    "\n",
    "    start_row = 0\n",
    "    start_col = 0\n",
    "\n",
    "    # write it\n",
    "    worksheet.merge_range(start_row, start_col, start_row, start_col + len(df3.columns) - 1, '95% confidence intervals for avg gross charge per month', merge)        \n",
    "    for i in range(len(df3.columns)):\n",
    "        worksheet.write(start_row + 1, start_col + i, df3.columns[i], header)\n",
    "        for j in range(len(df3)):\n",
    "            worksheet.write(start_row + 2 + j, start_col + i, df3.iloc[j,i], money)\n",
    "\n",
    "    worksheet.set_column(0,100,15)\n",
    "\n",
    "    # create \"by year\" summary for gross charges\n",
    "    df4 = sales_main[(sales_main['is state'] == 'yes')\n",
    "                  & (sales_main['class'].isin(gross))].copy()\n",
    "\n",
    "    df4['year'] = [x[:4] for x in df4['year and month']]\n",
    "    df5 = df4.groupby(['year','state name'])[['value']].sum().unstack(1).fillna(0)\n",
    "    df5.columns = df5.columns.droplevel(0)\n",
    "    df5 = df5.T\n",
    "    df5.reset_index(inplace = True)\n",
    "    df5['total'] = df5.sum(1)\n",
    "\n",
    "    start_row = 0\n",
    "    start_col = len(df3.columns) + 1\n",
    "\n",
    "    worksheet.merge_range(start_row, start_col, start_row, start_col + len(df5.columns) - 1, 'gross charges by year', merge)        \n",
    "    for i in range(len(df5.columns)):\n",
    "        worksheet.write(start_row + 1, start_col + i, df5.columns[i], header)\n",
    "        for j in range(len(df5)):\n",
    "            worksheet.write(start_row + 2 + j, start_col + i, df5.iloc[j,i], money)\n",
    "\n",
    "    # create \"by year\" summary for order count\n",
    "    df6 = sales_main[(sales_main['is state'] == 'yes')\n",
    "                  & (sales_main['class'].isin(gross))].copy()\n",
    "\n",
    "    df6['year'] = [x[:4] for x in df6['year and month']]\n",
    "    df7 = df6.groupby(['year','state name'])[['orders id']].nunique().unstack(1).fillna(0)\n",
    "    df7.columns = df7.columns.droplevel(0)\n",
    "    df7 = df7.T\n",
    "    df7.reset_index(inplace = True)\n",
    "    df7['total'] = df7.sum(1)\n",
    "\n",
    "    start_row = 0\n",
    "    start_col = len(df3.columns) + len(df5.columns) + 2\n",
    "\n",
    "    worksheet.merge_range(start_row, start_col, start_row, start_col + len(df7.columns) - 1, 'order counts by year', merge)        \n",
    "    for i in range(len(df7.columns)):\n",
    "        worksheet.write(start_row + 1, start_col + i, df7.columns[i], header)\n",
    "        for j in range(len(df7)):\n",
    "            worksheet.write(start_row + 2 + j, start_col + i, df7.iloc[j,i], number)\n",
    "\n",
    "    # write some notes about gross charges    \n",
    "    start_row = 0\n",
    "    start_col = len(df3.columns) + len(df5.columns)+ len(df7.columns) + 3\n",
    "\n",
    "    worksheet.merge_range(start_row, start_col, start_row, start_col + 2, 'notes on gross charges', merge)    \n",
    "    worksheet.write(start_row + 1, start_col, 'gross charges include:')\n",
    "    for i in range(len(gross)):\n",
    "        worksheet.write(start_row + 2 + i, start_col, gross[i])\n",
    "\n",
    "    start_row = start_row + len(gross) + 3\n",
    "    worksheet.write(start_row, start_col, 'gross charges do not include:')\n",
    "    for i in range(len(not_gross)):\n",
    "        worksheet.write(start_row + 1 + i, start_col, not_gross[i])\n",
    "\n",
    "    # loop through each state for subsequent tabs\n",
    "    ls = sorted(list(set(sales_main['state name'][sales_main['is state'] == 'yes'])))\n",
    "    for state in ls:\n",
    "\n",
    "        # create worksheet\n",
    "        worksheet = workbook.add_worksheet(state)\n",
    "\n",
    "        # structure data\n",
    "        main_df = sales_main[sales_main['state name'] == state]    \n",
    "\n",
    "        # get $$\n",
    "        df1 = main_df.groupby(['year and month','class'])[['value']].sum().unstack(1).fillna(0)\n",
    "        df1.columns = df1.columns.droplevel(0)\n",
    "\n",
    "        # make uniform cols, whether or not there are values\n",
    "        for col in cols:\n",
    "            if col not in list(df1.columns):\n",
    "                df1[col] = 0\n",
    "\n",
    "        df1 = df1[cols]\n",
    "        # exclude \"not gross\"\n",
    "        df1.drop(not_gross, 1, inplace = True)\n",
    "\n",
    "        # drop old total and make new one with just \"gross\" columns\n",
    "        df1.drop('total', 1, inplace = True)\n",
    "        df1['total'] = df1[gross].sum(1)\n",
    "\n",
    "        # get OID count\n",
    "        df2 = main_df.groupby('year and month')[['orders id']].nunique()\n",
    "        df2.columns = ['unique oid count']\n",
    "\n",
    "        df = df1.join(df2)\n",
    "        df.loc['total'] = df.sum()\n",
    "        df.reset_index(inplace = True) \n",
    "\n",
    "        start_row = 0\n",
    "        start_col = 0    \n",
    "\n",
    "        worksheet.merge_range(start_row, start_col, start_row, start_col + len(df.columns) - 1, 'gross charges by month', merge)        \n",
    "        for i in range(len(df.columns)):\n",
    "            worksheet.write(start_row + 1, start_col + i, df.columns[i], header)\n",
    "            for j in range(len(df)):\n",
    "                if df.columns[i] == 'unique oid count':\n",
    "                    fmt = number\n",
    "                else:\n",
    "                    fmt = money\n",
    "                worksheet.write(start_row + 2 + j, start_col + i, df.iloc[j,i], fmt)\n",
    "\n",
    "        worksheet.set_column(0,100,15)    \n",
    "\n",
    "        # by year\n",
    "        df.drop(df[df['year and month'] == 'total'].index, inplace = True)\n",
    "        df['year'] = df['year and month'].str[:4]    \n",
    "        by_year = df.groupby('year')[['total','unique oid count']].sum()    \n",
    "        by_year.loc['total'] = by_year.sum()\n",
    "        by_year.reset_index(inplace = True)\n",
    "\n",
    "        start_row = 0\n",
    "        start_col = len(df.columns)\n",
    "\n",
    "        worksheet.merge_range(start_row, start_col, start_row, start_col + len(by_year.columns) - 1, 'totals by year', merge)    \n",
    "        for i in range(len(by_year.columns)):\n",
    "            worksheet.write(start_row + 1, start_col + i, by_year.columns[i], header)\n",
    "            for j in range(len(by_year)):\n",
    "                if by_year.columns[i] == 'total':\n",
    "                    fmt = money\n",
    "                else:\n",
    "                    fmt = number\n",
    "                worksheet.write(start_row + 2 + j, start_col + i, by_year.iloc[j,i], fmt)    \n",
    "\n",
    "        # create confidence interval for gross charge and oid count\n",
    "        confidence = pd.DataFrame(columns = ['lower 95%','avg','upper 95%'])\n",
    "\n",
    "        for thing in ['total','unique oid count']:\n",
    "\n",
    "            x_bar = df[thing].mean()\n",
    "            s = df[thing].std()\n",
    "            n = len(df)\n",
    "\n",
    "            deg_freed = n - 1\n",
    "            phi = stats.t.ppf(0.95, deg_freed)\n",
    "\n",
    "            lower = x_bar - phi * (s/np.sqrt(n))\n",
    "            upper = x_bar + phi * (s/np.sqrt(n))\n",
    "\n",
    "            confidence.loc[thing] = [lower, x_bar, upper]\n",
    "\n",
    "        confidence.rename(index = {'total':'gross charge'}, inplace = True)\n",
    "        confidence.index.name = ''\n",
    "        confidence.reset_index(inplace = True)      \n",
    "\n",
    "        # write confidence interval\n",
    "        start_row = 0\n",
    "        start_col = len(df.columns) + len(by_year.columns) + 1\n",
    "\n",
    "        worksheet.merge_range(start_row, start_col, start_row, start_col + len(confidence.columns) - 1, '95% confidence intervals for avg per month', merge)\n",
    "        for i in range(len(confidence.columns)):\n",
    "            worksheet.write(start_row + 1, start_col + i, confidence.columns[i], header)\n",
    "            for j in range(len(confidence)):\n",
    "                if confidence.iloc[j][''] == 'unique oid count':\n",
    "                    fmt = number\n",
    "                else:\n",
    "                    fmt = money\n",
    "                worksheet.write(start_row + 2 + j, start_col + i, confidence.iloc[j,i], fmt)\n",
    "\n",
    "        confidence.rename(columns = {'':state}, inplace = True)\n",
    "        conf_dict[state] = confidence\n",
    "\n",
    "        # write some notes about gross charges    \n",
    "        start_row = 0\n",
    "        start_col = len(df.columns) + len(by_year.columns) + len(confidence.columns) + 2\n",
    "\n",
    "        worksheet.merge_range(start_row, start_col, start_row, start_col + 2, 'notes on gross charges', merge)    \n",
    "        worksheet.write(start_row + 1, start_col, 'gross charges include:')\n",
    "        for i in range(len(gross)):\n",
    "            worksheet.write(start_row + 2 + i, start_col, gross[i])\n",
    "\n",
    "        start_row = start_row + len(gross) + 3\n",
    "        worksheet.write(start_row, start_col, 'gross charges do not include:')\n",
    "        for i in range(len(not_gross)):\n",
    "            worksheet.write(start_row + 1 + i, start_col, not_gross[i])\n",
    "\n",
    "    workbook.close()        \n",
    "\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
