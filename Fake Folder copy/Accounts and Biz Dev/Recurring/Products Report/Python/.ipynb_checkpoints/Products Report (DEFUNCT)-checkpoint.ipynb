{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== part_categories start ==\n",
      "\n",
      "\n",
      "your df is called \"all_cats_df\"\n",
      "\n",
      "\n",
      "== part_categories end ==\n",
      "\n",
      "\n",
      "== part_cost_data start ==\n",
      "\n",
      "0 nulls\n",
      "the mean_stripe_margin is 77.44%\n",
      "\n",
      "the part types with no MSRP are/is: ['sku']\n",
      "\n",
      "avg gross profit for:\n",
      "parts, combos, and stripes\n",
      "which have been purchased within the last year\n",
      "whose sku_status equals \"working\"\n",
      "whose msrp is greater than zero\n",
      "which were bought by non resellers\n",
      "is 55.74%\n",
      "\n",
      "the parts with negative gross profit are: [2885, 3400]\n",
      "\n",
      "your dfs are: all_cost (cost on the sku level) and all_cost_by_part (cost on the part level)\n",
      "\n",
      "== part_cost_data end ==\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/Users/jarad/Fake Folder/Python Libraries/')\n",
    "\n",
    "from jb_libraries import *\n",
    "from part_categories_data import *\n",
    "from part_cost_data import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook_title = '2018 - 11 - Nov - Monthly Products Report'\n",
    "csv_path = '/Users/jarad/Fake Folder/InterDept/Recurring/Products Report/CSVs/'\n",
    "\n",
    "report_type = 'monthly'\n",
    "\n",
    "# go two years back\n",
    "date_start = '2016-11-01'\n",
    "date_end = '2018-11-30'\n",
    "\n",
    "adabox_avg_cost = 27.37 # average part cost over all adaboxes up to adabox009\n",
    "\n",
    "cur_per_end = date_end\n",
    "\n",
    "if report_type == 'monthly':\n",
    "    time = 'year and month'\n",
    "    per = 12\n",
    "    date_header = 'month'\n",
    "    \n",
    "    cur_per_start = str((pd.to_datetime(date_start) + pd.DateOffset(months = 24)).date())\n",
    "    cur_pretty = calendar.month_abbr[int(cur_per_start[5:7])] + ' ' + cur_per_start[:4]    \n",
    "    \n",
    "    prev_per_start = str((pd.to_datetime(date_start) + pd.DateOffset(months = 23)).date())\n",
    "    prev_per_end = cur_per_start\n",
    "    prev_pretty = calendar.month_abbr[int(prev_per_start[5:7])] + ' ' + prev_per_start[:4]\n",
    "    \n",
    "    overview_start = str((pd.to_datetime(date_start) + pd.DateOffset(months = 12)).date())\n",
    "    overview_end = date_end\n",
    "    \n",
    "elif report_type == 'quarterly':\n",
    "    time = 'year and quarter'\n",
    "    per = 4\n",
    "    date_header = 'quarter'\n",
    "    \n",
    "    cur_per_start = str((pd.to_datetime(date_start) + pd.DateOffset(months = 24)).date())\n",
    "    cur_pretty = 'Q' + str(pd.to_datetime(cur_per_end).quarter) + ' ' + str(pd.to_datetime(cur_per_end).year)[:4]        \n",
    "    \n",
    "    prev_per_start = str((pd.to_datetime(date_start) + pd.DateOffset(months = 21)).date())\n",
    "    prev_per_end = cur_per_start    \n",
    "    prev_pretty = 'Q' + str(pd.to_datetime(prev_per_start).quarter) + ' ' + str(pd.to_datetime(prev_per_start).year)[:4]    \n",
    "\n",
    "    overview_start = date_start\n",
    "    overview_end = date_end    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "*\n",
    "FROM orders_status\n",
    "ORDER BY orders_status_id \n",
    "''', db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "otb_main = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "otb.orders_id AS 'orders id',\n",
    "otb.sku_id AS 'otb sku id',\n",
    "k.part_id AS 'part id',\n",
    "otb.qty AS 'total qty'\n",
    "FROM orders_to_barcodes otb\n",
    "JOIN orders o ON otb.orders_id = o.orders_id\n",
    "LEFT JOIN skus k ON otb.sku_id = k.sku_id\n",
    "WHERE DATE(o.date_purchased) BETWEEN ' '''+ date_start +''' ' AND ' '''+ date_end +''' '\n",
    "AND otb.orders_id NOT IN \n",
    "(SELECT\n",
    "orders_id\n",
    "FROM orders\n",
    "WHERE orders_status IN (8,9,10,11,12,14,15)\n",
    "AND payment_method = 'Replacement Order')\n",
    "''', db)\n",
    "\n",
    "#=============================================================================================\n",
    "\n",
    "op_main = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "DATE(o.date_purchased) AS 'date purchased',\n",
    "op.orders_id AS 'orders id',\n",
    "op.part_id AS 'part id',\n",
    "op.products_quantity AS 'total qty'\n",
    "FROM orders_products op\n",
    "JOIN orders o ON op.orders_id = o.orders_id\n",
    "WHERE DATE(o.date_purchased) BETWEEN ' '''+ date_start +''' ' AND ' '''+ date_end +''' '\n",
    "AND o.orders_status NOT IN (8,9,10,11,12,14,15)\n",
    "AND o.payment_method != 'Replacement Order'\n",
    "''', db)\n",
    "\n",
    "op_main['total qty'] = op_main['total qty'].astype(int)\n",
    "\n",
    "#=============================================================================================\n",
    "\n",
    "customer_flags = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "o.orders_id,\n",
    "DATE(o.date_purchased) AS date_purchased,\n",
    "CASE \n",
    "WHEN o.orders_reseller = 0 AND o.orders_super_reseller = 0 THEN 'non reseller'\n",
    "WHEN o.orders_reseller = 1 AND o.orders_super_reseller = 0 THEN 'reseller'\n",
    "WHEN o.orders_super_reseller = 1 THEN 'super reseller'\n",
    "ELSE 'you missed one'\n",
    "END AS 'customer',\n",
    "op.part_id,\n",
    "op.products_quantity,\n",
    "op.products_quantity_free,\n",
    "op.products_price\n",
    "FROM orders o\n",
    "JOIN orders_products op ON o.orders_id = op.orders_id\n",
    "WHERE DATE(o.date_purchased) BETWEEN ' '''+ date_start +''' ' AND ' '''+ date_end +''' '\n",
    "AND o.orders_status NOT IN (8,9,10,11,12,14,15)\n",
    "AND o.payment_method != 'Replacement Order'\n",
    "''', db)\n",
    "\n",
    "customer_flags.columns = [x.replace('_',' ') for x in customer_flags.columns]\n",
    "customer_flags['products quantity'] = customer_flags['products quantity'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "qty totals do not match\n7,751,213 and 2,568,145",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5849748894cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'qty totals do not match\\n{:,.0f} and {:,.0f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: qty totals do not match\n7,751,213 and 2,568,145"
     ]
    }
   ],
   "source": [
    "otb_mat = otb_main.values\n",
    "\n",
    "otb_exp_main = np.zeros(shape = ((int(np.sum(otb_mat[:,-1])), len(otb_mat[0]))))\n",
    "\n",
    "counter = 0\n",
    "for i in np.arange(len(otb_mat)):\n",
    "    if otb_mat[i,-1] == 1:\n",
    "        otb_exp_main[counter] = otb_mat[i]\n",
    "        counter = counter + 1\n",
    "    else:\n",
    "        mult = otb_mat[i,-1]\n",
    "        otb_mat[i,-1] = 1\n",
    "        while mult > 0:\n",
    "            otb_exp_main[counter] = otb_mat[i]\n",
    "            mult = mult - 1\n",
    "            counter = counter + 1\n",
    "            \n",
    "otb_exp = pd.DataFrame(otb_exp_main)            \n",
    "otb_exp.columns = ['orders id','otb sku id','part id','total qty']\n",
    "otb_exp.sort_values(['orders id','part id'], inplace = True)\n",
    "otb_exp['sub index'] = otb_exp.groupby(['orders id','part id']).cumcount()\n",
    "\n",
    "v1 = otb_exp['total qty'].sum()\n",
    "v2 = otb_main['total qty'].sum()\n",
    "\n",
    "if v1 == v2:\n",
    "    pass\n",
    "else:\n",
    "    raise ValueError('qty totals do not match\\n{:,.0f} and {:,.0f}'.format(v1,v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_for_mat = op_main.drop('date purchased', 1)\n",
    "op_mat = op_for_mat.values\n",
    "\n",
    "op_exp_main = np.zeros(shape = ((int(np.sum(op_mat[:,-1])), len(op_mat[0]))))\n",
    "\n",
    "counter = 0\n",
    "for i in range(len(op_mat)):\n",
    "    if op_mat[i,-1] == 1:\n",
    "        op_exp_main[counter] = op_mat[i]\n",
    "        counter = counter + 1\n",
    "    else:\n",
    "        mult = op_mat[i,-1]\n",
    "        op_mat[i,-1] = 1\n",
    "        while mult > 0:\n",
    "            op_exp_main[counter] = op_mat[i]\n",
    "            mult = mult - 1\n",
    "            counter = counter + 1\n",
    "            \n",
    "op_exp = pd.DataFrame(op_exp_main)            \n",
    "op_exp.columns = ['orders id','part id','total qty']\n",
    "op_exp.sort_values(['orders id','part id'], inplace = True)\n",
    "op_exp['sub index'] = op_exp.groupby(['orders id','part id']).cumcount()\n",
    "\n",
    "v1 = op_exp['total qty'].sum()\n",
    "v2 = op_main['total qty'].sum()\n",
    "\n",
    "if v1 == v2:\n",
    "    pass\n",
    "else:\n",
    "    raise ValueError('qty totals do not match\\n{:,.0f} and {:,.0f}'.format(v1,v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "free_main = customer_flags.groupby(['orders id','part id'], as_index = False)[['products quantity free']].sum()\n",
    "free_main.rename(columns = {'products quantity free':'qty free'}, inplace = True)\n",
    "\n",
    "free_mat = free_main.values\n",
    "\n",
    "free_exp_main = np.zeros(shape = ((int(np.sum(free_mat[:,-1])), len(free_mat[0]))))\n",
    "\n",
    "counter = 0\n",
    "for i in range(len(free_mat)):\n",
    "    if free_mat[i,-1] == 1:\n",
    "        free_exp_main[counter] = free_mat[i]\n",
    "        counter = counter + 1\n",
    "    else:\n",
    "        mult = free_mat[i,-1]\n",
    "        free_mat[i,-1] = 1\n",
    "        while mult > 0:\n",
    "            free_exp_main[counter] = free_mat[i]\n",
    "            mult = mult - 1\n",
    "            counter = counter + 1\n",
    "            \n",
    "free_exp = pd.DataFrame(free_exp_main)            \n",
    "free_exp.columns = ['orders id', 'part id', 'qty free']\n",
    "free_exp.sort_values(['orders id','part id'], inplace = True)\n",
    "free_exp['sub index'] = free_exp.groupby(['orders id','part id']).cumcount()\n",
    "free_exp.drop(free_exp[(free_exp.iloc[:,:-1] == 0).all(1)].index, inplace = True)\n",
    "\n",
    "v1 = free_exp['qty free'].sum()\n",
    "v2 = customer_flags.groupby(['orders id','part id'], as_index = False)[['products quantity free']].sum()['products quantity free'].sum()\n",
    "\n",
    "if v1 == v2:\n",
    "    pass\n",
    "else:\n",
    "    raise ValueError('qty totals do not match\\n{:,.0f} and {:,.0f}'.format(v1,v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_exp = pd.merge(op_exp,\n",
    "                     otb_exp,\n",
    "                     how = 'left',\n",
    "                     on = ['orders id','part id','total qty','sub index']).merge(free_exp,\n",
    "                                                                                how = 'left',\n",
    "                                                                                on = ['orders id','part id','sub index'])\n",
    "\n",
    "sales_exp.drop('sub index', 1, inplace = True)\n",
    "sales_exp['qty free'].fillna(0, inplace = True)\n",
    "\n",
    "if sales_exp['total qty'].sum() == op_exp['total qty'].sum():\n",
    "    pass\n",
    "else:\n",
    "    raise ValueError('qty totals do not match')\n",
    "    \n",
    "skus_to_sales = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "part_id AS 'part id',\n",
    "sku_id AS 'sku id',\n",
    "CASE WHEN sku_id = 11573 THEN 'resale - no labor' ELSE LOWER(bom_type) END AS bom\n",
    "FROM skus\n",
    "''', db)    \n",
    "\n",
    "# single out consignment parts\n",
    "consign_main = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "sku_id,\n",
    "k.part_id,\n",
    "products_name,\n",
    "bom_type,\n",
    "sku_status\n",
    "FROM skus k\n",
    "JOIN products_description pd ON k.part_id = pd.part_id\n",
    "WHERE sku_outsourced_assembly = 1\n",
    "''', db)\n",
    "\n",
    "col_fix(consign_main)\n",
    "\n",
    "sales_exp['skus sku id'] = sales_exp['part id'].map(dict(zip(skus_to_sales['part id'], skus_to_sales['sku id'])))\n",
    "sales_exp['bom'] = sales_exp['skus sku id'].map(dict(zip(skus_to_sales['sku id'], skus_to_sales['bom'])))\n",
    "sales_exp['bom'].fillna('unspecified', inplace = True)\n",
    "\n",
    "# flag consignment parts\n",
    "sales_exp['bom'] = np.where(sales_exp['part id'].isin(consign_main['part id'].tolist()), 'consignment', sales_exp['bom'])\n",
    "\n",
    "# flag combos\n",
    "combos = all_cost2['part id'][all_cost2['type'] == 'combo'].tolist()\n",
    "sales_exp['bom'] = np.where(sales_exp['part id'].isin(combos), 'combos', sales_exp['bom'])\n",
    "sales_exp['bom'] = np.where(sales_exp['part id'] == 3836, 'unspecified', sales_exp['bom'])\n",
    "\n",
    "sales_exp['otb sku id'].fillna(sales_exp['skus sku id'], inplace = True)\n",
    "sales_exp.rename(columns = {'otb sku id':'sku id'}, inplace = True)\n",
    "sales_exp.drop('skus sku id', 1, inplace = True)\n",
    "\n",
    "print('parts/skus with unspecified bom\\n')\n",
    "print(sales_exp[['part id','sku id','bom']][(sales_exp['bom'] == 'unspecified')].drop_duplicates('part id').sort_values('part id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sku_cost = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "pm.sku_id AS 'sku id',\n",
    "IF(k.sku_outsourced_assembly = 1, pm.consigned_latest_cost, pm.latest_cost) AS 'cost per unit'\n",
    "FROM products_manufacturing pm\n",
    "JOIN skus k ON pm.sku_id = k.sku_id\n",
    "''', db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_exp['sku cost'] = sales_exp['sku id'].map(dict(zip(sku_cost['sku id'], sku_cost['cost per unit'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_cost = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "pts.part_id AS 'part id',\n",
    "pts.contains_part_id AS 'contains part id',\n",
    "pd.products_name AS 'part name',\n",
    "pts.pts_quantity * IF(k.sku_outsourced_assembly = 1, pm.consigned_latest_cost, pm.latest_cost) AS 'cost per unit',\n",
    "k.sku_status AS 'sku status',\n",
    "k.sku_date_modified AS 'date modified'\n",
    "\n",
    "FROM products_to_stuff pts\n",
    "JOIN skus k ON pts.contains_part_id = k.part_id\n",
    "JOIN products_manufacturing pm ON k.sku_id = pm.sku_id\n",
    "JOIN products_description pd ON pts.part_id = pd.part_id\n",
    "\n",
    "WHERE pts.part_id != 0\n",
    "AND pts.part_id IN (SELECT part_id FROM parts WHERE products_combo = 1)\n",
    "''', db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_cost.sort_values(['part id','contains part id','date modified'], inplace = True)\n",
    "combo_cost.drop_duplicates(['part id','contains part id'], keep = 'last', inplace = True)\n",
    "\n",
    "sales_exp['combo cost'] = sales_exp['part id'].map(dict(zip(combo_cost['part id'], combo_cost['cost per unit'])))\n",
    "sales_exp['cost per unit'] = np.where(sales_exp['combo cost'].isnull(), sales_exp['sku cost'], sales_exp['combo cost'])\n",
    "\n",
    "print('PNs with null cost')\n",
    "print(sales_exp['part id'][sales_exp['cost per unit'].isnull()].unique())\n",
    "\n",
    "if len(sales_exp['part id'][sales_exp['cost per unit'].isnull()].unique()):\n",
    "    sales_exp['cost per unit'].fillna(0, inplace = True)\n",
    "    \n",
    "sales_exp.drop(['sku cost','combo cost'], 1, inplace = True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if customer_flags['products quantity'].sum() == op_main['total qty'].sum():\n",
    "    pass\n",
    "else:\n",
    "    raise ValueError('qty totals do not match')\n",
    "    \n",
    "sales_exp['sku id'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_exp2 = pd.merge(sales_exp,\n",
    "                    customer_flags.drop_duplicates(['orders id','part id']).drop(['products quantity free','products quantity'], 1),\n",
    "                    how = 'left',\n",
    "                    on = ['orders id','part id'],\n",
    "                    copy = False)\n",
    "\n",
    "sales_exp2['orders id'] = pd.to_numeric(sales_exp2['orders id'])\n",
    "sales_exp2['orders id'] = [int(x) for x in sales_exp2['orders id']]\n",
    "\n",
    "print(sales_exp2['customer'].value_counts())\n",
    "\n",
    "partner = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "orders_id AS 'orders id'\n",
    "FROM orders_products\n",
    "WHERE part_id IN\n",
    "(SELECT\n",
    "part_id\n",
    "FROM products_description\n",
    "WHERE products_name LIKE '%partner%')\n",
    "''', db)\n",
    "\n",
    "sales_exp2['customer'] = np.where(sales_exp2['orders id'].isin(partner['orders id'].tolist()),\n",
    "                                 'partnership',\n",
    "                                  sales_exp2['customer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sales_exp2['total qty'].sum() == op_main['total qty'].sum():\n",
    "    pass\n",
    "else:\n",
    "    raise ValueError('qty totals do not match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_exp2['date purchased'] = pd.to_datetime(sales_exp2['date purchased'])\n",
    "sales_exp2['year and month'] = [str(x)[:7] for x in sales_exp2['date purchased']]\n",
    "sales_exp2['year and quarter'] = sales_exp2['date purchased'].dt.year.map(str) + '-Q' + sales_exp2['date purchased'].dt.quarter.map(str)\n",
    "\n",
    "sales_exp2['qty bought'] = sales_exp2['total qty'] - sales_exp2['qty free']\n",
    "\n",
    "particle = [3450,3451,3452,3453,3455,3454,3234,3233,2798,2725,2721,2723,2724,3051,3457,2799,3233,3234,2722]\n",
    "\n",
    "# particle is consignment\n",
    "# we receive one dollar from particle for each unit sold\n",
    "# consequently we are not affected by any part costs (overhead costs, yes, we are affected, but not part cost), so cost is zero\n",
    "sales_exp2['products price'] = np.where(sales_exp2['part id'].isin(particle), 1.00, sales_exp2['products price'])\n",
    "sales_exp2['cost per unit'] = np.where(sales_exp2['part id'].isin(particle), 0.0, sales_exp2['cost per unit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stripes costs are weird\n",
    "# we recently changed how we price and cost these (as of about may 2018)\n",
    "# for the price, that's in orders_products so don't worry about it here\n",
    "# for the cost, we'll create a stripe cost such that the gross profit margin for that stripe is equal to the mean_stripe_margin\n",
    "print('mean stripe margin is {:,.1f}%'.format(mean_stripe_margin * 100))\n",
    "\n",
    "# from all_cost df from part_cost.py\n",
    "stripe_ls = all_cost['part id'][all_cost['type'] == 'stripe'].tolist()\n",
    "\n",
    "sales_exp2['cost per unit'] = np.where((sales_exp2['part id'].isin(stripe_ls)) & (sales_exp2['date purchased'] <= '2018-05-01'), \n",
    "                                        (1 - mean_stripe_margin) * sales_exp2['products price'],\n",
    "                                        sales_exp2['cost per unit'])\n",
    "\n",
    "# fix adabox subscription cost and price\n",
    "#sales_exp2['cost per unit'] = np.where(sales_exp2['part id'] == 3067,\n",
    "#                                       adabox_avg_cost,\n",
    "#                                       sales_exp2['cost per unit'])\n",
    "\n",
    "#sales_exp2['products price'] = np.where(sales_exp2['part id'] == 3067,\n",
    "#                                        60.0,\n",
    "#                                        sales_exp2['products price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_exp2['revenue'] = sales_exp2['qty bought'] * sales_exp2['products price']\n",
    "sales_exp2['total cost'] = sales_exp2['total qty'] * sales_exp2['cost per unit']\n",
    "sales_exp2['gross profit'] = sales_exp2['revenue'] - sales_exp2['total cost']\n",
    "\n",
    "r = sales_exp2['revenue'].sum()\n",
    "gp = sales_exp2['gross profit'].sum()\n",
    "\n",
    "print('overall gross profit margin is {:,.1f}%'.format(gp/r * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sales_exp2['total qty'].sum() == op_main['total qty'].sum():\n",
    "    pass\n",
    "else:\n",
    "    raise ValueError('qty totals do not match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_names = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "part_id AS 'part id',\n",
    "LOWER(products_name) AS 'part name'\n",
    "FROM products_description\n",
    "''', db)\n",
    "\n",
    "sales_exp2['part name'] = sales_exp2['part id'].map(dict(zip(part_names['part id'], part_names['part name'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check gross profit margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only return where there were no freebies and someone actually paid some amount of revenue\n",
    "for_margin = sales_exp2[(sales_exp2['date purchased'].between(overview_start, overview_end))\n",
    "                      & (sales_exp2['qty free'] == 0)\n",
    "                      & (sales_exp2['revenue'] > 0)].copy()\n",
    "\n",
    "# get margin\n",
    "for_margin['margin'] = for_margin['gross profit']/for_margin['revenue']\n",
    "\n",
    "# flag strips, to make sure that our stripe cost fix worked\n",
    "for_margin['stripe'] = np.where(for_margin['part id'].isin(stripe_ls),'yes','no')\n",
    "\n",
    "print('icosaciles for margins')\n",
    "for_margin['margin'].describe(percentiles = np.arange(0,1.05,0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all \"bad margins\", so negative and greater than one\n",
    "# but we see in the icosaciles that the highest margin is 100%\n",
    "\n",
    "bad_margin = for_margin[(for_margin['margin'] < 0) | (for_margin['margin'] >= 1)].copy()\n",
    "\n",
    "print('{:,.0f} bad margin line(s)'.format(len(bad_margin)))\n",
    "print('bad margin counts as % of total lines: {:,.2f}%\\n'.format(len(bad_margin)/len(for_margin) * 100))\n",
    "\n",
    "print('proportion that are stripes')\n",
    "print(bad_margin['stripe'].value_counts()/bad_margin['stripe'].value_counts().sum())\n",
    "print('\\nbut we know from above that at every respective discount tier per part_id there are\\nonly a handful of negative profits,')\n",
    "print('so these \"bad margins\" don\\'t stem from the db, so to speak, they occurr as a result of order-specific actions')\n",
    "\n",
    "# check no cost against the db\n",
    "no_cost = bad_margin['sku id'][bad_margin['cost per unit'] == 0].unique()\n",
    "print('\\n{:,.0f} unique sku id(s) with zero latest cost'.format(len(no_cost)))\n",
    "\n",
    "db_cost_check = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "k.sku_id,\n",
    "k.part_id,\n",
    "pm.latest_cost\n",
    "FROM skus k\n",
    "JOIN products_manufacturing pm ON k.sku_id = pm.sku_id\n",
    "JOIN products_description pd ON k.part_id = pd.part_id\n",
    "WHERE k.sku_id IN '''+ str(tuple(no_cost)) +'''\n",
    "''', db)\n",
    "\n",
    "col_fix(db_cost_check)\n",
    "\n",
    "print('of those sku ids, %s have zero latest cost in the db' % len(db_cost_check['latest cost'] == 0))\n",
    "\n",
    "print('\\nskus that are in no_cost but not in the db')\n",
    "for x in no_cost:\n",
    "    if x not in db_cost_check['sku id'].tolist():\n",
    "        print('sku id ' + str(x)) # here in this script, a sku_id = 0 is a combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('all part_ids that we do not offer discounts on\\n')\n",
    "print(bad_margin[['part id','part name']][~bad_margin['part id'].isin(dis_main['part id'])].drop_duplicates().sort_values('part id'))\n",
    "print('\\nmakes sense')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check profit losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df1 = for_margin[(for_margin['gross profit'] < 0)\n",
    "               & (for_margin['part id'].isin(discount_losses['part id'].unique()))].groupby(['part id','part name'])[['gross profit']].sum().sort_values('gross profit')\n",
    "df1.columns = ['gross profit loss (expected)']\n",
    "\n",
    "df2 = for_margin[(for_margin['gross profit'] < 0)\n",
    "               & (~for_margin['part id'].isin(discount_losses['part id'].unique()))].groupby(['part id','part name'])[['gross profit']].sum().sort_values('gross profit')\n",
    "df2.columns = ['gross profit loss (unexpected)']\n",
    "\n",
    "profit_loss = pd.merge(df1,df2,how = 'outer',left_index = True, right_index = True).fillna(0)\n",
    "profit_loss['total loss'] = profit_loss.sum(1)\n",
    "profit_loss.sort_values('total loss', inplace = True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "min_ = for_margin['date purchased'].min().date()\n",
    "max_ = for_margin['date purchased'].max().date()\n",
    "months = np.floor((pd.to_datetime(max_) - pd.to_datetime(min_)).days/30)\n",
    "\n",
    "print('profit loss by part from %s to %s' % (min_,max_))\n",
    "profit_loss.loc['total'] = profit_loss.sum()\n",
    "\n",
    "print('\\nthat\\'s ${:,.0f} per month over {:,.0f} months'.format(profit_loss.loc['total', 'total loss']/months, months))\n",
    "\n",
    "profit_loss.format_(['m0'] * 3)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### profit loss over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_over_time = for_margin[for_margin['gross profit'] < 0].groupby(time)[['gross profit']].sum()\n",
    "print(loss_over_time.format_(['m0']))\n",
    "print('\\nperiod avg: ${:,.0f}'.format(loss_over_time['gross profit'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_over_time.pct_change(periods = 4).format_(['p2']).replace('nan%','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### profit losses for current period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_per_start, cur_per_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_main = for_margin[for_margin['gross profit'] < 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_loss_main = loss_main[loss_main['date purchased'].between(cur_per_start, cur_per_end)]\n",
    "\n",
    "current_loss = current_loss_main.groupby(['part id','part name'], as_index = False)[['gross profit']].sum().sort_values('gross profit')\n",
    "\n",
    "tot = pd.DataFrame({'part id':'total','part name':'','gross profit':current_loss['gross profit'].sum()}, index = [0])\n",
    "current_loss = pd.concat([current_loss, tot])\n",
    "\n",
    "current_loss.rename(columns = {'gross profit':cur_pretty + ' gross profit losses'})\n",
    "\n",
    "print(len(current_loss) - 1)\n",
    "\n",
    "current_loss.format_([0,0,'m0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### explore current profit losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val1 = current_loss_main.groupby('customer')[['gross profit']].sum()\n",
    "val2 = current_loss_main.groupby('customer')[['gross profit']].sum().sum()\n",
    "\n",
    "val1/val2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_loss_main[['orders id','part id','part name','qty bought','total cost','products price','revenue']][current_loss_main['part id'] == 2598].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top 3 per period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = loss_main.groupby([time,'part id','part name'])[['gross profit']].sum()\n",
    "g2 = g1['gross profit'].groupby(level = 0, group_keys = False)\n",
    "top_3 = pd.DataFrame(g2.nsmallest(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_cats_df df from part_categories.py\n",
    "all_cats_df['cat name'] = [x.lower() for x in all_cats_df['cat name']]\n",
    "sales_exp2['category'] = sales_exp2['part id'].map(dict(zip(all_cats_df['part id'], all_cats_df['cat name'])))\n",
    "\n",
    "# check nulls in the db\n",
    "print(pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "products_name\n",
    "FROM products_description\n",
    "WHERE part_id IN '''+ str(tuple(sales_exp2['part id'][sales_exp2['category'].isnull()].unique())) +'''\n",
    "''', db))\n",
    "\n",
    "print('\\nif all stripes then fill nulls with \"stripe\"')\n",
    "sales_exp2['category'].fillna('stripe', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sales_exp2['total qty'].sum() == op_main['total qty'].sum():\n",
    "    pass\n",
    "else:\n",
    "    raise ValueError('qty totals do not match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prods = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "part_id AS 'part id',\n",
    "DATE(products_date_added) AS 'date added'\n",
    "FROM parts\n",
    "''', db)\n",
    "\n",
    "new_prods['date added'] = pd.to_datetime(new_prods['date added'])\n",
    "\n",
    "new_prods['year and month added'] = [str(x)[:7] for x in new_prods['date added']]\n",
    "new_prods['year and quarter added'] = new_prods['date added'].dt.year.map(str) + '-Q' + new_prods['date added'].dt.quarter.map(str)\n",
    "\n",
    "cur_new_prods = new_prods[new_prods['date added'].between(cur_per_start, cur_per_end)].drop('date added', 1).drop_duplicates()\n",
    "\n",
    "sales_exp3 = pd.merge(sales_exp2,\n",
    "                      new_prods,\n",
    "                      on = 'part id',\n",
    "                      how = 'left',\n",
    "                      copy = False)\n",
    "\n",
    "sales_exp3['new product'] = np.where(sales_exp3['date added'].between(cur_per_start, cur_per_end), 1, 0)\n",
    "\n",
    "sales_exp3['new product over time'] = np.where(sales_exp3[time + ' added'] == sales_exp3[time], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sales_exp3['total qty'].sum() == op_main['total qty'].sum():\n",
    "    pass\n",
    "else:\n",
    "    raise ValueError('qty totals do not match')\n",
    "    \n",
    "print('%s null(s)' % np.sum(sales_exp3.isnull().any(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partnerships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partner = sales_exp3[sales_exp3['customer'] == 'partnership'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p2 = partner[partner['date purchased'].between(cur_per_start, cur_per_end)].groupby(['orders id','part id','part name']).agg({'revenue':'sum'})\n",
    "p2.loc[('','','total'),] = p2.sum()\n",
    "p2.format_(['m2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with PLM [Daily Stats](https://volcano.adafruit.com/volcano/ada_plm.php?zenAdminID=c2d3ee839d38936bafca30cd28172680#/Stats/Sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "DATE_FORMAT(timestamp, '%Y-%m') AS 'year and month',\n",
    "SUM(d_value) AS 'PLM revenue'\n",
    "FROM daily_stats\n",
    "WHERE d_class = 'd_all'\n",
    "AND DATE(timestamp) BETWEEN ' '''+ date_start +''' ' AND ' '''+ date_end +''' '\n",
    "GROUP BY DATE_FORMAT(timestamp, '%Y-%m')\n",
    "''', db)\n",
    "\n",
    "ds.set_index('year and month', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_check = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "DATE_FORMAT(o.date_purchased, '%Y-%m') AS 'year and month',\n",
    "SUM((op.products_quantity - op.products_quantity_free) * op.products_price) AS 'particle revenue'\n",
    "FROM orders_products op\n",
    "JOIN orders o ON op.orders_id = o.orders_id\n",
    "AND DATE(o.date_purchased) BETWEEN ' '''+ date_start +''' ' AND ' '''+ date_end +''' '\n",
    "AND o.orders_status NOT IN (8,9,10,11,12,14,15)\n",
    "AND o.payment_method != 'Replacement Order'\n",
    "WHERE op.part_id IN '''+ str(tuple(particle)) +'''\n",
    "GROUP BY DATE_FORMAT(o.date_purchased, '%Y-%m')\n",
    "''', db)\n",
    "\n",
    "particle_check.set_index('year and month', inplace = True)\n",
    "\n",
    "particle_fix_for_check = sales_exp3[sales_exp3['part id'].isin(particle)].groupby('year and month')[['revenue']].sum().rename(columns = {'revenue':'fixed particle revenue'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refunds01 = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "DATE_FORMAT(o.date_purchased, '%Y-%m') AS 'year and month',\n",
    "ot.orders_id AS 'orders id',\n",
    "ot.value AS 'ot rev'\n",
    "FROM orders_total ot\n",
    "JOIN orders o ON ot.orders_id = o.orders_id\n",
    "AND DATE(o.date_purchased) BETWEEN ' '''+ date_start +''' ' AND ' '''+ date_end +''' '\n",
    "AND o.orders_status NOT IN (8,9,10,11,12,14,15)\n",
    "AND o.payment_method != 'Replacement Order'\n",
    "WHERE ot.class = 'ot_subtotal'\n",
    "''', db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refunds02 = pd.read_sql(\n",
    "'''\n",
    "SELECT\n",
    "o.orders_id AS 'orders id',\n",
    "SUM((op.products_quantity - op.products_quantity_free) * op.products_price) AS 'op rev'\n",
    "FROM orders o\n",
    "JOIN orders_products op ON o.orders_id = op.orders_id\n",
    "WHERE DATE(o.date_purchased) BETWEEN ' '''+ date_start +''' ' AND ' '''+ date_end +''' '\n",
    "AND o.orders_status NOT IN (8,9,10,11,12,14,15)\n",
    "AND o.payment_method != 'Replacement Order'\n",
    "GROUP BY op.orders_id\n",
    "''', db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adabox = pd.read_sql(\n",
    "#'''\n",
    "#SELECT\n",
    "#DATE_FORMAT(o.date_purchased, '%Y-%m') AS 'year and month',\n",
    "#SUM(op.products_quantity - op.products_quantity_free) * 60 AS 'adabox subscription revenue'\n",
    "#FROM orders_products op\n",
    "#JOIN orders o ON op.orders_id = o.orders_id\n",
    "#AND DATE(o.date_purchased) BETWEEN ' '''+ date_start +''' ' AND ' '''+ date_end +''' '\n",
    "#WHERE op.part_id = 3067\n",
    "#AND op.products_price = 0\n",
    "#AND o.orders_status NOT IN (8,9,10,11,12,14,15)\n",
    "#AND o.payment_method != 'Replacement Order'\n",
    "#GROUP BY DATE_FORMAT(o.date_purchased, '%Y-%m')\n",
    "#''', db)\n",
    "\n",
    "#adabox.set_index('year and month', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = sales_exp3.groupby('year and month')[['revenue']].sum().rename(columns = {'revenue':'prod report revenue'}).join(ds).join(particle_check).join(particle_fix_for_check).join(refunds)#.join(adabox)\n",
    "check['fixed particle revenue'] = check['fixed particle revenue'] * -1\n",
    "#check['adabox subscription revenue'] = check['adabox subscription revenue'] * -1\n",
    "check = check[['prod report revenue',\n",
    "               'fixed particle revenue',\n",
    "               'particle revenue',\n",
    "#               'adabox subscription revenue',\n",
    "               'refunds',\n",
    "               'PLM revenue']]\n",
    "check['difference'] = check['PLM revenue'] - (check.sum(1) - check['PLM revenue'])\n",
    "check.reset_index(inplace = True)\n",
    "\n",
    "def diff(x):\n",
    "    if (x['difference'] > -1) and (x['difference'] < 1):\n",
    "        return 0\n",
    "    else:\n",
    "        return x['difference']\n",
    "\n",
    "check['difference'] = check.apply(diff, axis = 1)\n",
    "\n",
    "# get the most recent 13 months\n",
    "check = check.iloc[-13:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check.format_([0] + ['m0'] * (len(check.columns) - 1)).replace('$nan','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excel Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumcount goes \"0,1,2, etc\"\n",
    "# we are going to sum this column to get unique orders (further down we do this)\n",
    "sales_exp3['orders'] = sales_exp3.groupby('orders id')[['orders id']].cumcount()\n",
    "# replace 1 and over with null, so they don't sum\n",
    "sales_exp3['orders'] = np.where(sales_exp3['orders'] >= 1, np.nan, sales_exp3['orders'])  \n",
    "# replace zero with 1 so it sums\n",
    "sales_exp3['orders'] = sales_exp3['orders'].replace(0,1)\n",
    "\n",
    "total_rev = np.sum(sales_exp3['revenue'][(sales_exp3['date purchased'].between(cur_per_start, cur_per_end))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook = xlsxwriter.Workbook(csv_path + workbook_title + '.xlsx',\n",
    "                               {'nan_inf_to_errors': True})\n",
    "\n",
    "tabs = ['overview',\n",
    "       'all customers',\n",
    "       'resellers',\n",
    "       'super resellers',\n",
    "       'manufacturing',\n",
    "       'new products',\n",
    "       'by category',\n",
    "       'by bom',\n",
    "       'notes on revenue totals']\n",
    "\n",
    "#===== formats\n",
    "#==========================================================================================\n",
    "\n",
    "colors = {\n",
    "'1':'#343635',\n",
    "'2':'#2e4874',\n",
    "'3':'#7eaba4',\n",
    "'4':'#928c85',\n",
    "'5':'#347c83',\n",
    "'6':'#ebe9f2'\n",
    "} # http://www.color-hex.com/color-palette/57101\n",
    "\n",
    "colors2 = {\n",
    "'1':'#2e4045',\n",
    "'2':'#83adb5',\n",
    "'3':'#c7bbc9',\n",
    "'4':'#928c85',\n",
    "'5':'#5e3c58',\n",
    "'6':'#bfb5b2'\n",
    "} # http://www.color-hex.com/color-palette/240\n",
    "\n",
    "title = workbook.add_format({'font_size':25,\n",
    "                             'font_name':'Arial (Bold)'})\n",
    "\n",
    "sub_title = workbook.add_format({'font_size':15,\n",
    "                                 'font_name':'Arial (Bold)'})\n",
    "\n",
    "\n",
    "col_names = workbook.add_format({'font_name':'Arial (Bold)',\n",
    "                                 'font_color':'white',\n",
    "                                 'valign':'vcenter',\n",
    "                                 'align':'center',\n",
    "                                 'bg_color':colors['3'],\n",
    "                                 'bottom':1,\n",
    "                                 'top':1,\n",
    "                                 'left':1,\n",
    "                                 'right':1})\n",
    "\n",
    "money = workbook.add_format({'num_format':'$#,##0'})\n",
    "percent = workbook.add_format({'num_format':'0.00%'})\n",
    "number = workbook.add_format({'num_format':'#,##0'})\n",
    "\n",
    "for tab in tabs:\n",
    "    workbook.add_worksheet(tab) # create each tab\n",
    "\n",
    "my_worksheets = {}\n",
    "for sht in workbook.worksheets():\n",
    "    my_worksheets[sht.get_name()] = sht # create dict like tab_name:worksheet_instance\n",
    "\n",
    "#===== same formatting\n",
    "#==========================================================================================\n",
    "for k, v in my_worksheets.items():\n",
    "    sht = my_worksheets[k]\n",
    "    sht.write(0, 0,\n",
    "              k.title(),\n",
    "              title)\n",
    "    sht.write(1, 0,\n",
    "              workbook_title,\n",
    "              sub_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### overview "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmts = {'revenue':money, \n",
    "        'revenue %':percent,\n",
    "        'gross profit':money,\n",
    "        'gross profit %':percent,\n",
    "        'orders':number, \n",
    "        'orders %':percent}\n",
    "\n",
    "sht = my_worksheets['overview']\n",
    "\n",
    "start_row = 4\n",
    "start_col = 0\n",
    "\n",
    "for_aov = {}\n",
    "for x in ['revenue','gross profit','orders']:\n",
    "\n",
    "    sht.write(start_row, start_col, x.title(), sub_title)\n",
    "\n",
    "    df = sales_exp3[sales_exp3['date purchased'].between(overview_start, overview_end)].groupby([time,'customer'])[[x]].sum().unstack(1).fillna(0)\n",
    "    df.columns = df.columns.droplevel(0)\n",
    "    cols = ['non reseller','reseller','super reseller','partnership']\n",
    "    df = df[cols]\n",
    "    df['total'] = df.sum(1)\n",
    "    df.reset_index(inplace = True)\n",
    "\n",
    "    for_aov[x] = df        \n",
    "\n",
    "    for i in range(len(df.columns)):\n",
    "        sht.write(start_row + 1, start_col + i,\n",
    "                  df.columns[i],\n",
    "                  col_names)\n",
    "\n",
    "        sht.set_column(start_col + i,\n",
    "                       start_col + i,\n",
    "                       np.max([len(str(x)) for x in df.iloc[:, i]] + [len(str(x)) for x in df.columns]) + 1)\n",
    "\n",
    "        for j in range(len(df)):\n",
    "            sht.write(start_row + 2 + j, start_col + i,\n",
    "                     df.iloc[j,i],\n",
    "                     fmts[x])\n",
    "\n",
    "    start_row = start_row + len(df) + 2\n",
    "\n",
    "    df2 = df.set_index(time).pct_change()\n",
    "    df2.loc['YoY'] = df.set_index(time).pct_change(periods = per).iloc[-1]\n",
    "    df2.reset_index(inplace = True)\n",
    "    df2.replace(np.nan, '', inplace = True)\n",
    "    df2.replace(np.inf, '', inplace = True)\n",
    "    df2.replace(-np.inf, '', inplace = True)\n",
    "\n",
    "    for i in range(len(df2.columns)):\n",
    "        sht.write(start_row + 1, start_col + i,\n",
    "                  df2.columns[i],\n",
    "                  col_names)\n",
    "\n",
    "        for j in range(len(df2)):\n",
    "            sht.write(start_row + 2 + j, start_col + i,\n",
    "                     df2.iloc[j,i],\n",
    "                     fmts[x + ' %'])\n",
    "\n",
    "    start_row = start_row + len(df2) + 2\n",
    "\n",
    "    df3 = pd.DataFrame(df.mean(), columns = [report_type + ' avg']).reset_index()\n",
    "\n",
    "    for i in range(len(df3.columns)):\n",
    "        sht.write(start_row + 1, start_col + i,\n",
    "                  df3.columns[i],\n",
    "                  col_names)\n",
    "\n",
    "        for j in range(len(df3)):\n",
    "            sht.write(start_row + 2 + j, start_col + i,\n",
    "                     df3.iloc[j,i],\n",
    "                     fmts[x])\n",
    "\n",
    "    start_col = start_col + len(df.columns) + 2\n",
    "    start_row = 4\n",
    "\n",
    "#===== AOV add on for overview tab\n",
    "#==========================================================================================        \n",
    "\n",
    "aov = for_aov['revenue'].set_index(time).div(for_aov['orders'].set_index(time), axis = 1)\n",
    "aov.loc['YoY'] = aov.pct_change(periods = per).iloc[-1]\n",
    "aov.reset_index(inplace = True)\n",
    "aov.replace(np.nan, '', inplace = True)\n",
    "aov.replace(np.inf, '', inplace = True)\n",
    "aov.replace(-np.inf, '', inplace = True)\n",
    "\n",
    "if report_type == 'monthly':\n",
    "    start_row = 43\n",
    "else:\n",
    "    start_row = 35\n",
    "    \n",
    "start_col = 16    \n",
    "sht.write(start_row, start_col, 'AOV', sub_title)\n",
    "\n",
    "for i in range(len(aov.columns)):\n",
    "    sht.write(start_row + 1, start_col + i,\n",
    "              aov.columns[i],\n",
    "              col_names)\n",
    "\n",
    "    sht.set_column(start_col + i,\n",
    "                   start_col + i,\n",
    "                   np.max([len(str(x)) for x in aov.iloc[:, i]] + [len(str(x)) for x in aov.columns]) + 1)\n",
    "    \n",
    "    for j in range(len(aov)):\n",
    "        \n",
    "        if aov.loc[j,time] == 'YoY':\n",
    "            fmt = percent\n",
    "        else:\n",
    "            fmt = money\n",
    "                \n",
    "        sht.write(start_row + 2 + j, start_col + i,\n",
    "                 aov.iloc[j,i],\n",
    "                 fmt)\n",
    "\n",
    "start_row = start_row + len(aov) + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all customers, resellers, super resellers, manufacturing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_charts = {}\n",
    "for_charts_ot = {}\n",
    "\n",
    "dict_ = {'all customers':sales_exp3['customer'].isin(['non reseller','reseller','super reseller','partnership']),\n",
    "        'resellers':sales_exp3['customer'].isin(['reseller']),\n",
    "        'super resellers':sales_exp3['customer'].isin(['super reseller']),\n",
    "        'manufacturing':sales_exp3['bom'] == 'pnp'}\n",
    "\n",
    "for k, v in dict_.items():\n",
    "\n",
    "    fmts = {'part id':None,\n",
    "            'part name':None,\n",
    "             cur_pretty:money,\n",
    "             prev_pretty:money,\n",
    "            '% of New Products':percent,\n",
    "            '% of total':percent,\n",
    "            '% change':percent,\n",
    "            '% of ' + k.title():percent,\n",
    "            'margin':percent,\n",
    "            'revenue':money,\n",
    "            'gross profit':money,\n",
    "            'total qty':number,\n",
    "            time:None}\n",
    "\n",
    "    sht = my_worksheets[k]\n",
    "    \n",
    "    if k == 'manufacturing':\n",
    "        sht.write(2,0,'*a manufactured part is any part that has a bom type of \"PNP\" and which is not a consigned part')\n",
    "\n",
    "    df1 = sales_exp3[(sales_exp3['date purchased'].between(cur_per_start, cur_per_end))\n",
    "                    & (dict_[k])].groupby(['part id','part name'], as_index = False)[['revenue','gross profit']].sum()\n",
    "    df1['% of ' + k.title()] = df1['revenue']/df1['revenue'].sum()\n",
    "    df1['% of total'] = df1['revenue']/total_rev\n",
    "    df1['margin'] = df1['gross profit']/df1['revenue']\n",
    "    df1.rename(columns = {'revenue':cur_pretty}, inplace = True)\n",
    "\n",
    "    df2 = sales_exp3[(sales_exp3['date purchased'] >= prev_per_start)\n",
    "                   & (sales_exp3['date purchased'] < prev_per_end)\n",
    "                   & (dict_[k])].groupby(['part id','part name'], as_index = False)[['revenue']].sum()\n",
    "    df2.rename(columns = {'revenue':prev_pretty}, inplace = True)\n",
    "\n",
    "    df3 = pd.merge(df1,\n",
    "                  df2,\n",
    "                  how = 'left',\n",
    "                  on = ['part id','part name']).drop('gross profit',1)\n",
    "    df3['% change'] = df3[cur_pretty]/df3[prev_pretty] - 1\n",
    "    cols = ['part id','part name',prev_pretty,cur_pretty,'% change','% of ' + k.title(),'% of total','margin']\n",
    "    df3 = df3[cols].sort_values(cur_pretty, ascending = False).head(25).fillna(0)    \n",
    "\n",
    "    for_charts[k] = df3\n",
    "\n",
    "    start_row = 4\n",
    "    start_col = 0\n",
    "\n",
    "    sht.write(start_row, start_col, 'Top 25 Parts by Revenue', sub_title)\n",
    "\n",
    "    for i in range(len(df3.columns)):\n",
    "        sht.write(start_row + 1, start_col + i,\n",
    "                 df3.columns[i],\n",
    "                 col_names)\n",
    "\n",
    "        sht.set_column(start_col + i,\n",
    "                   start_col + i,\n",
    "                   np.max([len(str(x)) for x in df3.iloc[:, i]] + [len(str(x)) for x in df3.columns]) + 1)\n",
    "\n",
    "        for j in range(len(df3)):\n",
    "            sht.write(start_row + 2 + j, start_col + i,\n",
    "                     df3.iloc[j,i],\n",
    "                     fmts[df3.columns[i]])\n",
    "\n",
    "    ot = sales_exp3[dict_[k]][sales_exp3[dict_[k]]['date purchased'].between(overview_start, overview_end)].groupby(time, as_index = False)[['revenue','gross profit','total qty']].sum()\n",
    "    ot['margin'] = ot['gross profit']/ot['revenue']\n",
    "    cols = [time,'revenue','gross profit','margin','total qty']\n",
    "    ot = ot[cols]\n",
    "\n",
    "    for_charts_ot[k] = ot\n",
    "\n",
    "    start_col = start_col + len(df3.columns) + 1\n",
    "\n",
    "    sht.write(start_row, start_col, k.title() + ' Totals Over Time', sub_title)\n",
    "\n",
    "    for i in range(len(ot.columns)):\n",
    "        sht.write(start_row + 1, start_col + i,\n",
    "                 ot.columns[i],\n",
    "                 col_names)\n",
    "\n",
    "        sht.set_column(start_col + i,\n",
    "                       start_col + i,\n",
    "                       np.max([len(str(x)) for x in ot.iloc[:, i]] + [len(str(x)) for x in ot.columns]) + 1)\n",
    "\n",
    "        for j in range(len(ot)):\n",
    "            sht.write(start_row + 2 + j, start_col + i,\n",
    "                     ot.iloc[j,i],\n",
    "                     fmts[ot.columns[i]])\n",
    "\n",
    "    start_row = start_row + len(ot) + 2\n",
    "\n",
    "    avg = pd.DataFrame(ot.mean(), columns = [report_type + ' avg']).reset_index().rename(columns = {'index':'type'})\n",
    "\n",
    "    for i in range(len(avg.columns)):\n",
    "        sht.write(start_row + 1, start_col + i,\n",
    "                 avg.columns[i],\n",
    "                 col_names)\n",
    "\n",
    "        sht.set_column(start_col + i,\n",
    "                       start_col + i,\n",
    "                       np.max([len(str(x)) for x in avg.iloc[:, i]] + [len(str(x)) for x in avg.columns]) + 1)\n",
    "\n",
    "        for j in range(len(avg)):\n",
    "            sht.write(start_row + 2 + j, start_col + i,\n",
    "                     avg.iloc[j,i],\n",
    "                     fmts[avg.loc[j]['type']])\n",
    "\n",
    "    start_row = 4\n",
    "    start_col = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### new products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sht = my_worksheets['new products']    \n",
    "\n",
    "# current new products\n",
    "new = sales_exp3[(sales_exp3['new product'] == 1)\n",
    "                & (sales_exp3['date purchased'].between(cur_per_start, cur_per_end))].groupby(['part id','part name'], as_index = False)[['revenue','gross profit']].sum().sort_values('revenue', ascending = False).rename(columns = {'revenue':cur_pretty})\n",
    "new['% of New Products'] = new[cur_pretty]/new[cur_pretty].sum()\n",
    "new['% of total'] = new[cur_pretty]/total_rev\n",
    "new['margin'] = new['gross profit']/new[cur_pretty]\n",
    "new.drop('gross profit', 1, inplace = True)\n",
    "new['part id'] = [int(x) for x in new['part id']]\n",
    "\n",
    "start_row = 4\n",
    "start_col = 0\n",
    "\n",
    "sht.write(start_row, start_col, 'All New Products by Revenue', sub_title)\n",
    "sht.write(2,0,'*for New Products we use the \"date added\" field in the \"parts\" table in the database')\n",
    "\n",
    "fmts = {'part id':None,\n",
    "        'part name':None,\n",
    "         cur_pretty:money,\n",
    "         prev_pretty:money,\n",
    "        '% of New Products':percent,\n",
    "        '% of total':percent,\n",
    "        '% change':percent,\n",
    "        'margin':percent,\n",
    "        'revenue':money,\n",
    "        'gross profit':money,\n",
    "        'total qty':number,\n",
    "        time:None}\n",
    "\n",
    "for i in range(len(new.columns)):\n",
    "    sht.write(start_row + 1, start_col + i,\n",
    "             new.columns[i],\n",
    "             col_names)\n",
    "\n",
    "    sht.set_column(start_col + i,\n",
    "               start_col + i,\n",
    "               np.max([len(str(x)) for x in new.iloc[:, i]] + [len(str(x)) for x in new.columns]) + 1)\n",
    "\n",
    "    for j in range(len(new)):\n",
    "        sht.write(start_row + 2 + j, start_col + i,\n",
    "                 new.iloc[j,i],\n",
    "                 fmts[new.columns[i]])\n",
    "\n",
    "# new products over time\n",
    "new_ot = sales_exp3[(sales_exp3['new product over time'] == 1)\n",
    "                   & (sales_exp3['date purchased'].between(overview_start, overview_end))].groupby(time, as_index = False)[['revenue','gross profit','total qty']].sum()\n",
    "new_ot['margin'] = new_ot['gross profit']/new_ot['revenue']\n",
    "new_ot = new_ot[[time,'revenue','gross profit','margin','total qty']]\n",
    "\n",
    "start_col = start_col + len(new.columns) + 1\n",
    "\n",
    "sht.write(start_row - 1, start_col, '*parts which were released and sold in the same period')\n",
    "sht.write(start_row, start_col, 'Totals Over Time', sub_title)\n",
    "\n",
    "for i in range(len(new_ot.columns)):\n",
    "    sht.write(start_row + 1, start_col + i,\n",
    "             new_ot.columns[i],\n",
    "             col_names)\n",
    "\n",
    "    sht.set_column(start_col + i,\n",
    "                   start_col + i,\n",
    "                   np.max([len(str(x)) for x in new_ot.iloc[:, i]] + [len(str(x)) for x in new_ot.columns]) + 1)\n",
    "\n",
    "    for j in range(len(new_ot)):\n",
    "        sht.write(start_row + 2 + j, start_col + i,\n",
    "                 new_ot.iloc[j,i],\n",
    "                 fmts[new_ot.columns[i]])\n",
    "\n",
    "start_row = start_row + len(new_ot) + 2\n",
    "\n",
    "new_avg = pd.DataFrame(new_ot.mean(), columns = [report_type + ' avg']).reset_index().rename(columns = {'index':'type'})\n",
    "\n",
    "for i in range(len(new_avg.columns)):\n",
    "    sht.write(start_row + 1, start_col + i,\n",
    "             new_avg.columns[i],\n",
    "             col_names)\n",
    "\n",
    "    sht.set_column(start_col + i,\n",
    "                   start_col + i,\n",
    "                   np.max([len(str(x)) for x in new_avg.iloc[:, i]] + [len(str(x)) for x in new_avg.columns]) + 1)\n",
    "\n",
    "    for j in range(len(new_avg)):\n",
    "        sht.write(start_row + 2 + j, start_col + i,\n",
    "                 new_avg.iloc[j,i],\n",
    "                 fmts[new_avg.loc[j]['type']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### by category, by bom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_and_bom_charts = {}\n",
    "\n",
    "fmts = {cur_pretty:money,\n",
    "       prev_pretty:money,\n",
    "       '% change':percent,\n",
    "       '% of total':percent,\n",
    "       'margin':percent,\n",
    "       'category':None,\n",
    "       'bom':None}\n",
    "\n",
    "for col in ['category','bom']:\n",
    "\n",
    "    sht = my_worksheets['by ' + col]\n",
    "\n",
    "    df1 = sales_exp3[sales_exp3['date purchased'].between(cur_per_start, cur_per_end)].groupby(col, as_index = False)[['revenue','gross profit']].sum()\n",
    "    df1['% of total'] = df1['revenue']/total_rev\n",
    "    df1['margin'] = df1['gross profit']/df1['revenue']\n",
    "    df1.rename(columns = {'revenue':cur_pretty}, inplace = True)\n",
    "\n",
    "    df2 = sales_exp3[(sales_exp3['date purchased'] >= prev_per_start)\n",
    "                   & (sales_exp3['date purchased'] < prev_per_end)].groupby(col, as_index = False)[['revenue']].sum()\n",
    "    df2.rename(columns = {'revenue':prev_pretty}, inplace = True)\n",
    "\n",
    "    if len(df1) >= len(df2):\n",
    "        how = 'left'\n",
    "    else:\n",
    "        how = 'right'\n",
    "\n",
    "    df3 = pd.merge(df1,\n",
    "                  df2,\n",
    "                  how = how,\n",
    "                  on = col).drop('gross profit',1).fillna(0)\n",
    "    df3['% change'] = df3[cur_pretty]/df3[prev_pretty] - 1\n",
    "    \n",
    "    for r in [np.inf, -np.inf, np.nan]:\n",
    "        df3['% change'] = df3['% change'].replace(r,0)\n",
    "\n",
    "    cols = [col, prev_pretty, cur_pretty, '% change', '% of total', 'margin']\n",
    "    df3 = df3[cols].sort_values(cur_pretty, ascending = False)\n",
    "\n",
    "    cat_and_bom_charts['by ' + col] = df3\n",
    "\n",
    "    start_row = 4\n",
    "    start_col = 0\n",
    "\n",
    "    if col == 'category':\n",
    "        wrt = 'Categories'\n",
    "    else:\n",
    "        wrt = 'BOMs'\n",
    "\n",
    "    sht.write(start_row, start_col, 'All ' + wrt + ' by Revenue', sub_title)\n",
    "\n",
    "    for i in range(len(df3.columns)):\n",
    "        sht.write(start_row + 1, start_col + i,\n",
    "                 df3.columns[i],\n",
    "                 col_names)\n",
    "\n",
    "        sht.set_column(start_col + i,\n",
    "                   start_col + i,\n",
    "                   np.max([len(str(x)) for x in df3.iloc[:, i]] + [len(str(x)) for x in df3.columns]) + 1)\n",
    "\n",
    "        for j in range(len(df3)):\n",
    "            sht.write(start_row + 2 + j, start_col + i,\n",
    "                     df3.iloc[j,i],\n",
    "                     fmts[df3.columns[i]])\n",
    "\n",
    "    if col == 'bom':\n",
    "        unspec = sales_exp3[['part id','part name']][sales_exp3['bom'] == 'unspecified'].drop_duplicates('part id').sort_values('part id', ascending = False)        \n",
    "        start_col =  start_col + len(df3.columns) + 1\n",
    "        sht.write(start_row, start_col,\n",
    "                 '*parts with \"unpecified\" BOMs')\n",
    "\n",
    "        for i in range(len(unspec.columns)):\n",
    "            sht.write(start_row + 1, start_col + i,\n",
    "                     unspec.columns[i],\n",
    "                     col_names)\n",
    "\n",
    "            sht.set_column(start_col + i,\n",
    "                       start_col + i,\n",
    "                       np.max([len(str(x)) for x in unspec.iloc[:, i]] + [len(str(x)) for x in unspec.columns]) + 1)\n",
    "\n",
    "            for j in range(len(unspec)):\n",
    "                sht.write(start_row + 2 + j, start_col + i,\n",
    "                         unspec.iloc[j,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### notes on revenue totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sht = my_worksheets['notes on revenue totals']\n",
    "\n",
    "start_row = 4\n",
    "start_col = 0\n",
    "\n",
    "df = check[check['year and month'].between(overview_start[:7], overview_end[:7])].copy()\n",
    "df.fillna(0, inplace = True)\n",
    "\n",
    "for i in range(len(df.columns)):\n",
    "    sht.write(start_row + 1, start_col + i,\n",
    "             df.columns[i],\n",
    "             col_names)\n",
    "\n",
    "    sht.set_column(start_col + i,\n",
    "               start_col + i,\n",
    "               np.max([len(str(x)) for x in df.iloc[:, i]] + [len(str(x)) for x in df.columns]) + 1)\n",
    "\n",
    "    for j in range(len(df)):\n",
    "        sht.write(start_row + 2 + j, start_col + i,\n",
    "                 df.iloc[j,i],\n",
    "                 money)\n",
    "\n",
    "text01 = 'The revenue in the Products Report is calculated a little differently than in PLM Daily Stats.\\n'\n",
    "text02 = 'This worksheet shows you how to get from the Products Report revenue all the way to the Daily Stats revenue.\\n'\n",
    "text03 = '\\n'\n",
    "text04 = 'First, start with the Products Report revenue (col B).\\n'\n",
    "text05 = 'Then subtract out the Particle Revenue that we fix in the Report (ask jarad@adafruit.com why this is so) (col C).\\n'\n",
    "text06 = 'Then add back in the Particle revenue that\\'s in the database (col D).\\n'\n",
    "text07 = 'Account for manual refunds that are not reflected in Daily Stats (col E).\\n'\n",
    "text08 = 'Check out the \"difference\" column (col F), which is \"PLM revenue\" minus the sum of all the columns before \"PLM revenue\".\\n'\n",
    "text09 = '\\nThere! You have now gone from the Products Report revenue all the way to Daily Stats!'\n",
    "text10 = '\\n\\nHowever, if the \"difference\" column is much greater than zero, this means that some orders have been processed and Daily Stats has not yet updated, so to speak.\\n'\n",
    "text11 = '\\nDon\\'t worry! This is totally normal and will all balance out in the next month!'\n",
    "text = ''.join([text01,text02,text03,text04,text05,text06,text07,text08,text09,text10,text11])\n",
    "\n",
    "options = {'width': 750,\n",
    "           'height': 300}\n",
    "\n",
    "sht.insert_textbox(start_row + len(df) + 3,\n",
    "                  start_col,\n",
    "                  text,\n",
    "                  options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### close and save workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwings as xw\n",
    "\n",
    "#plt.rcdefaults()\n",
    "#plt.rcParams.keys()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (20,5)\n",
    "\n",
    "plt.rcParams['lines.linewidth'] = 5\n",
    "plt.rcParams['legend.fontsize'] = 15\n",
    "\n",
    "plt.rcParams['font.weight'] = 'bold'\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "\n",
    "plt.rcParams['axes.titlesize'] = 20\n",
    "plt.rcParams['axes.titleweight'] = 'bold'\n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 15\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "\n",
    "plt.rcParams['xtick.labelsize'] = 15\n",
    "plt.rcParams['ytick.labelsize'] = 15\n",
    "\n",
    "\n",
    "sht = xw.Book(r'/Users/jarad/fake_folder/InterDept/Recurring/Products Report/Python/' + workbook_title + '.xlsx').sheets\n",
    "\n",
    "#===== summary chart 01\n",
    "#==========================================================================================\n",
    "\n",
    "chart01 = sales_exp3[sales_exp3['date purchased'].between(overview_start, overview_end)].groupby([time])[['revenue','gross profit','orders']].sum()\n",
    "\n",
    "if report_type == 'monthly':\n",
    "    xticks = [calendar.month_abbr[int(str(x)[-2:])] + '\\n' + str(x)[:4] for x in chart01.index]\n",
    "else:\n",
    "    xticks = [str(x)[-2:] + '\\n' + str(x)[:4] for x in chart01.index]    \n",
    "\n",
    "fig, ax = plt.subplots(figsize = (11,4))\n",
    "x = np.arange(len(chart01))\n",
    "y1 = chart01['revenue']\n",
    "y2 = chart01['gross profit']\n",
    "y3 = chart01['orders']\n",
    "w = 0.90\n",
    "\n",
    "plot01 = ax.bar(x, y1, width = w, edgecolor = 'black', color = colors['3'], label = 'Revenue')\n",
    "plot02 = ax.bar(x, y2, width = w, edgecolor = 'black', color = colors['2'], label = 'Gross Profit')\n",
    "ax.set_xlim(-0.5,len(chart01)-0.5)\n",
    "ax2 = ax.twinx()\n",
    "plot03, = ax2.plot(x, y3, ls = '--', color = colors['5'], label = 'Order Count')\n",
    "\n",
    "ax.set_facecolor(colors['6'])\n",
    "ax.set_title('Revenue, Gross Profit, and Order Count Over Time')\n",
    "ax.set_yticklabels(['${:,.0f}'.format(x/1000) for x in ax.get_yticks()])\n",
    "ax.set_ylabel('thousands')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax2.set_yticklabels(['{:,.0f}'.format(x/1000) for x in ax2.get_yticks()])\n",
    "ax2.set_ylabel('thousands', rotation = 270, labelpad = 25)\n",
    "ax.legend(loc = 'lower left', edgecolor = 'black')\n",
    "ax2.legend(loc = 'lower right', edgecolor = 'black')\n",
    "\n",
    "sht_plot = sht['overview'].pictures.add(fig, \n",
    "                            name = ax.get_title(), \n",
    "                            update = True, \n",
    "                            left = sht['overview'].range('X6').left, \n",
    "                            top = sht['overview'].range('X6').top)\n",
    "plt.close()\n",
    "\n",
    "#===== summary chart 02\n",
    "#==========================================================================================\n",
    "\n",
    "chart02 = sales_exp3[sales_exp3['date purchased'].between(overview_start, overview_end)].groupby([time,'customer'])[['revenue']].sum().unstack(1).fillna(0)\n",
    "chart02.columns = chart02.columns.droplevel(0)\n",
    "chart02.sort_values(chart02.index[-1], ascending = False, axis = 1, inplace = True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (11,4))\n",
    "x = np.arange(len(chart02))\n",
    "y1,y2,y3,y4 = [chart02[x].tolist() for x in chart02.columns]\n",
    "w = 0.25\n",
    "\n",
    "plot01 = ax.stackplot(x,y1,y2,y3,y4,\n",
    "                        colors = list(colors.values())[1:-1],\n",
    "                        edgecolor = 'black',\n",
    "                        labels = [x.title() for x in chart02.columns])\n",
    "\n",
    "ax.set_facecolor(colors['6'])\n",
    "ax.set_xlim(-0.05, len(chart02)-0.95)\n",
    "ax.set_title('Revenue Over Time and by Customer')\n",
    "ax.set_yticklabels(['${:,.0f}'.format(x/1000) for x in ax.get_yticks()])\n",
    "ax.set_ylabel('thousands')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.legend(loc = 'lower left', edgecolor = 'black')\n",
    "\n",
    "sht_plot = sht['overview'].pictures.add(fig, \n",
    "                            name = ax.get_title(), \n",
    "                            update = True, \n",
    "                            left = sht['overview'].range('X30').left, \n",
    "                            top = sht['overview'].range('X30').top)\n",
    "\n",
    "plt.close()\n",
    "\n",
    "#===== charts for all customers, resellers, super resellers - parts\n",
    "#==========================================================================================\n",
    "\n",
    "for k, v in for_charts.items():\n",
    "\n",
    "    df = for_charts[k][['part id','part name',cur_pretty, prev_pretty]]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (11,4))\n",
    "\n",
    "    x = np.arange(len(df))\n",
    "    y1 = df[prev_pretty]\n",
    "    y2 = df[cur_pretty]\n",
    "\n",
    "    width = 0.45\n",
    "\n",
    "    ax.bar(x, y1, width = width, label = y1.name, edgecolor = 'black', color = colors2['2'])\n",
    "    ax.bar(x + width, y2, width = width, label = y2.name, edgecolor = 'black', color = colors2['3'])\n",
    "\n",
    "    ax.set_facecolor(colors['6'])\n",
    "    ax.set_xlim(-0.5, len(df) + 0.5)\n",
    "    ax.set_title('Top 25 Parts by Revenue\\n' + k.title())\n",
    "    ax.set_yticklabels(['${:,.0f}'.format(x/1000) for x in ax.get_yticks()])\n",
    "    ax.set_ylabel('thousands')\n",
    "    ax.set_xticks(x + width/2)\n",
    "    ax.set_xticklabels([int(x) for x in df['part id']], rotation = 270, ha = 'center')\n",
    "    ax.legend(loc = 'upper right', edgecolor = 'black')\n",
    "\n",
    "    sht_plot = sht[k].pictures.add(fig, \n",
    "                                    name = ax.get_title(), \n",
    "                                    update = True, \n",
    "                                    left = sht[k].range('A33').left, \n",
    "                                    top = sht[k].range('A33').top)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "#===== charts for all customers, resellers, super resellers - over time\n",
    "#==========================================================================================    \n",
    "\n",
    "for k, v in for_charts_ot.items():\n",
    "\n",
    "    df = for_charts_ot[k]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (11,4))\n",
    "    x = np.arange(len(for_charts_ot[k]))\n",
    "    y1 = for_charts_ot[k]['revenue']\n",
    "    y2 = for_charts_ot[k]['gross profit']\n",
    "    y3 = for_charts_ot[k]['total qty']\n",
    "    w = 0.90\n",
    "\n",
    "    plot01 = ax.bar(x, y1, width = w, edgecolor = 'black', color = colors2['2'], label = y1.name.title())\n",
    "    plot02 = ax.bar(x, y2, width = w, edgecolor = 'black', color = colors2['3'], label = y2.name.title())\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    plot03, = ax2.plot(x, y3, ls = '--', color = colors2['5'], label = y3.name.title())\n",
    "\n",
    "    ax.set_facecolor(colors['6'])\n",
    "    ax.set_title('Revenue, Gross Profit, and Qty Over Time\\n' + k.title())\n",
    "    ax.set_yticklabels(['${:,.0f}'.format(x/1000) for x in ax.get_yticks()])\n",
    "    ax.set_ylabel('thousands')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(xticks)\n",
    "    ax2.set_yticklabels(['{:,.0f}'.format(x/1000) for x in ax2.get_yticks()])\n",
    "    ax2.set_ylabel('thousands', rotation = 270, labelpad = 25)\n",
    "    ax.legend(loc = 'lower left', edgecolor = 'black')\n",
    "    ax2.legend(loc = 'lower right', edgecolor = 'black')\n",
    "\n",
    "    sht_plot = sht[k].pictures.add(fig, \n",
    "                                    name = ax.get_title(), \n",
    "                                    update = True, \n",
    "                                    left = sht[k].range('F33').left, \n",
    "                                    top = sht[k].range('F33').top)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "#===== by category chart\n",
    "#==========================================================================================        \n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,11))\n",
    "\n",
    "df = cat_and_bom_charts['by category'].copy()\n",
    "df = df.sort_values(cur_pretty, ascending = True).tail(10)\n",
    "df = df[['category',prev_pretty,cur_pretty,'% change','% of total','margin']]\n",
    "\n",
    "x = np.arange(len(df))\n",
    "y1 = df[prev_pretty]\n",
    "y2 = df[cur_pretty]\n",
    "\n",
    "width = 0.45\n",
    "\n",
    "ax.barh(x + width, y1, width, label = y1.name, edgecolor = 'black', color = colors['2'])\n",
    "ax.barh(x, y2, width, label = y2.name, edgecolor = 'black', color = colors['3'])\n",
    "\n",
    "ax.set_facecolor(colors['6'])\n",
    "ax.set_title('Top 10 Categories by Revenue')\n",
    "ax.set_xticklabels(['${:,.0f}'.format(x/1000) for x in ax.get_xticks()])\n",
    "ax.set_xlabel('thousands')\n",
    "ax.set_ylim(-0.5,len(df))\n",
    "ax.set_yticks(x + width/2)\n",
    "ax.set_yticklabels([x for x in df['category']])\n",
    "ax.legend(loc = 'lower right', edgecolor = 'black')\n",
    "\n",
    "sht_plot = sht['by category'].pictures.add(fig, \n",
    "                                            name = ax.get_title(), \n",
    "                                            update = True, \n",
    "                                            left = sht['by category'].range('H5').left, \n",
    "                                            top = sht['by category'].range('H5').top)\n",
    "plt.close()    \n",
    "\n",
    "#===== by bom\n",
    "#==========================================================================================        \n",
    "\n",
    "fig, ax = plt.subplots(figsize = (11,4))\n",
    "\n",
    "df = cat_and_bom_charts['by bom'].copy()\n",
    "\n",
    "x = np.arange(len(df))\n",
    "y1 = df[prev_pretty]\n",
    "y2 = df[cur_pretty]\n",
    "\n",
    "width = 0.45\n",
    "\n",
    "ax.bar(x, y1, width, label = y1.name, edgecolor = 'black', color = colors['2'])\n",
    "ax.bar(x + width, y2, width, label = y2.name, edgecolor = 'black', color = colors['3'])\n",
    "\n",
    "ax.set_facecolor(colors['6'])\n",
    "ax.set_title('All BOMs by Revenue')write\n",
    "ax.set_yticklabels(['${:,.0f}'.format(x/1000) for x in ax.get_yticks()])\n",
    "ax.set_ylabel('thousands')\n",
    "ax.set_xticks(x + width/2)\n",
    "ax.set_xticklabels([x.replace(' - ','\\n') for x in df['bom']], fontsize = 12)\n",
    "ax.legend(loc = 'upper right', edgecolor = 'black')\n",
    "\n",
    "sht_plot = sht['by bom'].pictures.add(fig, \n",
    "                                    name = ax.get_title(), \n",
    "                                    update = True, \n",
    "                                    left = sht['by bom'].range('A16').left, \n",
    "                                    top = sht['by bom'].range('A16').top)\n",
    "plt.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
